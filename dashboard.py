import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io
import time
import os
import socket
import hashlib
import re
from datetime import datetime
import html as _html
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
def _is_nan(x):
    try:
        return x != x
    except Exception:
        return False

def fmt_num(x, na="â€”"):
    if x is None or _is_nan(x):
        return na
    try:
        s = f"{float(x):,.2f}"
    except Exception:
        return str(x)
    s = s.rstrip("0").rstrip(".")
    return s

def fmt_pct_ratio(r, na="â€”", decimals=1):
    if r is None or _is_nan(r):
        return na
    v = float(r) * 100.0
    s = f"{v:.{decimals}f}".rstrip("0").rstrip(".")
    return f"{s}%"

def fmt_pct_value(p, na="â€”", decimals=1):
    if p is None or _is_nan(p):
        return na
    v = float(p)
    sign = "+" if v > 0 else ("-" if v < 0 else "")
    s = f"{abs(v):.{decimals}f}".rstrip("0").rstrip(".")
    return f"{sign}{s}%"

_COORD_NUM_RE = re.compile(r"[-+]?\d+(?:\.\d+)?")

def _parse_lon_lat(v):
    if v is None:
        return None, None
    s = str(v).strip()
    if not s or s.lower() in {"nan", "none"}:
        return None, None
    nums = _COORD_NUM_RE.findall(s)
    if len(nums) < 2:
        return None, None
    a = float(nums[0])
    b = float(nums[1])

    def _is_lon(x): return 70 <= x <= 140
    def _is_lat(x): return 0 <= x <= 60

    if _is_lon(a) and _is_lat(b):
        lon, lat = a, b
    elif _is_lon(b) and _is_lat(a):
        lon, lat = b, a
    else:
        lon, lat = (a, b) if abs(a) >= abs(b) else (b, a)
    if not _is_lon(lon) or not _is_lat(lat):
        return None, None
    return lon, lat

def get_host_ip():
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
    except Exception:
        ip = '127.0.0.1'
    finally:
        s.close()
    return ip

# -----------------------------------------------------------------------------
# 1. Page Config
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ç¾æ€é›…æ•°æ®åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)
st.markdown('<meta name="google" content="notranslate" />', unsafe_allow_html=True)
st.markdown("""
<script>
  // Force disable translation
  document.documentElement.setAttribute("translate", "no");
  document.documentElement.classList.add("notranslate");
  document.body.setAttribute("translate", "no");
  document.body.classList.add("notranslate");
  
  // Inject meta tag to head
  var meta = document.createElement('meta');
  meta.name = "google";
  meta.content = "notranslate";
  document.getElementsByTagName('head')[0].appendChild(meta);
</script>
""", unsafe_allow_html=True)

_required_password = os.getenv("DASHBOARD_PASSWORD", "").strip()
if _required_password:
    if not st.session_state.get("_authed", False):
        st.markdown("### ğŸ”’ è®¿é—®éªŒè¯")
        _pwd = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("éªŒè¯", type="primary"):
            if _pwd == _required_password:
                st.session_state["_authed"] = True
                st.rerun()
            else:
                st.error("å¯†ç é”™è¯¯")
        st.stop()

if 'drill_level' not in st.session_state:
    st.session_state.drill_level = 1
if 'selected_prov' not in st.session_state:
    st.session_state.selected_prov = None
if 'selected_dist' not in st.session_state:
    st.session_state.selected_dist = None
if 'perf_time_mode' not in st.session_state:
    st.session_state.perf_time_mode = 'è¿‘12ä¸ªæœˆ'
if 'perf_provs' not in st.session_state:
    st.session_state.perf_provs = []
if 'perf_cats' not in st.session_state:
    st.session_state.perf_cats = []

# -----------------------------------------------------------------------------
# 2. Custom CSS
# -----------------------------------------------------------------------------
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap');
    :root {
        --bg-1: #F5F5F7;
        --bg-2: #ECECEC;
        --bg-3: #E0E0E0;
        --panel: #FFFFFF;
        --panel-2: rgba(255, 255, 255, 0.85);
        --stroke: #E0E0E0;
        --stroke-strong: #D1D1D1;
        --text: #1B1530;
        --text-muted: rgba(27, 21, 48, 0.7);
        --primary: #5B2EA6;
        --primary-2: #6A3AD0;
        --accent: #FFC400;
        --accent-2: #FFB000;
        --danger: #E5484D;
        --success: #2FBF71;
        --shadow: 0 10px 26px rgba(0, 0, 0, 0.08);
        --shadow-soft: 0 4px 12px rgba(0, 0, 0, 0.05);
        --radius: 12px;
        --radius-sm: 10px;
        --transition: 240ms cubic-bezier(.2,.8,.2,1);
        --focus: 0 0 0 3px rgba(91, 46, 166, 0.2);
        --tbl-header-bg: #4285F4;
        --tbl-header-bg-hover: #2F76E4;
        --tbl-header-border: #2B63C4;
        --tbl-header-fg: #FFFFFF;
        --tbl-header-icon: rgba(255, 255, 255, 0.92);
        --tbl-header-shadow: 0 6px 16px rgba(0, 0, 0, 0.16);
        --tbl-header-font-size: 15px;
        --tbl-header-font-weight: 800;
        --tbl-cell-font-size: 13px;
    }
    
    @media (prefers-color-scheme: dark) {
        :root {
            --tbl-header-bg: #2B66D9;
            --tbl-header-bg-hover: #2358C2;
            --tbl-header-border: #1B46A0;
            --tbl-header-fg: #FFFFFF;
            --tbl-header-icon: rgba(255, 255, 255, 0.95);
            --tbl-header-shadow: 0 10px 22px rgba(0, 0, 0, 0.32);
        }
    }

    html, body, [class*="css"] {
        font-family: 'Inter', 'Microsoft YaHei', sans-serif;
        color: var(--text);
    }

    .stApp {
        background: #F5F5F7;
    }

    [data-testid="stSidebar"], [data-testid="collapsedControl"] {
        display: none !important;
    }

    div[data-testid="stDataFrame"] thead tr th,
    div[data-testid="stTable"] thead tr th {
        background: var(--tbl-header-bg) !important;
        color: var(--tbl-header-fg) !important;
        font-weight: var(--tbl-header-font-weight) !important;
        font-size: var(--tbl-header-font-size) !important;
        border-bottom: 1px solid var(--tbl-header-border) !important;
    }

    div[data-testid="stDataFrame"] thead tr th:hover,
    div[data-testid="stTable"] thead tr th:hover {
        background: var(--tbl-header-bg-hover) !important;
    }

    div[data-testid="stDataFrame"] thead tr th:active,
    div[data-testid="stTable"] thead tr th:active {
        box-shadow: var(--tbl-header-shadow) !important;
    }

    .out-kpi-card {
        background: linear-gradient(180deg, rgba(66,133,244,0.08) 0%, rgba(255,255,255,0.92) 60%, #FFFFFF 100%);
        border-radius: 14px;
        padding: 16px 16px 14px;
        border: 1px solid rgba(66,133,244,0.22);
        box-shadow: 0 10px 26px rgba(0,0,0,0.06);
        margin-bottom: 10px;
        position: relative;
        overflow: hidden;
    }
    .out-kpi-bar {
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 3px;
        background: linear-gradient(90deg, var(--tbl-header-bg) 0%, var(--success) 60%, var(--accent) 100%);
        opacity: 0.9;
    }
    .out-kpi-head { display:flex; align-items:center; gap:10px; margin-bottom: 10px; }
    .out-kpi-ico {
        width: 34px;
        height: 34px;
        border-radius: 10px;
        display:flex;
        justify-content:center;
        align-items:center;
        background: rgba(66,133,244,0.16);
        border: 1px solid rgba(66,133,244,0.28);
        color: var(--tbl-header-bg);
        font-weight: 900;
        font-size: 18px;
    }
    .out-kpi-title { font-size: 15px; color: rgba(27,21,48,0.78); font-weight: 800; letter-spacing: 0.2px; }
    .out-kpi-val { font-size: 26px; font-weight: 900; color: #1B1530; margin-bottom: 4px; }
    .out-kpi-sub { font-size: 13px; display:flex; justify-content:space-between; align-items:center; color: rgba(27,21,48,0.72); }
    .out-kpi-sub2 { font-size: 12px; display:flex; justify-content:space-between; align-items:center; color: rgba(27,21,48,0.62); margin-top: 4px; }
    .out-kpi-progress { background: rgba(27,21,48,0.10); border-radius: 999px; height: 6px; width: 100%; overflow: hidden; }
    .out-kpi-progress-bar { height: 100%; border-radius: 999px; }
    .trend-up { color: var(--success); font-weight: 800; }
    .trend-down { color: var(--danger); font-weight: 800; }
    .trend-neutral { color: rgba(27,21,48,0.72); font-weight: 800; }
    @media (max-width: 768px) {
        .out-kpi-card { padding: 14px 14px 12px; }
        .out-kpi-val { font-size: 22px; }
        .out-kpi-title { font-size: 14px; }
    }

    h1, h2, h3, h4, h5, h6 {
        color: var(--text);
        letter-spacing: 0.2px;
        text-shadow: none;
    }

    [data-testid="stAppViewContainer"] {
        color: var(--text);
    }

    /* Reset global text visibility */
    .stMarkdown, .stText, p, li, span, label {
        color: var(--text) !important;
        text-shadow: none;
    }
    
    /* Caption specific */
    .stCaption {
        color: var(--text-muted) !important;
    }

    /* --- SIDEBAR STYLING REMOVED TO RESTORE VISIBILITY --- */
    
    /* Only keep global metric styling that doesn't affect visibility */
    div[data-testid="stMetric"] {
        background: var(--panel);
        border: 1px solid var(--stroke);
        border-radius: var(--radius);
        box-shadow: var(--shadow-soft);
        padding: 18px;
    }

    div[data-testid="stMetric"] * {
        color: var(--text) !important;
    }
    
    div[data-testid="stMetric"] label {
        color: var(--text-muted) !important;
    }

    div[data-testid="stMetric"] div[data-testid="stMetricValue"] {
        color: var(--primary) !important;
    }

    div[data-testid="stMetric"] div[data-testid="stMetricDelta"] {
        color: var(--accent-2) !important;
    }
    
    /* Buttons */
    div.stButton > button {
        border-radius: var(--radius-sm);
    }
    
    /* Analysis Button Customization */
    div.stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #FFC400 0%, #FFB000 100%) !important;
        border: 1px solid rgba(255, 176, 0, 0.4) !important;
        color: #5B2EA6 !important;
        font-weight: 700 !important;
        text-shadow: none !important;
        box-shadow: 0 4px 12px rgba(255, 196, 0, 0.25) !important;
        transition: all 0.2s ease !important;
    }

    div.stButton > button[kind="primary"]:hover {
        background: linear-gradient(135deg, #FFD54F 0%, #FFC107 100%) !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 6px 16px rgba(255, 196, 0, 0.35) !important;
        border-color: rgba(255, 176, 0, 0.6) !important;
    }
    
    div.stButton > button[kind="primary"]:active {
        transform: translateY(1px) !important;
        box-shadow: 0 2px 8px rgba(255, 196, 0, 0.2) !important;
    }
    
    /* Tabs styling kept simple */
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }

    /* Outbound subtabs (radio styled as tabs) */
    div[data-testid="stRadio"] .out-subtab-hint {display:none;}
    div[data-testid="stRadio"] [data-baseweb="radio"] > div {
        background: transparent !important;
        border: none !important;
        box-shadow: none !important;
        padding: 0 !important;
        margin: 0 !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input {
        position: absolute !important;
        opacity: 0 !important;
        pointer-events: none !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] div[role="radio"] {
        display: none !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] span {
        font-weight: 600 !important;
        color: rgba(27, 21, 48, 0.75) !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input:checked ~ div span {
        color: rgba(27, 21, 48, 0.95) !important;
    }
    div[data-testid="stRadio"] [data-testid="stRadio"] > div[role="radiogroup"] {
        border-bottom: 1px solid rgba(0, 0, 0, 0.08) !important;
        padding-bottom: 6px !important;
        gap: 10px !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] {
        position: relative !important;
        padding: 8px 0 10px 0 !important;
        margin-right: 14px !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input:checked ~ div::after {
        content: "" !important;
        position: absolute !important;
        left: 0 !important;
        right: 0 !important;
        bottom: -7px !important;
        height: 2px !important;
        background: #E5484D !important;
        border-radius: 2px !important;
        transition: all 0.2s ease !important;
    }

    .out-subtab-content {
        animation: outFadeUp 240ms cubic-bezier(.2,.8,.2,1);
    }
    @keyframes outFadeUp {
        from { opacity: 0; transform: translateY(8px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* Ensure DataFrame styling is applied even if internal structure varies */
    [data-testid="stDataFrame"] {
        background: var(--panel);
        border: 1px solid var(--stroke);
        border-radius: var(--radius);
        box-shadow: var(--shadow-soft);
        overflow: hidden;
    }
    
    /* Target all possible table cells within the dataframe container */
    [data-testid="stDataFrame"] td, 
    [data-testid="stDataFrame"] th,
    [data-testid="stDataFrame"] [role="gridcell"],
    [data-testid="stDataFrame"] [role="columnheader"],
    [data-testid="stDataFrame"] div[data-testid="stDataFrameResizable"] {
        text-align: center !important;
        vertical-align: middle !important;
        color: var(--text) !important;
        display: flex;
        justify-content: center;
        align-items: center;
    }
    
    /* Force header content center */
    [data-testid="stDataFrame"] [role="columnheader"] > div {
        justify-content: center !important;
        text-align: center !important;
        width: 100%;
        display: flex;
    }
    
    /* Force cell content center */
    [data-testid="stDataFrame"] [role="gridcell"] > div {
        justify-content: center !important;
        text-align: center !important;
        width: 100%;
        display: flex;
    }

    /* Essential Visibility Controls */
    button[kind="header"], [data-testid="collapsedControl"] {
        visibility: visible !important;
        z-index: 999999 !important;
    }

    header {visibility: visible !important;}
    [data-testid="stSidebarNav"] {display: block !important;}
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
    [data-testid="stStatusWidget"] {visibility: hidden;}
    [data-testid="stToolbar"] {display: none !important;}
    [data-testid="stHeader"] {background: transparent !important;}
    [data-testid="stHeader"] a {display:none !important;}
    [data-testid="stViewerBadge"] {display:none !important;}
    [data-testid="stGitHubLink"] {display:none !important;}

    /* Sidebar explicit frosted light scheme to ensure readability */
    [data-testid="stSidebar"] {
        background: rgba(255, 255, 255, 0.88) !important;
        backdrop-filter: blur(10px) !important;
        border-right: 1px solid rgba(0, 0, 0, 0.08) !important;
    }
    [data-testid="stSidebar"] * {
        color: #333333 !important;
    }
    [data-testid="stSidebar"] summary svg,
    [data-testid="stSidebar"] svg {
        fill: #333333 !important;
    }
    [data-testid="stSidebar"] details[data-testid="stExpander"] > summary:hover {
        background: rgba(0,0,0,0.05) !important;
    }

    /* Sidebar inputs and selects */
    [data-testid="stSidebar"] input,
    [data-testid="stSidebar"] div[data-baseweb="select"] > div {
        background: rgba(255,255,255,0.95) !important;
        border: 1px solid rgba(0,0,0,0.15) !important;
        color: #333333 !important;
    }
    [data-testid="stSidebar"] input::placeholder {
        color: rgba(0,0,0,0.55) !important;
    }
    [data-testid="stSidebar"] div[data-baseweb="select"] > div:hover,
    [data-testid="stSidebar"] input:hover {
        border-color: rgba(91,46,166,0.6) !important;
    }

    /* File uploader dropzone */
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] {
        background: rgba(255,255,255,0.92) !important;
        border: 1px dashed rgba(0,0,0,0.18) !important;
        color: #333333 !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] span {
        color: #333333 !important;
    }
    [data-testid="stSidebar"] [data-testid="stBaseButton-secondary"] {
        background: rgba(91,46,166,0.10) !important;
        color: #333333 !important;
        border: 1px solid rgba(91,46,166,0.35) !important;
    }

    /* Collapsed control arrow visibility and contrast */
    [data-testid="collapsedControl"] {
        color: #333333 !important;
        background: rgba(255,255,255,0.55) !important;
        border: 1px solid rgba(0,0,0,0.12) !important;
        border-radius: 6px !important;
        top: 56px !important;
    }

    @media (max-width: 768px) {
        div[data-testid="stMetric"] {
            padding: 14px;
        }
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
    div[data-testid="stDataFrame"] div[role="gridcell"] { display: flex; align-items: center; }
    div[data-testid="stDataFrame"] div[role="columnheader"] { display: flex; align-items: center; justify-content: center; }
    .msy-table-wrap {
        width: 100%;
        overflow-x: auto;
        border-radius: 12px;
        border: 1px solid rgba(0,0,0,0.08);
        background: rgba(255,255,255,0.9);
        box-shadow: 0 6px 18px rgba(0,0,0,0.06);
    }
    table.msy-table {
        width: 100%;
        border-collapse: collapse;
        table-layout: auto;
        font-size: 14px;
        line-height: 1.45;
    }
    table.msy-table thead th {
        position: sticky;
        top: 0;
        background: #1F2937;
        color: #F9FAFB;
        font-weight: 700;
        padding: 10px 12px;
        border: 1px solid rgba(255,255,255,0.12);
        text-align: center;
        vertical-align: middle;
        white-space: nowrap;
    }
    table.msy-table tbody td {
        padding: 10px 12px;
        border: 1px solid rgba(0,0,0,0.08);
        text-align: center;
        vertical-align: middle;
        font-variant-numeric: tabular-nums;
        white-space: nowrap;
    }
    table.msy-table tbody tr:nth-child(even) td {
        background: #F8FAFC;
    }
    table.msy-table tbody tr:hover td {
        background: #EEF2FF;
    }
</style>
""", unsafe_allow_html=True)

def _format_cell(v):
    if v is None or pd.isna(v):
        return ""
    if isinstance(v, (int, float, np.integer, np.floating)):
        return fmt_num(v, na="")
    return str(v)


# -----------------------------------------------------------------------------
# AgGrid Helper
# -----------------------------------------------------------------------------
JS_COLOR_CONDITIONAL = JsCode("""
function(params) {
    if (params.value > 0) {
        return {'color': '#28A745', 'textAlign': 'center', 'fontWeight': 'bold'};
    } else if (params.value < 0) {
        return {'color': '#DC3545', 'textAlign': 'center', 'fontWeight': 'bold'};
    }
    return {'textAlign': 'center'};
}
""")

JS_CENTER = JsCode("""
function(params) {
    return {'textAlign': 'center'};
}
""")

JS_FMT_NUM = JsCode("""
function(params) {
    const v = params.value;
    if (v === null || v === undefined) return '';
    const n = Number(v);
    if (!isFinite(n)) return '';
    return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
}
""")

JS_FMT_PCT_RATIO = JsCode("""
function(params) {
    const v = params.value;
    if (v === null || v === undefined) return '';
    const n = Number(v);
    if (!isFinite(n)) return '';
    const p = n * 100;
    return p.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1}) + '%';
}
""")

# Custom Cell Renderer for Progress Bar (Mockup using HTML)
JS_PROGRESS_BAR = JsCode("""
class ProgressBarRenderer {
    init(params) {
        this.eGui = document.createElement('div');
        this.eGui.style.width = '100%';
        this.eGui.style.height = '100%';
        this.eGui.style.display = 'flex';
        this.eGui.style.alignItems = 'center';
        
        const fmt1 = (v) => {
            if (v === null || v === undefined) return '';
            const n = Number(v);
            if (!isFinite(n)) return '';
            if (Math.abs(n - Math.round(n)) < 1e-9) return Math.round(n).toLocaleString('zh-CN');
            return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
        };

        let value = params.value;
        if (value === null || value === undefined) value = 0;

        let maxValue = 0;
        if (params.colDef && params.colDef.cellRendererParams && params.colDef.cellRendererParams.maxValue !== undefined) {
            maxValue = Number(params.colDef.cellRendererParams.maxValue) || 0;
        }

        const percent = maxValue > 0 ? Math.min(Math.max((Number(value) / maxValue) * 100, 0), 100) : 0;

        let color = '#007bff';
        if (percent >= 100) color = '#28a745';
        else if (percent < 60) color = '#dc3545';
        else color = '#ffc107';
        
        this.eGui.innerHTML = `
            <div style="width: 100%; height: 20px; background-color: #e9ecef; border-radius: 3px; position: relative;">
                <div style="width: ${percent}%; height: 100%; background-color: ${color}; border-radius: 3px; transition: width 0.5s;"></div>
                <span style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; text-align: center; line-height: 20px; font-size: 12px; color: #000;">${fmt1(value)}</span>
            </div>
        `;
    }
    getGui() {
        return this.eGui;
    }
}
""")

# Custom Cell Renderer for Count (No %)
JS_PROGRESS_BAR_COUNT = JsCode("""
class ProgressBarCountRenderer {
    init(params) {
        this.eGui = document.createElement('div');
        this.eGui.style.width = '100%';
        this.eGui.style.height = '100%';
        this.eGui.style.display = 'flex';
        this.eGui.style.alignItems = 'center';
        
        const fmt1 = (v) => {
            if (v === null || v === undefined) return '';
            const n = Number(v);
            if (!isFinite(n)) return '';
            if (Math.abs(n - Math.round(n)) < 1e-9) return Math.round(n).toLocaleString('zh-CN');
            return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
        };

        let value = params.value;
        if (value === null || value === undefined) value = 0;

        let maxValue = 0;
        if (params.colDef && params.colDef.cellRendererParams && params.colDef.cellRendererParams.maxValue !== undefined) {
            maxValue = Number(params.colDef.cellRendererParams.maxValue) || 0;
        }

        const percent = maxValue > 0 ? Math.min(Math.max((Number(value) / maxValue) * 100, 0), 100) : 0;

        let color = '#28a745';
        if (percent > 0) color = '#ffc107';
        if (percent >= 60) color = '#dc3545';
        
        this.eGui.innerHTML = `
            <div style="width: 100%; height: 20px; background-color: #e9ecef; border-radius: 3px; position: relative;">
                <div style="width: ${percent}%; height: 100%; background-color: ${color}; border-radius: 3px; transition: width 0.5s;"></div>
                <span style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; text-align: center; line-height: 20px; font-size: 12px; color: #000;">${fmt1(value)}</span>
            </div>
        `;
    }
    getGui() {
        return this.eGui;
    }
}
""")

def show_aggrid_table(df, height=None, key=None, on_row_selected=None, 
                      columns_props=None, 
                      column_defs=None,
                      grid_options_overrides=None,
                      auto_height_limit=2000):
    """
    Standardized AgGrid Table
    :param df: DataFrame to display
    :param height: Fixed height (optional)
    :param key: Unique key
    :param on_row_selected: 'single' or 'multiple' or None
    :param columns_props: Dict of col_name -> {type: 'percent'|'money'|'growth'|'bar', ...}
    :param auto_height_limit: Max height for auto calculation
    """
    if df is None or df.empty:
        # Custom Empty State
        st.markdown("""
            <div style="text-align: center; padding: 40px; background: #f8f9fa; border-radius: 8px; border: 1px dashed #d9d9d9;">
                <div style="font-size: 24px; margin-bottom: 10px;">ğŸ“­</div>
                <div style="color: #666; font-size: 14px;">æš‚æ— æ•°æ®</div>
            </div>
        """, unsafe_allow_html=True)
        return None

    # Inject CSS for Custom AgGrid Styling
    st.markdown("""
        <style>
        /* --- 1. Header Styling --- */
        .ag-header {
            background-color: var(--tbl-header-bg) !important;
            border-bottom: 1px solid var(--tbl-header-border) !important;
        }
        .ag-header-row,
        .ag-header-group-cell,
        .ag-header-cell {
            background-color: var(--tbl-header-bg) !important;
        }
        .ag-header-group-cell:hover,
        .ag-header-cell:hover {
            background-color: var(--tbl-header-bg-hover) !important;
        }
        .ag-header-group-cell:active,
        .ag-header-cell:active {
            box-shadow: var(--tbl-header-shadow) !important;
        }
        .ag-header-cell {
            color: var(--tbl-header-fg) !important;
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-header-font-size) !important;
            font-weight: var(--tbl-header-font-weight) !important;
            padding: 0 12px !important;
        }
        .ag-header-group-cell {
            color: var(--tbl-header-fg) !important;
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-header-font-size) !important;
            font-weight: var(--tbl-header-font-weight) !important;
        }
        .ag-header-cell .ag-icon,
        .ag-header-group-cell .ag-icon,
        .ag-sort-indicator-icon,
        .ag-icon-asc,
        .ag-icon-desc,
        .ag-icon-menu {
            color: var(--tbl-header-icon) !important;
            fill: var(--tbl-header-icon) !important;
            opacity: 1 !important;
        }
        /* Strict Centering for Header */
        .ag-header-cell-label {
            display: flex !important;
            justify-content: center !important;
            align-items: center !important;
            text-align: center !important;
            width: 100% !important;
        }
        .ag-header-cell-label, .ag-header-cell-text {
            white-space: normal !important;
            overflow: visible !important;
            text-overflow: clip !important;
            line-height: 1.2 !important;
        }

        /* Strict Centering for Cells */
        .ag-cell, .ag-cell-value {
            display: flex !important;
            justify-content: center !important;
            align-items: center !important;
            text-align: center !important;
        }
        
        /* Remove default separator bars in header */
        .ag-header-cell::after, .ag-header-group-cell::after {
            display: none !important;
        }

        /* --- 2. Row & Cell Styling --- */
        .ag-row {
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-cell-font-size) !important;
            color: #333333 !important;
            border-bottom-color: #f0f0f0 !important;
        }
        .ag-row-odd {
            background-color: #f8f9fa !important;
        }
        .ag-row-even {
            background-color: #ffffff !important;
        }
        .ag-row-hover {
            background-color: #f0f7ff !important;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;
            z-index: 5;
        }
        .ag-row-selected {
            background-color: #e6f7ff !important;
            border-left: 2px solid #4096ff !important; /* Left highlight */
        }
        
        /* Removed duplicate .ag-cell rule, handled above */

        /* Selected Row Text */
        .ag-row-selected .ag-cell {
            font-weight: 500 !important;
        }

        .ag-row.ag-row-pinned,
        .ag-row.ag-row-pinned-bottom {
            background-color: var(--tbl-header-bg) !important;
        }
        .ag-row-pinned .ag-cell,
        .ag-row-pinned-bottom .ag-cell {
            color: var(--tbl-header-fg) !important;
            font-weight: 900 !important;
            border-top: 1px solid var(--tbl-header-border) !important;
        }
        .ag-row-pinned .ag-cell .ag-cell-value,
        .ag-row-pinned-bottom .ag-cell .ag-cell-value {
            color: var(--tbl-header-fg) !important;
            font-weight: 900 !important;
        }
        .ag-row-pinned .ag-cell .ag-icon,
        .ag-row-pinned-bottom .ag-cell .ag-icon {
            color: var(--tbl-header-icon) !important;
            fill: var(--tbl-header-icon) !important;
        }
        
        /* --- 3. Container & Borders --- */
        .ag-root-wrapper {
            border: 1px solid #e5e6eb !important;
            border-radius: 4px !important;
            overflow: hidden !important; /* For radius */
        }
        
        /* --- 4. Scrollbars (Optional, for better look) --- */
        .ag-body-viewport::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        .ag-body-viewport::-webkit-scrollbar-thumb {
            background: #ccc;
            border-radius: 4px;
        }
        .ag-body-viewport::-webkit-scrollbar-track {
            background: #f1f1f1;
        }

        /* --- 5. Mobile Optimization --- */
        @media (max-width: 768px) {
            .ag-header-cell {
                font-size: 13px !important;
                padding: 0 4px !important;
            }
            .ag-header-group-cell {
                font-size: 13px !important;
            }
            .ag-cell {
                font-size: 12px !important;
                padding: 0 4px !important;
            }
            .ag-header-group-cell:active,
            .ag-header-cell:active {
                box-shadow: none !important;
            }
        }
        </style>
    """, unsafe_allow_html=True)

    gb = GridOptionsBuilder.from_dataframe(df)

    percent_cols = set()
    if columns_props:
        for col, props in columns_props.items():
            c_type = (props or {}).get('type')
            if c_type in ['percent', 'growth']:
                percent_cols.add(col)
    for col in df.columns:
        if ('åŒæ¯”' in str(col)) or ('å¢é•¿' in str(col)) or ('è¾¾æˆç‡' in str(col)) or (str(col).endswith('ç‡')):
            percent_cols.add(col)
    
    total_row = {c: None for c in df.columns}
    if len(df.columns) > 0:
        total_row[df.columns[0]] = 'åˆè®¡'
    yoy_cols = [c for c in df.columns if ('åŒæ¯”' in str(c)) or (str(c) == 'åŒæ¯”å¢é•¿')]

    for c in df.columns:
        if c == df.columns[0]:
            continue
        if c in percent_cols:
            continue
        s = pd.to_numeric(df[c], errors='coerce')
        if s.notna().sum() == 0:
            continue
        total_row[c] = float(s.fillna(0).sum())

    def _infer_yoy_pair(yoy_col: str):
        if yoy_col not in df.columns:
            return None

        for old, new in [
            ('åŒæ¯”(ç®±)', 'ç®±æ•°'),
            ('åŒæ¯”ï¼ˆç®±ï¼‰', 'ç®±æ•°'),
            ('åŒæ¯”(é—¨åº—)', 'é—¨åº—æ•°'),
            ('åŒæ¯”ï¼ˆé—¨åº—ï¼‰', 'é—¨åº—æ•°'),
        ]:
            if old in str(yoy_col):
                cur = str(yoy_col).replace(old, new)
                last = str(yoy_col).replace(old, 'åŒæœŸ(ç®±æ•°)' if 'ç®±' in old else 'åŒæœŸ(é—¨åº—æ•°)')
                if cur in df.columns and last in df.columns:
                    return cur, last

        if str(yoy_col) == 'åŒæ¯”å¢é•¿':
            for cur, last in [
                ('æœ¬æœˆ', 'åŒæœŸ'),
                ('æœ¬æœˆä¸šç»©', 'åŒæœŸä¸šç»©'),
                ('æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)'),
                ('æœ¬æœˆä¸šç»©(ä¸‡)', 'åŒæœŸä¸šç»©(ä¸‡)'),
                ('å®é™…', 'åŒæœŸ'),
            ]:
                if cur in df.columns and last in df.columns:
                    return cur, last

        base = (
            str(yoy_col)
            .replace('åŒæ¯”å¢é•¿', '')
            .replace('åŒæ¯”', '')
            .replace('å¢é•¿', '')
            .strip()
        )
        if not base:
            return None
        last_candidates = [c for c in df.columns if ('åŒæœŸ' in str(c) or 'å»å¹´' in str(c)) and base in str(c)]
        cur_candidates = [c for c in df.columns if ('åŒæœŸ' not in str(c) and 'å»å¹´' not in str(c) and 'åŒæ¯”' not in str(c) and 'å¢é•¿' not in str(c)) and base in str(c)]
        if len(cur_candidates) == 1 and len(last_candidates) == 1:
            return cur_candidates[0], last_candidates[0]
        return None

    for c in yoy_cols:
        pair = _infer_yoy_pair(c)
        if not pair:
            continue
        cur_col, last_col = pair
        try:
            cur_sum = float(pd.to_numeric(df[cur_col], errors='coerce').fillna(0).sum())
            last_sum = float(pd.to_numeric(df[last_col], errors='coerce').fillna(0).sum())
            total_row[c] = (cur_sum - last_sum) / last_sum if last_sum > 0 else None
        except Exception:
            total_row[c] = None
    
    # Configure General Options
    gb.configure_grid_options(
        rowHeight=40, # increased for padding
        headerHeight=60,
        animateRows=True,
        suppressCellFocus=True, # remove blue outline on click
        enableCellTextSelection=True,
        suppressDragLeaveHidesColumns=True,
        sideBar={
            "toolPanels": [
                {
                    "id": "columns",
                    "labelDefault": "åˆ—",
                    "iconKey": "columns",
                    "toolPanel": "agColumnsToolPanel",
                    "toolPanelParams": {
                        "suppressRowGroups": True,
                        "suppressValues": True,
                        "suppressPivots": True,
                        "suppressPivotMode": True
                    }
                }
            ],
            "defaultToolPanel": None
        }
    )
    
    # Default Config: Centered, Resizable, Sortable, Filterable
    gb.configure_default_column(
        resizable=True,
        filterable=True,
        sortable=True,
        cellStyle=JS_CENTER,
        headerClass='ag-header-center',
        headerStyle={'textAlign': 'center', 'justifyContent': 'center'},
        wrapHeaderText=True,
        autoHeaderHeight=True,
        minWidth=70,
        flex=1
    )
    
    configured_cols = set()

    # Apply Column Specific Props
    if columns_props:
        for col, props in columns_props.items():
            if col not in df.columns:
                continue
            
            c_type = props.get('type')
            max_value = None
            if c_type in ("bar", "bar_count"):
                s = pd.to_numeric(df[col], errors='coerce')
                max_value = float(s.max()) if len(s) and pd.notna(s.max()) else 0.0
            
            if c_type == 'growth':
                gb.configure_column(col, 
                                    cellStyle=JS_COLOR_CONDITIONAL, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_PCT_RATIO,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'percent':
                 gb.configure_column(col, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_PCT_RATIO,
                                    minWidth=70,
                                    flex=1)
                 configured_cols.add(col)
            elif c_type == 'money':
                gb.configure_column(col, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'bar':
                # Use custom renderer
                gb.configure_column(col, 
                                    cellRenderer=JS_PROGRESS_BAR,
                                    cellRendererParams={'maxValue': max_value},
                                    type=["numericColumn", "numberColumnFilter"],
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'bar_count':
                # Use custom renderer for count
                gb.configure_column(col, 
                                    cellRenderer=JS_PROGRESS_BAR_COUNT,
                                    cellRendererParams={'maxValue': max_value},
                                    type=["numericColumn", "numberColumnFilter"],
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
                
    # Generic Auto-Type Logic (Fallbacks)
    for col in df.columns:
        if col in configured_cols:
            continue
        
        # Check if column has 'growth' or 'åŒæ¯”' -> Growth Color
        if 'åŒæ¯”' in col or 'å¢é•¿' in col:
            gb.configure_column(col, 
                                cellStyle=JS_COLOR_CONDITIONAL, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_PCT_RATIO,
                                minWidth=70,
                                flex=1)
        
        # Check if 'è¾¾æˆç‡' or 'ç‡' -> Percent
        elif 'è¾¾æˆç‡' in col or 'å æ¯”' in col or str(col).endswith('ç‡'):
            gb.configure_column(col, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_PCT_RATIO,
                                minWidth=70,
                                flex=1)
            
            # Optional: Add Data Bar style for 'è¾¾æˆç‡' if requested
            if 'è¾¾æˆç‡' in col:
                 gb.configure_column(col,
                    cellStyle=JsCode("""
                        function(params) {
                            let ratio = params.value;
                            if (ratio === null || isNaN(ratio)) return {'textAlign': 'center'};
                            let percent = ratio * 100;
                             let color = '#28a745'; // Green
                             if (percent < 100) color = '#ffc107'; // Yellow
                             if (percent < 60) color = '#dc3545'; // Red
                             return {
                                 'textAlign': 'center', 
                                 'background': `linear-gradient(90deg, ${color} ${Math.min(percent, 100)}%, transparent ${Math.min(percent, 100)}%)`
                             };
                        }
                    """),
                    valueFormatter=JS_FMT_PCT_RATIO,
                    minWidth=70,
                    flex=1
                 )

        # Money/Number
        elif pd.api.types.is_numeric_dtype(df[col]):
            gb.configure_column(col, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_NUM,
                                minWidth=70,
                                flex=1)
        else:
            if col == df.columns[0]:
                gb.configure_column(col, minWidth=95, flex=1.2, tooltipField=col)
            else:
                gb.configure_column(col, minWidth=100, flex=1.2, tooltipField=col)

    # Selection
    if on_row_selected:
        gb.configure_selection('single', use_checkbox=False)
        
    gridOptions = gb.build()
    gridOptions['pinnedBottomRowData'] = [total_row]
    if column_defs:
        gridOptions['columnDefs'] = column_defs
        gridOptions['groupHeaderHeight'] = 40
        gridOptions['headerHeight'] = 46
    if grid_options_overrides:
        gridOptions.update(grid_options_overrides)
    
    # --- Auto Height & Pagination Logic ---
    # 1. Calculate ideal height for all rows
    n_rows = len(df)
    row_h = 40  # consistent with configure_grid_options rowHeight
    header_h = 60 # consistent with configure_grid_options headerHeight
    padding = 20
    
    calc_full_height = header_h + (n_rows * row_h) + padding + 40 # +40 buffer for potential horizontal scrollbar/total row
    
    # 2. Thresholds
    MAX_HEIGHT_NO_SCROLL = 600  # If content < 600px, show full height (no scroll/pagination)
    PAGE_SIZE = 20              # If content > 600px, use pagination with 20 rows/page
    
    # 3. Determine Mode
    # If explicit height provided, use it (and scroll if needed)
    # Else, apply auto-logic
    if height:
        final_height = height
        # If explicitly short height, maybe enable pagination? No, trust caller or AgGrid default scroll.
    else:
        if calc_full_height <= MAX_HEIGHT_NO_SCROLL:
            final_height = max(150, calc_full_height) # At least 150px
            # No pagination needed
            gridOptions['pagination'] = False
        else:
            # Content too long -> Use Pagination
            gridOptions['pagination'] = True
            gridOptions['paginationPageSize'] = PAGE_SIZE
            # Height fits PageSize rows + Header + PaginationPanel
            # PageSize * RowHeight + Header + PagerPanel(~50px)
            final_height = (PAGE_SIZE * row_h) + header_h + 50 + padding
    
    # Enable SideBar for Columns Tool Panel (Optional, user asked for "Drop down menu for each column")
    # AgGrid default filter menu is on column header. 
    
    # --- Responsive & Horizontal Scroll Logic ---
    # If too many columns, disable 'fit_columns_on_grid_load' to allow horizontal scroll
    # Heuristic: > 8-10 columns or if we suspect wide content
    should_fit_columns = True
    if len(df.columns) > 10:
        should_fit_columns = False
    
    return AgGrid(
        df,
        gridOptions=gridOptions,
        height=final_height,
        width='100%',
        data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
        update_mode=GridUpdateMode.SELECTION_CHANGED | GridUpdateMode.VALUE_CHANGED,
        fit_columns_on_grid_load=should_fit_columns,
        allow_unsafe_jscode=True, 
        theme='streamlit', 
        key=key
    )

# -----------------------------------------------------------------------------
# 3. Data Logic
# -----------------------------------------------------------------------------

@st.cache_data(show_spinner=False)
def load_data_v2(file_bytes: bytes, file_name: str):
    debug_logs = []
    try:
        file_name_lower = (file_name or "").lower()
        bio = io.BytesIO(file_bytes)
        if file_name_lower.endswith('.csv'):
            df = pd.read_csv(bio, encoding='gb18030')
            df_stock = None
            df_q4_raw = None
            df_perf_raw = None
        else:
            xl = pd.ExcelFile(bio)
            df = xl.parse(0)
            df_stock = xl.parse(1) if len(xl.sheet_names) > 1 else None
            df_q4_raw = xl.parse(2) if len(xl.sheet_names) > 2 else None
            df_perf_raw = None
            
            debug_logs.append(f"Total Sheets: {len(xl.sheet_names)} | Names: {xl.sheet_names}")

            # Sheet 4 Detection Logic (Robust)
            if len(xl.sheet_names) > 3:
                preferred = next((s for s in xl.sheet_names if 'sheet4' in str(s).strip().lower()), None)
                candidate_names = [preferred] if preferred else []
                candidate_names += [s for s in xl.sheet_names if s not in candidate_names]
                
                for sname in candidate_names:
                    try:
                        # Optimization: Read only header first (0 rows) to check columns
                        tmp_header = xl.parse(sname, nrows=0)
                        cols = [str(c).strip() for c in tmp_header.columns]
                    except Exception as e:
                        debug_logs.append(f"Error parsing header of {sname}: {str(e)}")
                        continue
                    
                    # Fuzzy match for keys
                    key_hits = sum(1 for k in ['å¹´ä»½', 'æœˆä»½', 'çœåŒº'] if any(k in c for c in cols))
                    signal_hits = sum(1 for k in ['å‘è´§ä»“', 'åŸä»·é‡‘é¢', 'åŸºæœ¬æ•°é‡', 'å¤§åˆ†ç±»', 'æœˆåˆ†æ', 'å®¢æˆ·ç®€ç§°'] if any(k in c for c in cols))
                    
                    debug_logs.append(f"Checking '{sname}': keys={key_hits}, signals={signal_hits}")
                    
                    if key_hits >= 2 and signal_hits >= 1:
                        # Found it! Now read the full sheet
                        try:
                            df_perf_raw = xl.parse(sname)
                            debug_logs.append(f"-> MATCHED Sheet4: {sname}")
                            break
                        except Exception as e:
                            debug_logs.append(f"Error reading body of {sname}: {e}")
            else:
                 debug_logs.append("Warning: Less than 4 sheets found.")
            
        # --- Process Sheet 1 (Sales) ---
        # Ensure column names are clean
        df.columns = [str(c).strip() for c in df.columns]
        
        # --- Handle Long Format (Rows) -> Wide Format (Columns) ---
        # User indicates Time (Month) is in Column F (index 5)
        # Potential Columns: F=Time, I=Prov, J=Dist, K=Qty (based on user info)
        is_long_format = False
        time_col = None
        
        # Check if Column F exists and looks like Month
        if len(df.columns) > 5:
            col_f = df.columns[5]
            # Check a sample of values in Col F for "æœˆ" or date-like
            sample_vals = df[col_f].dropna().head(10).astype(str).tolist()
            if any('æœˆ' in v for v in sample_vals):
                is_long_format = True
                time_col = col_f
        
        if is_long_format:
            # Identify Key Columns for Pivot
            # Try to map by name or index
            # User hints: Prov(I=8), Dist(J=9), Qty(K=10)
            
            col_prov = df.columns[8] if len(df.columns) > 8 else None
            col_dist = df.columns[9] if len(df.columns) > 9 else None
            col_qty = df.columns[10] if len(df.columns) > 10 else None
            
            # Fallback: Search by name
            if col_prov is None: col_prov = next((c for c in df.columns if 'çœ' in c), None)
            if col_dist is None: col_dist = next((c for c in df.columns if 'ç»é”€' in c or 'å®¢æˆ·' in c), None)
            if col_qty is None: col_qty = next((c for c in df.columns if 'æ•°' in c or 'Qty' in c or 'ç®±' in c), None)
            
            # Store Column? If not found, default to Dist or blank
            col_store = next((c for c in df.columns if 'é—¨åº—' in c), None)
            
            if col_prov and col_dist and col_qty and time_col:
                # Prepare for Pivot
                pivot_index = [col_prov, col_dist]
                if col_store:
                    pivot_index.append(col_store)
                
                # Pivot
                # Ensure Qty is numeric
                df[col_qty] = pd.to_numeric(df[col_qty], errors='coerce').fillna(0)
                
                df_wide = df.pivot_table(
                    index=pivot_index,
                    columns=time_col,
                    values=col_qty,
                    aggfunc='sum'
                ).reset_index()
                
                # Handle Missing Store Column if needed
                if not col_store:
                    df_wide['é—¨åº—åç§°'] = df_wide[col_dist] # Use Dist as Store if missing
                    
                df = df_wide
                # Reset clean columns
                df.columns = [str(c).strip() for c in df.columns]
                
        # Identify Month Columns (Assume '1æœˆ', '2æœˆ', etc. or columns 4 onwards if strict structure)
        # Based on user requirement: Col 1-3 are dimensions, 4+ are months.
        # Let's try to detect "Xæœˆ" pattern first, fallback to index.
        month_cols = [c for c in df.columns if 'æœˆ' in c and c not in ['å“ç‰ŒçœåŒºåç§°', 'ç»é”€å•†åç§°', 'é—¨åº—åç§°']]
        
        # If headers are standard: å“ç‰ŒçœåŒºåç§°, ç»é”€å•†åç§°, é—¨åº—åç§°
        # Normalize dimension columns
        rename_map = {}
        if 'å“ç‰ŒçœåŒºåç§°' in df.columns: rename_map['å“ç‰ŒçœåŒºåç§°'] = 'çœåŒº'
        if 'ç»é”€å•†åç§°' not in df.columns and len(df.columns) > 1: rename_map[df.columns[1]] = 'ç»é”€å•†åç§°'
        if 'é—¨åº—åç§°' not in df.columns and len(df.columns) > 2: rename_map[df.columns[2]] = 'é—¨åº—åç§°'
        
        df = df.rename(columns=rename_map)
        
        # Validate critical columns
        required = ['çœåŒº', 'ç»é”€å•†åç§°', 'é—¨åº—åç§°']
        for req in required:
            if req not in df.columns:
                # Fallback: Assume positional 0, 1, 2
                if len(df.columns) >= 3:
                    df.columns.values[0] = 'çœåŒº'
                    df.columns.values[1] = 'ç»é”€å•†åç§°'
                    df.columns.values[2] = 'é—¨åº—åç§°'
                else:
                    st.error(f"æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå¤±åˆ— {req}")
                    return None, None, None, None

        # Re-identify month cols after rename
        month_cols = [c for c in df.columns if c not in required]
        
        # Ensure numeric
        for col in month_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        # --- Core Metric Calculation ---
        # 1. Total Shipment
        df['æ€»å‡ºåº“æ•°'] = df[month_cols].sum(axis=1)
        
        # 2. Effective Months (Count where Shipment > 0)
        df['æœ‰æ•ˆæœˆä»½æ•°'] = df[month_cols].gt(0).sum(axis=1).astype(int)
        
        # 3. Avg Monthly Shipment
        # Optimized: Vectorized calculation instead of apply
        df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] = np.where(df['æœ‰æ•ˆæœˆä»½æ•°'] > 0, df['æ€»å‡ºåº“æ•°'] / df['æœ‰æ•ˆæœˆä»½æ•°'], 0.0)
        
        # Classification
        # Optimized: Vectorized select
        conditions = [
            df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 4,
            (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 2) & (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] < 4),
            (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 1) & (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] < 2)
        ]
        choices = ['Aç±»é—¨åº— (>=4)', 'Bç±»é—¨åº— (2-4)', 'Cç±»é—¨åº— (1-2)']
        df['é—¨åº—åˆ†ç±»'] = np.select(conditions, choices, default='Dç±»é—¨åº— (<1)')
        
        # --- Process Sheet 2 (Stock) ---
        if df_stock is not None:
            # Clean columns
            df_stock.columns = [str(c).strip() for c in df_stock.columns]
            
            # Validate Stock Columns (A-L strict structure check or Name check)
            # User defined: ç»é”€å•†ç¼–ç (A), ç»é”€å•†åç§°(B), äº§å“ç¼–ç (C), äº§å“åç§°(D), åº“å­˜æ•°é‡(E), ç®±æ•°(F), çœåŒº(G), å®¢æˆ·ç®€ç§°(H), å¤§ç±»(I), å°ç±»(J), é‡é‡(K), è§„æ ¼(L)
            # We map by index to be safe if names vary slightly, or by expected names.
            # Let's use expected names map based on index to standardize.
            # UPDATE: Use 'å®¢æˆ·ç®€ç§°' (Håˆ—, index 7) as the primary 'ç»é”€å•†åç§°' for analysis.
            # Rename original 'ç»é”€å•†åç§°' (Båˆ—, index 1) to 'ç»é”€å•†å…¨ç§°' for reference.
            stock_cols_map = {
                0: 'ç»é”€å•†ç¼–ç ', 1: 'ç»é”€å•†å…¨ç§°', 2: 'äº§å“ç¼–ç ', 3: 'äº§å“åç§°', 
                4: 'åº“å­˜æ•°é‡(å¬/ç›’)', 5: 'ç®±æ•°', 6: 'çœåŒºåç§°', 7: 'ç»é”€å•†åç§°', # Map 'å®¢æˆ·ç®€ç§°' to 'ç»é”€å•†åç§°'
                8: 'äº§å“å¤§ç±»', 9: 'äº§å“å°ç±»', 10: 'é‡é‡', 11: 'è§„æ ¼'
            }
            
            if len(df_stock.columns) >= 12:
                # Rename columns by index to ensure standard access
                new_cols = list(df_stock.columns)
                for idx, name in stock_cols_map.items():
                    new_cols[idx] = name
                df_stock.columns = new_cols
                
                # Ensure numeric 'ç®±æ•°'
                df_stock['ç®±æ•°'] = pd.to_numeric(df_stock['ç®±æ•°'], errors='coerce').fillna(0)
                
                # Clean Distributor Name (å®¢æˆ·ç®€ç§°)
                df_stock['ç»é”€å•†åç§°'] = df_stock['ç»é”€å•†åç§°'].astype(str).str.strip()
                
                # Fix PyArrow mixed type error for mixed columns
                df_stock['é‡é‡'] = df_stock['é‡é‡'].astype(str)
                df_stock['è§„æ ¼'] = df_stock['è§„æ ¼'].astype(str)
                
                # --- Smart Classification Logic (Specific Category) ---
                # Rules:
                # - é›…ç³»åˆ—ï¼šä»…å½“äº§å“åç§°åŒ…å«ã€Œé›…èµ‹/é›…è€€/é›…èˆ’/é›…æŠ¤ã€ä¹‹ä¸€æ—¶å‘½ä¸­
                # - åˆ†æ®µï¼šä»…åœ¨ã€Œäº§å“å¤§ç±»=ç¾æ€é›…æ®µç²‰ã€èŒƒå›´å†…ï¼Œä¸”äº§å“åç§°åŒ…å«ã€Œ1æ®µ/2æ®µ/3æ®µã€ä¹‹ä¸€æ—¶å‘½ä¸­
                
                # Optimized: Vectorized Logic using np.select and str.contains
                # Pre-calculate boolean masks
                name_series = df_stock['äº§å“åç§°'].astype(str)
                cat_series = df_stock['äº§å“å¤§ç±»'].astype(str)
                
                mask_ya = name_series.str.contains('é›…èµ‹|é›…è€€|é›…èˆ’|é›…æŠ¤', regex=True)
                mask_seg_cat = cat_series == 'ç¾æ€é›…æ®µç²‰'
                
                # For segments, we need to extract which segment it is. 
                # Since we need the specific string ('1æ®µ' etc), np.select is good but we need to know WHICH one.
                # Let's use extraction for segments.
                seg_extract = name_series.str.extract(r'(1æ®µ|2æ®µ|3æ®µ)')[0]
                
                # Logic:
                # 1. If 'é›…ç³»åˆ—' keyword -> return keyword. (Need to extract which one? Old logic returned the keyword itself e.g. 'é›…èµ‹')
                # 2. If 'ç¾æ€é›…æ®µç²‰' and has segment -> return segment.
                # 3. Else 'å…¶ä»–'
                
                # Extract Ya keyword
                ya_extract = name_series.str.extract(r'(é›…èµ‹|é›…è€€|é›…èˆ’|é›…æŠ¤)')[0]
                
                # Construct final series
                # Priority: Ya > Segment (if logic follows original sequence, Ya was checked first)
                
                df_stock['å…·ä½“åˆ†ç±»'] = np.where(
                    mask_ya, ya_extract,
                    np.where(
                        mask_seg_cat & seg_extract.notna(), seg_extract,
                        'å…¶ä»–'
                    )
                )
                df_stock['å…·ä½“åˆ†ç±»'] = df_stock['å…·ä½“åˆ†ç±»'].fillna('å…¶ä»–').astype(str)
                 
                # --- Filter Stock Data (Hardcoded Rules) ---
                # Rule 1: Weight (é‡é‡) must be '700', '800', '800-æ–°åŒ…è£…'
                if 'é‡é‡' in df_stock.columns:
                    valid_weights = ['700', '800', '800-æ–°åŒ…è£…']
                    # Ensure weight column is string for comparison (already done above)
                    # Handle potential float/int like 700.0 or 700
                    # We converted to string, so 700 might become '700' or '700.0' depending on source.
                    # Let's normalize: check if string contains the valid weight or exact match.
                    # Exact match is safer if data is clean. Let's try exact match first, assuming '700' in Excel is '700' or 700.
                    # If it was 700 (int), astype(str) makes it '700'.
                    df_stock = df_stock[df_stock['é‡é‡'].isin(valid_weights)]
            else:
                st.warning("åº“å­˜è¡¨ (Sheet2) åˆ—æ•°ä¸è¶³ 12 åˆ—ï¼Œæ— æ³•è¿›è¡Œåº“å­˜åˆ†æã€‚")
                df_stock = None

        # --- Process Sheet 3 (Outbound Base Table) ---
        if df_q4_raw is not None:
            df_q4_raw.columns = [str(c).strip() for c in df_q4_raw.columns]

            df_out = df_q4_raw.copy()

            month_src = df_out.columns[5] if len(df_out.columns) > 5 else None
            prov_src = df_out.columns[8] if len(df_out.columns) > 8 else None
            dist_src = df_out.columns[9] if len(df_out.columns) > 9 else None
            qty_src = df_out.columns[10] if len(df_out.columns) > 10 else None

            rename_map = {}
            if month_src: rename_map[month_src] = 'æœˆä»½'
            if prov_src: rename_map[prov_src] = 'çœåŒº'
            if dist_src: rename_map[dist_src] = 'ç»é”€å•†åç§°'
            if qty_src: rename_map[qty_src] = 'æ•°é‡(ç®±)'

            cat_src = next((c for c in df_out.columns if 'äº§å“å¤§ç±»' in str(c)), None)
            if cat_src is None:
                cat_src = next((c for c in df_out.columns if ('å¤§ç±»' in str(c)) and ('çœåŒº' not in str(c))), None)
            sub_src = next((c for c in df_out.columns if 'äº§å“å°ç±»' in str(c)), None)
            if sub_src is None:
                sub_src = next((c for c in df_out.columns if ('å°ç±»' in str(c)) and ('äº§å“' in str(c))), None)
            if cat_src is None and len(df_out.columns) > 11:
                cat_src = df_out.columns[11]
            if sub_src is None and len(df_out.columns) > 12:
                sub_src = df_out.columns[12]

            if cat_src: rename_map[cat_src] = 'äº§å“å¤§ç±»'
            if sub_src: rename_map[sub_src] = 'äº§å“å°ç±»'

            df_out = df_out.rename(columns=rename_map)
            df_out = df_out.loc[:, ~df_out.columns.duplicated()]

            if 'ç»é”€å•†åç§°' in df_out.columns:
                df_out['ç»é”€å•†åç§°'] = df_out['ç»é”€å•†åç§°'].astype(str).str.strip()
            if 'æ•°é‡(ç®±)' in df_out.columns:
                df_out['æ•°é‡(ç®±)'] = pd.to_numeric(df_out['æ•°é‡(ç®±)'], errors='coerce').fillna(0)
            if 'äº§å“å¤§ç±»' in df_out.columns:
                df_out['äº§å“å¤§ç±»'] = df_out['äº§å“å¤§ç±»'].astype(str).str.strip()
            if 'äº§å“å°ç±»' in df_out.columns:
                df_out['äº§å“å°ç±»'] = df_out['äº§å“å°ç±»'].astype(str).str.strip()

            df_q4_raw = df_out

        # --- Process Sheet 4 (Performance / Shipment) ---
        if df_perf_raw is not None:
            df_perf_raw.columns = [str(c).strip() for c in df_perf_raw.columns]
            df_perf = df_perf_raw.copy()

            col_year = next((c for c in df_perf.columns if c == 'å¹´ä»½' or 'å¹´' in c), None)
            col_month = next((c for c in df_perf.columns if c == 'æœˆä»½' or 'æœˆ' in c), None)
            col_prov = next((c for c in df_perf.columns if c == 'çœåŒº' or 'çœåŒº' in c), None)
            col_dist = next((c for c in df_perf.columns if c == 'ç»é”€å•†åç§°' or c == 'å®¢æˆ·ç®€ç§°' or 'å®¢æˆ·ç®€ç§°' in c), None)
            col_qty = next((c for c in df_perf.columns if c == 'ç®±æ•°' or c == 'åŸºæœ¬æ•°é‡' or 'æ•°é‡' in c), None)
            col_amt = next((c for c in df_perf.columns if c == 'å‘è´§é‡‘é¢' or c == 'åŸä»·é‡‘é¢' or 'é‡‘é¢' in c), None)
            col_wh = next((c for c in df_perf.columns if c == 'å‘è´§ä»“' or 'å‘è´§ä»“' in c), None)
            col_mid = next((c for c in df_perf.columns if c == 'ä¸­ç±»' or 'ä¸­ç±»' in c), None)
            col_grp = next((c for c in df_perf.columns if c == 'å½’ç±»' or 'å½’ç±»' in c), None)
            col_bigcat = next((c for c in df_perf.columns if c == 'å¤§åˆ†ç±»' or 'å¤§åˆ†ç±»' in c), None)
            col_big = next((c for c in df_perf.columns if c == 'å¤§ç±»' or 'å¤§ç±»' in c), None)
            col_small = next((c for c in df_perf.columns if c == 'å°ç±»' or 'å°ç±»' in c), None)
            col_cat = next((c for c in df_perf.columns if c == 'æœˆåˆ†æ' or 'æœˆåˆ†æ' in c), None)

            rename_perf = {}
            if col_year: rename_perf[col_year] = 'å¹´ä»½'
            if col_month: rename_perf[col_month] = 'æœˆä»½'
            if col_prov: rename_perf[col_prov] = 'çœåŒº'
            if col_dist: rename_perf[col_dist] = 'ç»é”€å•†åç§°'
            if col_qty: rename_perf[col_qty] = 'å‘è´§ç®±æ•°'
            if col_amt: rename_perf[col_amt] = 'å‘è´§é‡‘é¢'
            if col_wh: rename_perf[col_wh] = 'å‘è´§ä»“'
            if col_mid: rename_perf[col_mid] = 'ä¸­ç±»'
            if col_grp: rename_perf[col_grp] = 'å½’ç±»'
            if col_bigcat:
                rename_perf[col_bigcat] = 'å¤§åˆ†ç±»'
            elif col_cat:
                rename_perf[col_cat] = 'å¤§åˆ†ç±»'
            if col_big: rename_perf[col_big] = 'å¤§ç±»'
            if col_small: rename_perf[col_small] = 'å°ç±»'

            df_perf = df_perf.rename(columns=rename_perf)

            for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'å‘è´§ä»“', 'ä¸­ç±»', 'å½’ç±»', 'å¤§åˆ†ç±»', 'å¤§ç±»', 'å°ç±»']:
                if c in df_perf.columns:
                    df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()
            
            # --- FIX: Ensure 'ç»é”€å•†åç§°' exists ---
            if 'ç»é”€å•†åç§°' not in df_perf.columns:
                # Try to find alias
                alt_dist = next((c for c in df_perf.columns if 'å®¢æˆ·' in c or 'ç»é”€' in c), None)
                if alt_dist:
                    df_perf = df_perf.rename(columns={alt_dist: 'ç»é”€å•†åç§°'})
                else:
                    # Fallback: Create empty if absolutely necessary (but better to warn)
                    df_perf['ç»é”€å•†åç§°'] = 'æœªçŸ¥ç»é”€å•†'
            # --------------------------------------

            if 'å¤§åˆ†ç±»' in df_perf.columns and 'ç±»ç›®' not in df_perf.columns:
                df_perf['ç±»ç›®'] = df_perf['å¤§åˆ†ç±»']

            if 'å¹´ä»½' in df_perf.columns:
                # Handle "25å¹´" or "2025" strings by extracting digits
                # NOTE: Use regex extraction to handle "25å¹´" -> "25"
                df_perf['å¹´ä»½'] = df_perf['å¹´ä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                # Normalize 2-digit years to 4-digit (e.g. 25 -> 2025)
                df_perf['å¹´ä»½'] = df_perf['å¹´ä»½'].apply(lambda y: y + 2000 if 0 < y < 100 else y)

            if 'æœˆä»½' in df_perf.columns:
                 # Handle "1æœˆ" or "01" strings
                df_perf['æœˆä»½'] = df_perf['æœˆä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if 'å‘è´§ç®±æ•°' in df_perf.columns:
                df_perf['å‘è´§ç®±æ•°'] = pd.to_numeric(df_perf['å‘è´§ç®±æ•°'], errors='coerce').fillna(0)
            if 'å‘è´§é‡‘é¢' in df_perf.columns:
                df_perf['å‘è´§é‡‘é¢'] = pd.to_numeric(df_perf['å‘è´§é‡‘é¢'], errors='coerce').fillna(0)

            if 'å¹´ä»½' in df_perf.columns and 'æœˆä»½' in df_perf.columns:
                df_perf = df_perf[(df_perf['å¹´ä»½'] > 0) & (df_perf['æœˆä»½'].between(1, 12))]
                df_perf['å¹´æœˆ'] = pd.to_datetime(df_perf['å¹´ä»½'].astype(str) + '-' + df_perf['æœˆä»½'].astype(str).str.zfill(2) + '-01')
            else:
                df_perf['å¹´æœˆ'] = pd.NaT

            df_perf_raw = df_perf

        # --- Process Sheet 5 (Target) ---
        df_target_raw = None
        try:
            if len(xl.sheet_names) > 4:
                df_target_raw = xl.parse(4)
                df_target_raw.columns = [str(c).strip() for c in df_target_raw.columns]
                
                # Expected Cols: D(å“ç±»), E(æœˆä»½), F(ä»»åŠ¡é‡) -> Index 3, 4, 5
                # Rename by index to be safe
                rename_target = {}
                if len(df_target_raw.columns) > 3: rename_target[df_target_raw.columns[3]] = 'å“ç±»'
                if len(df_target_raw.columns) > 4: rename_target[df_target_raw.columns[4]] = 'æœˆä»½'
                if len(df_target_raw.columns) > 5: rename_target[df_target_raw.columns[5]] = 'ä»»åŠ¡é‡'
                
                df_target_raw = df_target_raw.rename(columns=rename_target)
                
                # Basic Cleaning
                if 'æœˆä»½' in df_target_raw.columns:
                     # Handle "1æœˆ" or "01" strings
                    df_target_raw['æœˆä»½'] = df_target_raw['æœˆä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                if 'ä»»åŠ¡é‡' in df_target_raw.columns:
                    df_target_raw['ä»»åŠ¡é‡'] = pd.to_numeric(df_target_raw['ä»»åŠ¡é‡'], errors='coerce').fillna(0)
            else:
                 debug_logs.append("Warning: Sheet5 (Target) not found.")
        except Exception as e:
            debug_logs.append(f"Error parsing Sheet5: {e}")
            df_target_raw = None

        return df, month_cols, df_stock, df_q4_raw, df_perf_raw, df_target_raw, debug_logs
        
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None, None, None, None, None, None, [str(e)]

@st.cache_data(ttl=3600)
def load_data_v3(file_bytes: bytes, file_name: str):
    debug_logs = []
    try:
        file_name_lower = (file_name or "").lower()
        bio = io.BytesIO(file_bytes)
        
        # Init Returns
        df = None
        month_cols = []
        df_stock = None
        df_q4_raw = None
        df_perf_raw = None
        df_target_raw = None
        df_scan_raw = None

        if file_name_lower.endswith('.csv'):
            df = pd.read_csv(bio, encoding='gb18030')
        else:
            xl = pd.ExcelFile(bio)
            debug_logs.append(f"Sheet Names: {xl.sheet_names}")
            
            # Sheet 1: Sales
            if len(xl.sheet_names) > 0: df = xl.parse(0)
            
            # Sheet 2: Stock
            if len(xl.sheet_names) > 1: df_stock = xl.parse(1)
            
            # Sheet 3: Outbound (Q4)
            if len(xl.sheet_names) > 2: df_q4_raw = xl.parse(2)
            
            # Sheet 4: Performance
            if len(xl.sheet_names) > 3:
                preferred = next((s for s in xl.sheet_names if 'sheet4' in str(s).strip().lower()), None)
                candidate_names = [preferred] if preferred else []
                candidate_names += [s for s in xl.sheet_names if s not in candidate_names]
                for sname in candidate_names:
                    try:
                        tmp_header = xl.parse(sname, nrows=0)
                        cols = [str(c).strip() for c in tmp_header.columns]
                        key_hits = sum(1 for k in ['å¹´ä»½', 'æœˆä»½', 'çœåŒº'] if any(k in c for c in cols))
                        signal_hits = sum(1 for k in ['å‘è´§ä»“', 'åŸä»·é‡‘é¢', 'åŸºæœ¬æ•°é‡', 'å¤§åˆ†ç±»', 'æœˆåˆ†æ', 'å®¢æˆ·ç®€ç§°'] if any(k in c for c in cols))
                        if key_hits >= 2 and signal_hits >= 1:
                            df_perf_raw = xl.parse(sname)
                            debug_logs.append(f"-> MATCHED Sheet4: {sname}")
                            break
                    except: continue
            
            # Sheet 5: Target
            if len(xl.sheet_names) > 4: df_target_raw = xl.parse(4)

            # Sheet 6: Scan Data
            if len(xl.sheet_names) > 5: df_scan_raw = xl.parse(5)

        # --- Process Sheet 1 (Sales) ---
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            
            # Identify Month Columns
            is_long_format = False
            time_col = None
            if len(df.columns) > 5:
                col_f = df.columns[5]
                sample_vals = df[col_f].dropna().head(10).astype(str).tolist()
                if any('æœˆ' in v for v in sample_vals):
                    is_long_format = True
                    time_col = col_f
            
            if is_long_format:
                col_prov = df.columns[8] if len(df.columns) > 8 else None
                col_dist = df.columns[9] if len(df.columns) > 9 else None
                col_qty = df.columns[10] if len(df.columns) > 10 else None
                
                if col_prov is None: col_prov = next((c for c in df.columns if 'çœ' in c), None)
                if col_dist is None: col_dist = next((c for c in df.columns if 'ç»é”€' in c or 'å®¢æˆ·' in c), None)
                if col_qty is None: col_qty = next((c for c in df.columns if 'æ•°' in c or 'Qty' in c or 'ç®±' in c), None)
                col_store = next((c for c in df.columns if 'é—¨åº—' in c), None)
                
                if col_prov and col_dist and col_qty and time_col:
                    df[col_qty] = pd.to_numeric(df[col_qty], errors='coerce').fillna(0)
                    pivot_index = [col_prov, col_dist]
                    if col_store: pivot_index.append(col_store)
                    df_wide = df.pivot_table(index=pivot_index, columns=time_col, values=col_qty, aggfunc='sum').reset_index()
                    if not col_store: df_wide['é—¨åº—åç§°'] = df_wide[col_dist]
                    df = df_wide
                    df.columns = [str(c).strip() for c in df.columns]
            
            rename_map = {}
            if 'å“ç‰ŒçœåŒºåç§°' in df.columns: rename_map['å“ç‰ŒçœåŒºåç§°'] = 'çœåŒº'
            if 'ç»é”€å•†åç§°' not in df.columns and len(df.columns) > 1: rename_map[df.columns[1]] = 'ç»é”€å•†åç§°'
            if 'é—¨åº—åç§°' not in df.columns and len(df.columns) > 2: rename_map[df.columns[2]] = 'é—¨åº—åç§°'
            df = df.rename(columns=rename_map)
            
            required = ['çœåŒº', 'ç»é”€å•†åç§°', 'é—¨åº—åç§°']
            for req in required:
                if req not in df.columns:
                    if len(df.columns) >= 3:
                        df.columns.values[0] = 'çœåŒº'
                        df.columns.values[1] = 'ç»é”€å•†åç§°'
                        df.columns.values[2] = 'é—¨åº—åç§°'
            
            month_cols = [c for c in df.columns if 'æœˆ' in c and c not in required]
            for col in month_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
            df['æ€»å‡ºåº“æ•°'] = df[month_cols].sum(axis=1)
            df['æœ‰æ•ˆæœˆä»½æ•°'] = df[month_cols].gt(0).sum(axis=1).astype(int)
            df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] = np.where(df['æœ‰æ•ˆæœˆä»½æ•°'] > 0, df['æ€»å‡ºåº“æ•°'] / df['æœ‰æ•ˆæœˆä»½æ•°'], 0.0)
            
            conditions = [df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 4, (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 2) & (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] < 4), (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] >= 1) & (df['å¹³å‡æ¯æœˆå‡ºåº“æ•°'] < 2)]
            choices = ['Aç±»é—¨åº— (>=4)', 'Bç±»é—¨åº— (2-4)', 'Cç±»é—¨åº— (1-2)']
            df['é—¨åº—åˆ†ç±»'] = np.select(conditions, choices, default='Dç±»é—¨åº— (<1)')

        # --- Process Sheet 2 (Stock) ---
        if df_stock is not None:
            df_stock.columns = [str(c).strip() for c in df_stock.columns]
            stock_cols_map = {
                0: 'ç»é”€å•†ç¼–ç ', 1: 'ç»é”€å•†å…¨ç§°', 2: 'äº§å“ç¼–ç ', 3: 'äº§å“åç§°', 
                4: 'åº“å­˜æ•°é‡(å¬/ç›’)', 5: 'ç®±æ•°', 6: 'çœåŒºåç§°', 7: 'ç»é”€å•†åç§°', # 7=å®¢æˆ·ç®€ç§°
                8: 'äº§å“å¤§ç±»', 9: 'äº§å“å°ç±»', 10: 'é‡é‡', 11: 'è§„æ ¼'
            }
            if len(df_stock.columns) >= 12:
                new_cols = list(df_stock.columns)
                for idx, name in stock_cols_map.items():
                    if idx < len(new_cols): new_cols[idx] = name
                df_stock.columns = new_cols
                df_stock['ç®±æ•°'] = pd.to_numeric(df_stock['ç®±æ•°'], errors='coerce').fillna(0)
                
                # CLEAN DISTRIBUTOR NAME STRICTLY
                if 'ç»é”€å•†åç§°' in df_stock.columns:
                    df_stock['ç»é”€å•†åç§°'] = df_stock['ç»é”€å•†åç§°'].astype(str).str.replace(r'\s+', '', regex=True)
                
                df_stock['é‡é‡'] = df_stock['é‡é‡'].astype(str)
                df_stock['è§„æ ¼'] = df_stock['è§„æ ¼'].astype(str)
                
                name_series = df_stock['äº§å“åç§°'].astype(str)
                mask_ya = name_series.str.contains('é›…èµ‹|é›…è€€|é›…èˆ’|é›…æŠ¤', regex=True)
                mask_seg_cat = df_stock['äº§å“å¤§ç±»'].astype(str) == 'ç¾æ€é›…æ®µç²‰'
                seg_extract = name_series.str.extract(r'(1æ®µ|2æ®µ|3æ®µ)')[0]
                ya_extract = name_series.str.extract(r'(é›…èµ‹|é›…è€€|é›…èˆ’|é›…æŠ¤)')[0]
                
                df_stock['å…·ä½“åˆ†ç±»'] = np.where(mask_ya, ya_extract, np.where(mask_seg_cat & seg_extract.notna(), seg_extract, 'å…¶ä»–'))
                df_stock['å…·ä½“åˆ†ç±»'] = df_stock['å…·ä½“åˆ†ç±»'].fillna('å…¶ä»–').astype(str)
                 
                if 'é‡é‡' in df_stock.columns:
                    valid_weights = ['700', '800', '800-æ–°åŒ…è£…']
                    df_stock = df_stock[df_stock['é‡é‡'].isin(valid_weights)]
            else:
                df_stock = None

        # --- Process Sheet 3 (Outbound) FIX ---
        if df_q4_raw is not None:
            # Deduplicate
            cols = pd.Series(df_q4_raw.columns)
            for dup in cols[cols.duplicated()].unique(): 
                cols[cols[cols == dup].index.values.tolist()] = [dup + '.' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]
            df_q4_raw.columns = cols
            
            df_out = df_q4_raw.copy()
            
            # Map Indices (User Requirement: +8 shift)
            # M(12)=Year, N(13)=Month, Q(16)=Prov, R(17)=Dist(CustomerAbbr), S(18)=Qty, U(20)=SubCat
            idx_map = {
                12: 'å¹´ä»½',
                13: 'æœˆä»½',
                16: 'çœåŒº',
                17: 'ç»é”€å•†åç§°',
                18: 'æ•°é‡(ç®±)',
                20: 'äº§å“å°ç±»',
                19: 'äº§å“å¤§ç±»'
            }
            curr_cols = list(df_out.columns)
            
            # Avoid Name Collision: Rename existing columns that clash with target names
            target_names = list(idx_map.values())
            for i, c in enumerate(curr_cols):
                if c in target_names and i not in idx_map:
                    new_n = f"{c}_old_{i}"
                    df_out.rename(columns={c: new_n}, inplace=True)
                    debug_logs.append(f"Renamed collision '{c}' -> '{new_n}'")
            
            # Refresh columns after collision avoidance
            curr_cols = list(df_out.columns)
            
            for idx, name in idx_map.items():
                if idx < len(curr_cols):
                    df_out.rename(columns={curr_cols[idx]: name}, inplace=True)
            
            # Clean Dist Name
            if 'ç»é”€å•†åç§°' in df_out.columns:
                 df_out['ç»é”€å•†åç§°'] = df_out['ç»é”€å•†åç§°'].astype(str).str.replace(r'\s+', '', regex=True)
                 debug_logs.append(f"Sheet3 Dist Sample: {df_out['ç»é”€å•†åç§°'].head(3).tolist()}")

            if 'æ•°é‡(ç®±)' in df_out.columns:
                df_out['æ•°é‡(ç®±)'] = pd.to_numeric(df_out['æ•°é‡(ç®±)'], errors='coerce').fillna(0)
            
            if 'äº§å“å¤§ç±»' in df_out.columns: df_out['äº§å“å¤§ç±»'] = df_out['äº§å“å¤§ç±»'].astype(str).str.strip()
            if 'äº§å“å°ç±»' in df_out.columns: df_out['äº§å“å°ç±»'] = df_out['äº§å“å°ç±»'].astype(str).str.strip()
            
            # Clean Year
            if 'å¹´ä»½' in df_out.columns:
                # Extract digits and normalize
                df_out['å¹´ä»½'] = df_out['å¹´ä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                # Normalize 25 -> 2025
                df_out['å¹´ä»½'] = df_out['å¹´ä»½'].apply(lambda y: y + 2000 if 20 <= y < 100 else y)

            df_q4_raw = df_out

        # --- Process Sheet 4 (Perf) ---
        if df_perf_raw is not None:
            df_perf_raw.columns = [str(c).strip() for c in df_perf_raw.columns]
            df_perf = df_perf_raw.copy()
            col_year = next((c for c in df_perf.columns if str(c).strip() == 'å¹´ä»½' or ('å¹´' in str(c))), None)
            col_month = next((c for c in df_perf.columns if str(c).strip() == 'æœˆä»½' or ('æœˆ' in str(c))), None)
            col_prov = next((c for c in df_perf.columns if str(c).strip() == 'çœåŒº' or ('çœåŒº' in str(c)) or (str(c).strip() == 'çœ')), None)
            col_dist = next((c for c in df_perf.columns if str(c).strip() == 'ç»é”€å•†åç§°' or str(c).strip() == 'å®¢æˆ·ç®€ç§°' or ('å®¢æˆ·ç®€ç§°' in str(c)) or ('ç»é”€å•†' in str(c))), None)
            col_qty = next((c for c in df_perf.columns if str(c).strip() == 'å‘è´§ç®±æ•°' or str(c).strip() == 'ç®±æ•°' or str(c).strip() == 'åŸºæœ¬æ•°é‡' or ('æ•°é‡' in str(c)) or ('ç®±' in str(c))), None)
            col_amt = next((c for c in df_perf.columns if str(c).strip() == 'å‘è´§é‡‘é¢' or str(c).strip() == 'åŸä»·é‡‘é¢' or ('é‡‘é¢' in str(c))), None)
            col_wh = next((c for c in df_perf.columns if str(c).strip() == 'å‘è´§ä»“' or ('å‘è´§ä»“' in str(c))), None)
            col_mid = next((c for c in df_perf.columns if str(c).strip() == 'ä¸­ç±»' or ('ä¸­ç±»' in str(c))), None)
            col_grp = next((c for c in df_perf.columns if str(c).strip() == 'å½’ç±»' or ('å½’ç±»' in str(c))), None)
            col_bigcat = next((c for c in df_perf.columns if str(c).strip() == 'å¤§åˆ†ç±»' or ('å¤§åˆ†ç±»' in str(c))), None)
            col_big = next((c for c in df_perf.columns if str(c).strip() == 'å¤§ç±»' or ('å¤§ç±»' in str(c))), None)
            col_small = next((c for c in df_perf.columns if str(c).strip() == 'å°ç±»' or ('å°ç±»' in str(c))), None)
            col_cat = next((c for c in df_perf.columns if str(c).strip() == 'æœˆåˆ†æ' or ('æœˆåˆ†æ' in str(c))), None)

            rename_perf = {}
            if col_year: rename_perf[col_year] = 'å¹´ä»½'
            if col_month: rename_perf[col_month] = 'æœˆä»½'
            if col_prov: rename_perf[col_prov] = 'çœåŒº'
            if col_dist: rename_perf[col_dist] = 'ç»é”€å•†åç§°'
            if col_qty: rename_perf[col_qty] = 'å‘è´§ç®±æ•°'
            if col_amt: rename_perf[col_amt] = 'å‘è´§é‡‘é¢'
            if col_wh: rename_perf[col_wh] = 'å‘è´§ä»“'
            if col_mid: rename_perf[col_mid] = 'ä¸­ç±»'
            if col_grp: rename_perf[col_grp] = 'å½’ç±»'
            if col_bigcat:
                rename_perf[col_bigcat] = 'å¤§åˆ†ç±»'
            elif col_cat:
                rename_perf[col_cat] = 'å¤§åˆ†ç±»'
            if col_big: rename_perf[col_big] = 'å¤§ç±»'
            if col_small: rename_perf[col_small] = 'å°ç±»'

            df_perf = df_perf.rename(columns=rename_perf)

            if 'ç»é”€å•†åç§°' not in df_perf.columns:
                alt_dist = next((c for c in df_perf.columns if ('å®¢æˆ·' in str(c)) or ('ç»é”€' in str(c))), None)
                if alt_dist:
                    df_perf = df_perf.rename(columns={alt_dist: 'ç»é”€å•†åç§°'})
                else:
                    df_perf['ç»é”€å•†åç§°'] = ''
                    debug_logs.append("Warning: Sheet4 missing distributor column; set 'ç»é”€å•†åç§°' to empty.")

            for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'å‘è´§ä»“', 'ä¸­ç±»', 'å½’ç±»', 'å¤§åˆ†ç±»', 'å¤§ç±»', 'å°ç±»']:
                if c in df_perf.columns:
                    df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()

            if 'å¹´ä»½' in df_perf.columns:
                df_perf['å¹´ä»½'] = df_perf['å¹´ä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                df_perf['å¹´ä»½'] = df_perf['å¹´ä»½'].apply(lambda y: y + 2000 if 0 < y < 100 else y)
            if 'æœˆä»½' in df_perf.columns:
                df_perf['æœˆä»½'] = df_perf['æœˆä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if 'å‘è´§ç®±æ•°' in df_perf.columns:
                df_perf['å‘è´§ç®±æ•°'] = pd.to_numeric(df_perf['å‘è´§ç®±æ•°'], errors='coerce').fillna(0)
            if 'å‘è´§é‡‘é¢' in df_perf.columns:
                df_perf['å‘è´§é‡‘é¢'] = pd.to_numeric(df_perf['å‘è´§é‡‘é¢'], errors='coerce').fillna(0)

            if 'å¹´ä»½' in df_perf.columns and 'æœˆä»½' in df_perf.columns:
                df_perf = df_perf[(df_perf['å¹´ä»½'] > 0) & (df_perf['æœˆä»½'].between(1, 12))]
                df_perf['å¹´æœˆ'] = pd.to_datetime(
                    df_perf['å¹´ä»½'].astype(str) + '-' + df_perf['æœˆä»½'].astype(str).str.zfill(2) + '-01',
                    errors='coerce'
                )
            else:
                df_perf['å¹´æœˆ'] = pd.NaT
            df_perf_raw = df_perf

        # --- Process Sheet 5 (Target) ---
        if df_target_raw is not None:
            df_target_raw.columns = [str(c).strip() for c in df_target_raw.columns]
            rename_target = {}
            if len(df_target_raw.columns) > 3: rename_target[df_target_raw.columns[3]] = 'å“ç±»'
            if len(df_target_raw.columns) > 4: rename_target[df_target_raw.columns[4]] = 'æœˆä»½'
            if len(df_target_raw.columns) > 5: rename_target[df_target_raw.columns[5]] = 'ä»»åŠ¡é‡'
            df_target_raw = df_target_raw.rename(columns=rename_target)
            if 'æœˆä»½' in df_target_raw.columns:
                df_target_raw['æœˆä»½'] = df_target_raw['æœˆä»½'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if 'ä»»åŠ¡é‡' in df_target_raw.columns:
                df_target_raw['ä»»åŠ¡é‡'] = pd.to_numeric(df_target_raw['ä»»åŠ¡é‡'], errors='coerce').fillna(0)

        # --- Process Sheet 6 (Scan Data) ---
        if df_scan_raw is not None:
            df0 = df_scan_raw

            def _col(idx: int):
                if idx < df0.shape[1]:
                    return df0.iloc[:, idx]
                return pd.Series([None] * len(df0))

            df_scan_raw = pd.DataFrame({
                "é—¨åº—åç§°": _col(1),
                "ç»é”€å•†åç§°": _col(18),
                "çœåŒº": _col(17),
                "äº§å“å¤§ç±»": _col(19),
                "äº§å“å°ç±»": _col(20),
                "ç»çº¬åº¦": _col(12),
                "å¹´ä»½": _col(13),
                "æœˆä»½": _col(14),
                "æ—¥": _col(15),
            })

            df_scan_raw["å¹´ä»½"] = df_scan_raw["å¹´ä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
            df_scan_raw["å¹´ä»½"] = df_scan_raw["å¹´ä»½"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
            df_scan_raw["æœˆä»½"] = df_scan_raw["æœˆä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
            df_scan_raw["æ—¥"] = df_scan_raw["æ—¥"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)

            for c in ["é—¨åº—åç§°", "çœåŒº", "ç»é”€å•†åç§°", "äº§å“å¤§ç±»", "äº§å“å°ç±»"]:
                df_scan_raw[c] = df_scan_raw[c].fillna("").astype(str).str.strip()

            coords = df_scan_raw["ç»çº¬åº¦"].apply(_parse_lon_lat)
            df_scan_raw["ç»åº¦"] = coords.apply(lambda x: x[0])
            df_scan_raw["çº¬åº¦"] = coords.apply(lambda x: x[1])

        return df, month_cols, df_stock, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs
        
    except Exception as e:
        import traceback
        return None, None, None, None, None, None, None, [f"Error: {str(e)}", traceback.format_exc()]

@st.cache_data(ttl=3600)
def load_builtin_perf_2025():
    base_dir = os.path.dirname(__file__) if "__file__" in globals() else os.getcwd()
    path = os.path.join(base_dir, "åˆ†æåº•è¡¨0115.xlsx")
    if not os.path.exists(path):
        return pd.DataFrame()
    xl = pd.ExcelFile(path)
    sheet_name = next((s for s in xl.sheet_names if "å‘è´§" in str(s)), None)
    if sheet_name is None and len(xl.sheet_names) > 3:
        sheet_name = xl.sheet_names[3]
    if sheet_name is None:
        return pd.DataFrame()
    df0 = xl.parse(sheet_name)
    df0.columns = [str(c).strip() for c in df0.columns]
    col_year = next((c for c in df0.columns if str(c).strip() == "å¹´ä»½" or "å¹´" in str(c)), None)
    col_month = next((c for c in df0.columns if str(c).strip() == "æœˆä»½" or "æœˆ" in str(c)), None)
    col_prov = next((c for c in df0.columns if "çœåŒº" in str(c)), None)
    col_dist = next((c for c in df0.columns if "å®¢æˆ·ç®€ç§°" in str(c)), None) or next((c for c in df0.columns if "è´­è´§å•ä½" in str(c)), None)
    col_qty = next((c for c in df0.columns if "åŸºæœ¬æ•°é‡" in str(c)), None) or next((c for c in df0.columns if "ç®±" in str(c) or "æ•°é‡" in str(c)), None)
    col_amt = next((c for c in df0.columns if "åŸä»·é‡‘é¢" in str(c)), None) or next((c for c in df0.columns if "é‡‘é¢" in str(c)), None)
    col_wh = next((c for c in df0.columns if "å‘è´§ä»“" in str(c)), None)
    col_grp = next((c for c in df0.columns if "å½’ç±»" in str(c)), None)
    col_bigcat = next((c for c in df0.columns if str(c).strip() == "å¤§åˆ†ç±»"), None) or next((c for c in df0.columns if "æœˆåˆ†æ" in str(c)), None)
    col_big = next((c for c in df0.columns if str(c).strip() == "å¤§ç±»"), None)
    col_mid = next((c for c in df0.columns if str(c).strip() == "ä¸­ç±»"), None)
    col_small = next((c for c in df0.columns if str(c).strip() == "å°ç±»"), None)

    df = pd.DataFrame()
    if col_year is not None: df["å¹´ä»½"] = df0[col_year]
    if col_month is not None: df["æœˆä»½"] = df0[col_month]
    if col_prov is not None: df["çœåŒº"] = df0[col_prov]
    if col_dist is not None: df["ç»é”€å•†åç§°"] = df0[col_dist]
    if col_qty is not None: df["å‘è´§ç®±æ•°"] = df0[col_qty]
    if col_amt is not None: df["å‘è´§é‡‘é¢"] = df0[col_amt]
    if col_wh is not None: df["å‘è´§ä»“"] = df0[col_wh]
    if col_mid is not None: df["ä¸­ç±»"] = df0[col_mid]
    if col_grp is not None: df["å½’ç±»"] = df0[col_grp]
    if col_bigcat is not None: df["å¤§åˆ†ç±»"] = df0[col_bigcat]
    if col_big is not None: df["å¤§ç±»"] = df0[col_big]
    if col_small is not None: df["å°ç±»"] = df0[col_small]

    for c in ["çœåŒº", "ç»é”€å•†åç§°", "å‘è´§ä»“", "ä¸­ç±»", "å½’ç±»", "å¤§åˆ†ç±»", "å¤§ç±»", "å°ç±»"]:
        if c in df.columns:
            df[c] = df[c].fillna("").astype(str).str.strip()
    if "å¹´ä»½" in df.columns:
        df["å¹´ä»½"] = df["å¹´ä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["å¹´ä»½"] = df["å¹´ä»½"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
    if "æœˆä»½" in df.columns:
        df["æœˆä»½"] = df["æœˆä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
    if "å‘è´§ç®±æ•°" in df.columns:
        df["å‘è´§ç®±æ•°"] = pd.to_numeric(df["å‘è´§ç®±æ•°"], errors="coerce").fillna(0)
    if "å‘è´§é‡‘é¢" in df.columns:
        df["å‘è´§é‡‘é¢"] = pd.to_numeric(df["å‘è´§é‡‘é¢"], errors="coerce").fillna(0)
    if "å¹´ä»½" in df.columns and "æœˆä»½" in df.columns:
        df = df[(df["å¹´ä»½"] == 2025) & (df["æœˆä»½"].between(1, 12))]
        df["å¹´æœˆ"] = pd.to_datetime(df["å¹´ä»½"].astype(str) + "-" + df["æœˆä»½"].astype(str).str.zfill(2) + "-01", errors="coerce")
    else:
        return pd.DataFrame()
    return df

@st.cache_data(ttl=3600)
def load_builtin_scan_2025():
    # Attempt to load built-in file if it exists, otherwise return empty
    base_dir = os.path.dirname(__file__) if "__file__" in globals() else os.getcwd()
    path = os.path.join(base_dir, "åˆ†æåº•è¡¨0115.xlsx")
    if not os.path.exists(path):
        return pd.DataFrame()
    
    try:
        xl = pd.ExcelFile(path)
        if len(xl.sheet_names) <= 5:
            return pd.DataFrame()

        df0 = xl.parse(5)
        if df0 is None or df0.empty:
            return pd.DataFrame()

        def _col(idx: int):
            if idx < df0.shape[1]:
                return df0.iloc[:, idx]
            return pd.Series([None] * len(df0))

        df = pd.DataFrame({
            "é—¨åº—åç§°": _col(1),
            "ç»é”€å•†åç§°": _col(18),
            "çœåŒº": _col(17),
            "äº§å“å¤§ç±»": _col(19),
            "äº§å“å°ç±»": _col(20),
            "ç»çº¬åº¦": _col(12),
            "å¹´ä»½": _col(13),
            "æœˆä»½": _col(14),
            "æ—¥": _col(15),
        })

        df["å¹´ä»½"] = df["å¹´ä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["å¹´ä»½"] = df["å¹´ä»½"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
        df["æœˆä»½"] = df["æœˆä»½"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["æ—¥"] = df["æ—¥"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)

        for c in ["é—¨åº—åç§°", "çœåŒº", "ç»é”€å•†åç§°", "äº§å“å¤§ç±»", "äº§å“å°ç±»"]:
            df[c] = df[c].fillna("").astype(str).str.strip()

        coords = df["ç»çº¬åº¦"].apply(_parse_lon_lat)
        df["ç»åº¦"] = coords.apply(lambda x: x[0])
        df["çº¬åº¦"] = coords.apply(lambda x: x[1])

        df = df[df["å¹´ä»½"] == 2025]
        return df
    except Exception:
        return pd.DataFrame()

# -----------------------------------------------------------------------------
# 4. Layout
# -----------------------------------------------------------------------------

st.markdown("## ğŸ› ï¸ æ•°æ®æ§åˆ¶å°")

if 'hc_mode' not in st.session_state:
    st.session_state.hc_mode = False

st.toggle("é«˜å¯¹æ¯”æ¨¡å¼", key="hc_mode")

if st.session_state.get("hc_mode"):
    st.markdown("""
    <style>
      :root {
        --tbl-header-bg: #0B57D0;
        --tbl-header-bg-hover: #0846AB;
        --tbl-header-border: #06357F;
        --tbl-header-fg: #FFFFFF;
        --tbl-header-icon: #FFFFFF;
        --tbl-header-shadow: 0 10px 22px rgba(0, 0, 0, 0.38);
      }
    </style>
    """, unsafe_allow_html=True)

if 'exp_upload' not in st.session_state:
    st.session_state.exp_upload = True
if 'exp_filter' not in st.session_state:
    st.session_state.exp_filter = True

with st.expander("ğŸ“¥ æ•°æ®å¯¼å…¥", expanded=st.session_state.exp_upload):
    uploaded_file = st.file_uploader("å¯¼å…¥æ•°æ®è¡¨ (Excel/CSV)", type=['xlsx', 'xls', 'csv'], key="main_uploader")

if uploaded_file is None:
    st.markdown(
        """
        <div style='text-align: center; padding: 60px 20px; background-color: white; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 40px;'>
            <h1 style='color: #4096ff; margin-bottom: 16px;'>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ç¾æ€é›…æ•°æ®åˆ†æç³»ç»Ÿ</h1>
            <p style='color: #666; font-size: 16px; margin-bottom: 0;'>è¯·ä¸Šä¼  Excel æ•°æ®æ–‡ä»¶ä»¥è§£é”å®Œæ•´åˆ†æé¢æ¿</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    # st.stop()  # Streamlit Cloud Health Check Fix: Avoid blocking the app here

# Main Logic
if uploaded_file:
    uploaded_name = uploaded_file.name
    cached_bytes = st.session_state.get("_uploaded_bytes")
    cached_sig = st.session_state.get("_uploaded_sig")
    cached_name = st.session_state.get("_uploaded_name")

    if cached_bytes is None or cached_sig is None or cached_name != uploaded_name:
        cached_bytes = uploaded_file.getvalue()
        cached_sig = hashlib.md5(cached_bytes).hexdigest()
        st.session_state["_uploaded_bytes"] = cached_bytes
        st.session_state["_uploaded_sig"] = cached_sig
        st.session_state["_uploaded_name"] = uploaded_name

    if st.session_state.get("_active_file_sig") != cached_sig:
        st.session_state["_active_file_sig"] = cached_sig
        st.session_state["run_analysis"] = False

    parsed_cache = st.session_state.get("_parsed_cache", {})
    if cached_sig in parsed_cache:
        # Check if cache is old version (7 elements) or new version (8 elements)
        cache_val = parsed_cache[cached_sig]
        if len(cache_val) == 8:
            df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = cache_val
        else:
            # Re-parse if cache format mismatch (Old cache had 7 items)
            df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = load_data_v3(cached_bytes, uploaded_name)
            parsed_cache[cached_sig] = (df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs)
            st.session_state["_parsed_cache"] = parsed_cache
    else:
        df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = load_data_v3(cached_bytes, uploaded_name)
        parsed_cache[cached_sig] = (df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs)
        if len(parsed_cache) > 2:
            for k in list(parsed_cache.keys())[:-2]:
                parsed_cache.pop(k, None)
        st.session_state["_parsed_cache"] = parsed_cache

    df_perf_2025 = load_builtin_perf_2025()
    if df_perf_2025 is not None and not df_perf_2025.empty:
        if df_perf_raw is None or getattr(df_perf_raw, "empty", True):
            df_perf_raw = df_perf_2025.copy()
        else:
            years = pd.to_numeric(df_perf_raw.get("å¹´ä»½", pd.Series(dtype=float)), errors="coerce")
            if not bool((years == 2025).any()):
                df_perf_raw = pd.concat([df_perf_2025, df_perf_raw], ignore_index=True, sort=False)
                
    df_scan_2025 = load_builtin_scan_2025()
    if df_scan_2025 is not None and not df_scan_2025.empty:
        if df_scan_raw is None or getattr(df_scan_raw, "empty", True):
            df_scan_raw = df_scan_2025.copy()
        else:
            years_s = pd.to_numeric(df_scan_raw.get("å¹´ä»½", pd.Series(dtype=float)), errors="coerce")
            if not bool((years_s == 2025).any()):
                df_scan_raw = pd.concat([df_scan_2025, df_scan_raw], ignore_index=True, sort=False)

    if df_raw is None and debug_logs:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ã€‚è¯¦ç»†æ—¥å¿—å¦‚ä¸‹ï¼š")
        st.text("\n".join(debug_logs))

    if df_raw is not None:
        # --- Filters Area ---
        with st.expander("ğŸ” ç­›é€‰æœç´¢", expanded=st.session_state.exp_filter):
            # Province Filter
            provinces = ['å…¨éƒ¨'] + sorted(list(df_raw['çœåŒº'].unique()))
            sel_prov = st.selectbox("é€‰æ‹©çœåŒº (Province)", provinces)
            
            # Distributor Filter
            if sel_prov != 'å…¨éƒ¨':
                dist_options = ['å…¨éƒ¨'] + sorted(list(df_raw[df_raw['çœåŒº']==sel_prov]['ç»é”€å•†åç§°'].unique()))
            else:
                dist_options = ['å…¨éƒ¨'] + sorted(list(df_raw['ç»é”€å•†åç§°'].unique()))
            sel_dist = st.selectbox("é€‰æ‹©ç»é”€å•† (Distributor)", dist_options)

            cat_set = set()
            for _df, _col in [
                (df_perf_raw, 'å¤§åˆ†ç±»'),
                (df_perf_raw, 'äº§å“å¤§ç±»'),
                (df_q4_raw, 'äº§å“å¤§ç±»'),
                (df_stock_raw, 'äº§å“å¤§ç±»'),
                (df_scan_raw, 'äº§å“å¤§ç±»'),
            ]:
                if _df is not None and not getattr(_df, "empty", True) and _col in _df.columns:
                    cat_set |= set(_df[_col].fillna('').astype(str).str.strip().tolist())
            cat_options = ['å…¨éƒ¨'] + sorted([x for x in cat_set if x])
            sel_cat = st.selectbox("é€‰æ‹©äº§å“å¤§ç±» (Category)", cat_options, key="main_sel_cat")
        
        # Apply Filters
        df = df_raw.copy()
        if sel_prov != 'å…¨éƒ¨':
            df = df[df['çœåŒº'] == sel_prov]
        if sel_dist != 'å…¨éƒ¨':
            df = df[df['ç»é”€å•†åç§°'] == sel_dist]
            
        if not st.session_state.get('run_analysis', False):
            st.markdown("### âœ… æ•°æ®å·²åŠ è½½")
            st.caption("ç‚¹å‡»ã€Œå¼€å§‹åˆ†æ ğŸš€ã€è¿›å…¥åˆ†æé¡µé¢ã€‚")
            if st.button("å¼€å§‹åˆ†æ ğŸš€", type="primary", key="main_start_analysis"):
                st.session_state['run_analysis'] = True

        # Share / external-access UI intentionally removed
            
        if st.session_state.get('run_analysis', False):
            
            # --- Header ---
            st.title("ğŸ“ˆ ç¾æ€é›…æ•°æ®åˆ†æç³»ç»Ÿ")
            st.markdown(f"å½“å‰æ•°æ®èŒƒå›´: **{sel_prov}** / **{sel_dist}** | åŒ…å« **{len(df)}** å®¶é—¨åº—")
            
            # --- Tabs ---
            tab1, tab7, tab6, tab_out, tab_scan, tab3, tab_other = st.tabs(["ğŸ“Š æ ¸å¿ƒæ¦‚è§ˆ", "ğŸš€ ä¸šç»©åˆ†æ", "ğŸ“¦ åº“å­˜åˆ†æ", "ğŸšš å‡ºåº“åˆ†æ", "ğŸ“± æ‰«ç åˆ†æ", "ğŸ“ˆ ABCDæ•ˆèƒ½åˆ†æ", "å…¶ä»–åˆ†æ"])
            
            # === TAB 1: OVERVIEW ===
            with tab1:
                st.caption(f"ç­›é€‰å£å¾„ï¼šçœåŒº={sel_prov}ï½œç»é”€å•†={sel_dist}ï½œäº§å“å¤§ç±»={st.session_state.get('main_sel_cat', 'å…¨éƒ¨')}")

                # --- Common Helpers for Tab 1 ---
                def _fmt_wan(x): return fmt_num((x or 0) / 10000)
                def _fmt_pct(x): return fmt_pct_ratio(x) if x is not None else "â€”"
                def _arrow(x): return "â†‘" if x and x>0 else ("â†“" if x and x<0 else "")
                def _trend_cls(x): return "trend-up" if x and x > 0 else ("trend-down" if x and x < 0 else "trend-neutral")

                # Card Renderer for Performance (Tab 7 Style)
                def _render_perf_card(title, icon, val_wan, target_wan, rate, yoy_val_wan, yoy_pct):
                    trend_cls = _trend_cls(yoy_pct)
                    arrow = _arrow(yoy_pct)
                    rate_txt = _fmt_pct(rate)
                    yoy_txt = _fmt_pct(yoy_pct)
                    pct_val = min(max(rate * 100 if rate else 0, 0), 100)
                    prog_color = "#28A745" if rate and rate >= 1.0 else ("#FFC107" if rate and rate >= 0.8 else "#DC3545")

                    st.markdown(f"""
                    <div class="out-kpi-card">
                        <div class="out-kpi-bar"></div>
                        <div class="out-kpi-head">
                            <div class="out-kpi-ico">{icon}</div>
                            <div class="out-kpi-title">{title}</div>
                        </div>
                        <div class="out-kpi-val">Â¥ {val_wan}ä¸‡</div>
                        <div class="out-kpi-sub2" style="margin-top:8px;">
                            <span>è¾¾æˆç‡</span>
                            <span style="font-weight:800; color:{prog_color}">{rate_txt}</span>
                        </div>
                        <div class="out-kpi-progress" style="margin-top:6px;">
                            <div class="out-kpi-progress-bar" style="background:{prog_color}; width:{pct_val}%;"></div>
                        </div>
                        <div class="out-kpi-sub2" style="margin-top:10px;">
                            <span>ç›®æ ‡</span>
                            <span>{target_wan}ä¸‡</span>
                        </div>
                        <div class="out-kpi-sub2">
                            <span>åŒæœŸ</span>
                            <span>{yoy_val_wan}ä¸‡</span>
                        </div>
                        <div class="out-kpi-sub2">
                            <span>åŒæ¯”</span>
                            <span class="{trend_cls}">{arrow} {yoy_txt}</span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

                # Card Renderer for Outbound/Scan (General Style)
                def _render_general_card(title, icon, main_val, sub_items):
                    # sub_items: list of (label, value_html)
                    rows_html = ""
                    for label, val_html in sub_items:
                        rows_html += f'<div class="out-kpi-sub2"><span>{label}</span><span>{val_html}</span></div>'
                    
                    st.markdown(f"""
                    <div class="out-kpi-card">
                        <div class="out-kpi-bar"></div>
                        <div class="out-kpi-head">
                            <div class="out-kpi-ico">{icon}</div>
                            <div class="out-kpi-title">{title}</div>
                        </div>
                        <div class="out-kpi-val">{main_val}</div>
                        <div style="margin-top:10px;">{rows_html}</div>
                    </div>
                    """, unsafe_allow_html=True)

                sel_bigcat = st.session_state.get("main_sel_cat", "å…¨éƒ¨")

                def _filter_common(_df):
                    if _df is None or getattr(_df, "empty", True):
                        return pd.DataFrame()
                    d = _df.copy()
                    for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'äº§å“å¤§ç±»', 'å¤§åˆ†ç±»']:
                        if c in d.columns:
                            d[c] = d[c].fillna('').astype(str).str.strip()
                    if sel_prov != 'å…¨éƒ¨' and 'çœåŒº' in d.columns:
                        d = d[d['çœåŒº'] == sel_prov]
                    if sel_dist != 'å…¨éƒ¨' and 'ç»é”€å•†åç§°' in d.columns:
                        d = d[d['ç»é”€å•†åç§°'] == sel_dist]
                    if sel_bigcat != 'å…¨éƒ¨':
                        if 'äº§å“å¤§ç±»' in d.columns:
                            d = d[d['äº§å“å¤§ç±»'] == sel_bigcat]
                        elif 'å¤§åˆ†ç±»' in d.columns:
                            d = d[d['å¤§åˆ†ç±»'] == sel_bigcat]
                    return d

                # ---------------------------------------------------------
                # 1. æ ¸å¿ƒä¸šç»©æŒ‡æ ‡ (From Tab 7)
                # ---------------------------------------------------------
                st.markdown("### ğŸš€ æ ¸å¿ƒä¸šç»©æŒ‡æ ‡")
                df_perf = _filter_common(df_perf_raw)
                if not df_perf.empty:
                    # Data Prep
                    if 'å¹´ä»½' in df_perf.columns:
                        df_perf['å¹´ä»½'] = pd.to_numeric(df_perf['å¹´ä»½'], errors='coerce').fillna(0).astype(int)
                    if 'æœˆä»½' in df_perf.columns:
                        df_perf['æœˆä»½'] = pd.to_numeric(df_perf['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                    amt_col = 'å‘è´§é‡‘é¢' if 'å‘è´§é‡‘é¢' in df_perf.columns else None
                    if amt_col:
                        df_perf[amt_col] = pd.to_numeric(df_perf[amt_col], errors='coerce').fillna(0)
                    
                    years_avail = sorted([y for y in df_perf['å¹´ä»½'].unique().tolist() if y > 2000])
                    perf_y = max(years_avail) if years_avail else 2025
                    months_avail = sorted([m for m in df_perf[df_perf['å¹´ä»½'] == perf_y]['æœˆä»½'].unique().tolist() if 1 <= m <= 12])
                    perf_m = max(months_avail) if months_avail else 1
                    last_y = perf_y - 1

                    # Actuals
                    cur_m_amt = df_perf[(df_perf['å¹´ä»½'] == perf_y) & (df_perf['æœˆä»½'] == perf_m)][amt_col].sum() if amt_col else 0
                    last_m_amt = df_perf[(df_perf['å¹´ä»½'] == last_y) & (df_perf['æœˆä»½'] == perf_m)][amt_col].sum() if amt_col else 0
                    cur_y_amt = df_perf[df_perf['å¹´ä»½'] == perf_y][amt_col].sum() if amt_col else 0
                    last_y_amt = df_perf[df_perf['å¹´ä»½'] == last_y][amt_col].sum() if amt_col else 0

                    yoy_m = (cur_m_amt - last_m_amt) / last_m_amt if last_m_amt > 0 else 0
                    yoy_y = (cur_y_amt - last_y_amt) / last_y_amt if last_y_amt > 0 else 0

                    # Targets
                    t_cur_m = 0.0
                    t_cur_y = 0.0
                    if df_target_raw is not None and not getattr(df_target_raw, "empty", True):
                        df_t = df_target_raw.copy()
                        for c in ['çœåŒº', 'å“ç±»']:
                            if c in df_t.columns: df_t[c] = df_t[c].fillna('').astype(str).str.strip()
                        if 'æœˆä»½' in df_t.columns: df_t['æœˆä»½'] = pd.to_numeric(df_t['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                        if 'ä»»åŠ¡é‡' in df_t.columns: df_t['ä»»åŠ¡é‡'] = pd.to_numeric(df_t['ä»»åŠ¡é‡'], errors='coerce').fillna(0)
                        
                        if sel_prov != 'å…¨éƒ¨' and 'çœåŒº' in df_t.columns:
                            df_t = df_t[df_t['çœåŒº'] == sel_prov]
                        # Target usually doesn't filter by Distributor, but filters by Category
                        if sel_bigcat != 'å…¨éƒ¨' and 'å“ç±»' in df_t.columns:
                            df_t = df_t[df_t['å“ç±»'] == sel_bigcat]
                        
                        t_cur_m = df_t[df_t['æœˆä»½'] == perf_m]['ä»»åŠ¡é‡'].sum()
                        t_cur_y = df_t['ä»»åŠ¡é‡'].sum() # Total Year Target

                    rate_m = (cur_m_amt / t_cur_m) if t_cur_m > 0 else None
                    rate_y = (cur_y_amt / t_cur_y) if t_cur_y > 0 else None

                    c1, c2 = st.columns(2)
                    with c1:
                        _render_perf_card(f"æœ¬æœˆä¸šç»©ï¼ˆ{perf_m}æœˆï¼‰", "ğŸ“…", _fmt_wan(cur_m_amt), _fmt_wan(t_cur_m), rate_m, _fmt_wan(last_m_amt), yoy_m)
                    with c2:
                        _render_perf_card(f"å¹´åº¦ç´¯è®¡ä¸šç»©ï¼ˆ{perf_y}å¹´ï¼‰", "ğŸ†", _fmt_wan(cur_y_amt), _fmt_wan(t_cur_y), rate_y, _fmt_wan(last_y_amt), yoy_y)
                else:
                    st.info("ä¸šç»©æ•°æ®ä¸ºç©ºæˆ–ä¸å«åŒ¹é…å­—æ®µ")

                st.markdown("---")

                # ---------------------------------------------------------
                # 2. åº“å­˜å…³é”®æŒ‡æ ‡ (From Tab 6)
                # ---------------------------------------------------------
                st.markdown("### ğŸ“¦ åº“å­˜å…³é”®æŒ‡æ ‡")
                df_stock = _filter_common(df_stock_raw)
                if not df_stock.empty:
                    # Prepare Data for Metrics
                    stock_box_col = 'ç®±æ•°' if 'ç®±æ•°' in df_stock.columns else next((c for c in df_stock.columns if 'ç®±' in str(c)), None)
                    stock_boxes = float(pd.to_numeric(df_stock[stock_box_col], errors='coerce').fillna(0).sum()) if stock_box_col else 0.0
                    
                    # Q4 Avg Sales (Need logic from Tab 6)
                    total_q4_avg = 0.0
                    if df_q4_raw is not None and not getattr(df_q4_raw, "empty", True):
                        # Simple estimation: Filter Q4 raw by current filters -> Sum Q4 months -> Divide by 3
                        # Tab 6 logic is more complex (Distributor based), but for Overview Total, simple sum is close enough.
                        # However, let's try to match Tab 6 logic: Sum 'Q4_Avg' of relevant distributors.
                        
                        # 1. Get filtered distributors
                        valid_dists = df_stock['ç»é”€å•†åç§°'].unique()
                        
                        # 2. Calculate Q4 Sales for these distributors
                        df_q4_f = df_q4_raw.copy()
                        if 'å¹´ä»½' in df_q4_f.columns: df_q4_f = df_q4_f[df_q4_f['å¹´ä»½'] == 2025] # Q4 assumption
                        if 'ç»é”€å•†åç§°' in df_q4_f.columns:
                            df_q4_f = df_q4_f[df_q4_f['ç»é”€å•†åç§°'].isin(valid_dists)]
                        
                        # Filter for Oct, Nov, Dec
                        if 'æœˆä»½' in df_q4_f.columns:
                            df_q4_f['æœˆä»½'] = pd.to_numeric(df_q4_f['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                            df_q4_f = df_q4_f[df_q4_f['æœˆä»½'].isin([10, 11, 12])]
                        
                        qty_col = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in df_q4_f.columns else next((c for c in df_q4_f.columns if 'æ•°é‡' in str(c)), None)
                        if qty_col:
                            total_q4_sales = pd.to_numeric(df_q4_f[qty_col], errors='coerce').sum()
                            total_q4_avg = total_q4_sales / 3.0

                    dos = stock_boxes / total_q4_avg if total_q4_avg > 0 else 0.0
                    
                    # Abnormal Count (Simplify for Overview)
                    # Tab 6 calculates per distributor. Here we just show global metrics.
                    
                    m1, m2, m3 = st.columns(3)
                    m1.metric("ğŸ“¦ æ€»åº“å­˜ (ç®±)", fmt_num(stock_boxes))
                    m2.metric("ğŸ“‰ Q4æœˆå‡é”€", fmt_num(total_q4_avg))
                    m3.metric("ğŸ“… æ•´ä½“å¯é”€æœˆ (DOS)", fmt_num(dos))
                else:
                    st.info("åº“å­˜æ•°æ®ä¸ºç©º")

                st.markdown("---")

                # ---------------------------------------------------------
                # 3. å‡ºåº“å…³é”®æŒ‡æ ‡ (From Tab Out)
                # ---------------------------------------------------------
                st.markdown("### ğŸšš å‡ºåº“å…³é”®æŒ‡æ ‡")
                df_out = _filter_common(df_q4_raw)
                if not df_out.empty:
                    # Date Prep
                    tmp = df_out.copy()
                    for c in ['å¹´ä»½', 'æœˆä»½']: 
                        if c in tmp.columns: tmp[c] = pd.to_numeric(tmp[c], errors='coerce').fillna(0).astype(int)
                    if 'æ—¥' in tmp.columns: tmp['æ—¥'] = pd.to_numeric(tmp['æ—¥'], errors='coerce').fillna(0).astype(int)
                    qty_col = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in tmp.columns else next((c for c in tmp.columns if 'æ•°é‡' in str(c) or 'ç®±' in str(c)), None)
                    if qty_col:
                        tmp['æ•°é‡(ç®±)'] = pd.to_numeric(tmp[qty_col], errors='coerce').fillna(0)
                        tmp = tmp[tmp['å¹´ä»½'] > 0]
                        
                        oy = int(tmp['å¹´ä»½'].max())
                        om = int(tmp[tmp['å¹´ä»½'] == oy]['æœˆä»½'].max())
                        od = int(tmp[(tmp['å¹´ä»½'] == oy) & (tmp['æœˆä»½'] == om)]['æ—¥'].max())
                        
                        # Current
                        today_boxes = tmp[(tmp['å¹´ä»½'] == oy) & (tmp['æœˆä»½'] == om) & (tmp['æ—¥'] == od)]['æ•°é‡(ç®±)'].sum()
                        month_boxes = tmp[(tmp['å¹´ä»½'] == oy) & (tmp['æœˆä»½'] == om)]['æ•°é‡(ç®±)'].sum()
                        year_boxes = tmp[tmp['å¹´ä»½'] == oy]['æ•°é‡(ç®±)'].sum()
                        
                        # Last Year
                        ly = oy - 1
                        l_today_boxes = tmp[(tmp['å¹´ä»½'] == ly) & (tmp['æœˆä»½'] == om) & (tmp['æ—¥'] == od)]['æ•°é‡(ç®±)'].sum()
                        l_month_boxes = tmp[(tmp['å¹´ä»½'] == ly) & (tmp['æœˆä»½'] == om)]['æ•°é‡(ç®±)'].sum()
                        l_year_boxes = tmp[tmp['å¹´ä»½'] == ly]['æ•°é‡(ç®±)'].sum()
                        
                        # YoY
                        yoy_d = (today_boxes - l_today_boxes) / l_today_boxes if l_today_boxes > 0 else 0
                        yoy_m = (month_boxes - l_month_boxes) / l_month_boxes if l_month_boxes > 0 else 0
                        yoy_y = (year_boxes - l_year_boxes) / l_year_boxes if l_year_boxes > 0 else 0
                        
                        k1, k2, k3 = st.columns(3)
                        with k1:
                            trend = _trend_cls(yoy_d)
                            arr = _arrow(yoy_d)
                            _render_general_card("æœ¬æ—¥å‡ºåº“", "ğŸšš", f"{fmt_num(today_boxes)} ç®±", [
                                ("åŒæœŸ", f"{fmt_num(l_today_boxes)} ç®±"),
                                ("åŒæ¯”", f'<span class="{trend}">{arr} {_fmt_pct(yoy_d)}</span>')
                            ])
                        with k2:
                            trend = _trend_cls(yoy_m)
                            arr = _arrow(yoy_m)
                            _render_general_card(f"æœ¬æœˆç´¯è®¡å‡ºåº“ï¼ˆ{om}æœˆï¼‰", "ğŸ“¦", f"{fmt_num(month_boxes)} ç®±", [
                                ("åŒæœŸ", f"{fmt_num(l_month_boxes)} ç®±"),
                                ("åŒæ¯”", f'<span class="{trend}">{arr} {_fmt_pct(yoy_m)}</span>')
                            ])
                        with k3:
                            trend = _trend_cls(yoy_y)
                            arr = _arrow(yoy_y)
                            _render_general_card(f"æœ¬å¹´ç´¯è®¡å‡ºåº“ï¼ˆ{oy}å¹´ï¼‰", "ğŸ§¾", f"{fmt_num(year_boxes)} ç®±", [
                                ("åŒæœŸ", f"{fmt_num(l_year_boxes)} ç®±"),
                                ("åŒæ¯”", f'<span class="{trend}">{arr} {_fmt_pct(yoy_y)}</span>')
                            ])
                else:
                    st.info("å‡ºåº“æ•°æ®ä¸ºç©º")

                st.markdown("---")

                # ---------------------------------------------------------
                # 4. æ‰«ç ç‡æ¦‚è§ˆ (From Tab Scan)
                # ---------------------------------------------------------
                st.markdown("### ğŸ“± æ‰«ç ç‡æ¦‚è§ˆ")
                df_scan = _filter_common(df_scan_raw)
                # Re-use out_base from above or re-calc
                if not df_scan.empty and not df_out.empty:
                    # Ensure Date Cols
                    for c in ['å¹´ä»½', 'æœˆä»½', 'æ—¥']:
                        if c in df_scan.columns: df_scan[c] = pd.to_numeric(df_scan[c], errors='coerce').fillna(0).astype(int)
                    
                    # Use same oy, om, od from Outbound
                    scan_today = len(df_scan[(df_scan['å¹´ä»½'] == oy) & (df_scan['æœˆä»½'] == om) & (df_scan['æ—¥'] == od)]) / 6.0
                    scan_month = len(df_scan[(df_scan['å¹´ä»½'] == oy) & (df_scan['æœˆä»½'] == om)]) / 6.0
                    scan_year = len(df_scan[df_scan['å¹´ä»½'] == oy]) / 6.0
                    
                    l_scan_today = len(df_scan[(df_scan['å¹´ä»½'] == ly) & (df_scan['æœˆä»½'] == om) & (df_scan['æ—¥'] == od)]) / 6.0
                    l_scan_month = len(df_scan[(df_scan['å¹´ä»½'] == ly) & (df_scan['æœˆä»½'] == om)]) / 6.0
                    l_scan_year = len(df_scan[df_scan['å¹´ä»½'] == ly]) / 6.0

                    rate_today = scan_today / today_boxes if today_boxes > 0 else 0
                    rate_month = scan_month / month_boxes if month_boxes > 0 else 0
                    rate_year = scan_year / year_boxes if year_boxes > 0 else 0
                    
                    yoy_rate_d = rate_today - (l_scan_today / l_today_boxes if l_today_boxes > 0 else 0)
                    yoy_rate_m = rate_month - (l_scan_month / l_month_boxes if l_month_boxes > 0 else 0)
                    yoy_rate_y = rate_year - (l_scan_year / l_year_boxes if l_year_boxes > 0 else 0)

                    s1, s2, s3 = st.columns(3)
                    with s1:
                        trend = _trend_cls(yoy_rate_d)
                        arr = _arrow(yoy_rate_d)
                        _render_general_card("æœ¬æ—¥æ‰«ç ç‡", "ğŸ“±", fmt_pct_ratio(rate_today), [
                            ("æ‰«ç  / å‡ºåº“", f"{fmt_num(scan_today)} / {fmt_num(today_boxes)}"),
                            ("åŒæ¯”å¢å‡", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_d*100)}</span>')
                        ])
                    with s2:
                        trend = _trend_cls(yoy_rate_m)
                        arr = _arrow(yoy_rate_m)
                        _render_general_card("æœ¬æœˆæ‰«ç ç‡", "ğŸ—“ï¸", fmt_pct_ratio(rate_month), [
                            ("æ‰«ç  / å‡ºåº“", f"{fmt_num(scan_month)} / {fmt_num(month_boxes)}"),
                            ("åŒæ¯”å¢å‡", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_m*100)}</span>')
                        ])
                    with s3:
                        trend = _trend_cls(yoy_rate_y)
                        arr = _arrow(yoy_rate_y)
                        _render_general_card("æœ¬å¹´æ‰«ç ç‡", "ğŸ“ˆ", fmt_pct_ratio(rate_year), [
                            ("æ‰«ç  / å‡ºåº“", f"{fmt_num(scan_year)} / {fmt_num(year_boxes)}"),
                            ("åŒæ¯”å¢å‡", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_y*100)}</span>')
                        ])
                else:
                    st.info("æ‰«ç æ•°æ®ä¸ºç©º")

            # === TAB SCAN: SCAN ANALYSIS ===
            with tab_scan:
                if df_scan_raw is not None and not df_scan_raw.empty:
                    st.subheader("ğŸ“± æ‰«ç åˆ†æ")
                    
                    # 1. Date Calculation
                    # Today: Max date in max month of 2026
                    max_scan_date = None
                    df_scan_2026 = df_scan_raw[df_scan_raw['å¹´ä»½'] == 2026]
                    if not df_scan_2026.empty:
                        max_month = df_scan_2026['æœˆä»½'].max()
                        max_day = df_scan_2026[df_scan_2026['æœˆä»½'] == max_month]['æ—¥'].max()
                        max_scan_date = pd.Timestamp(year=2026, month=max_month, day=max_day)
                    
                    if max_scan_date:
                        cur_year = max_scan_date.year
                        cur_month = max_scan_date.month
                        cur_day = max_scan_date.day
                        st.info(f"ğŸ“… å½“å‰ç»Ÿè®¡æ—¥æœŸï¼š{cur_year}å¹´{cur_month}æœˆ{cur_day}æ—¥")
                    else:
                        st.warning("âš ï¸ æœªæ‰¾åˆ°2026å¹´æ‰«ç æ•°æ®ï¼Œæ— æ³•è®¡ç®—å½“æ—¥/å½“æœˆæŒ‡æ ‡")
                        cur_year, cur_month, cur_day = 2026, 1, 1

                    # 2. Filter Area
                    with st.expander("ğŸ” æ‰«ç ç­›é€‰", expanded=True):
                        c_s1, c_s2, c_s3 = st.columns(3)
                        # Province
                        prov_opts_s = ['å…¨éƒ¨'] + sorted(df_scan_raw['çœåŒº'].unique().tolist())
                        sel_prov_s = c_s1.selectbox("çœåŒº", prov_opts_s, key="scan_prov")
                        
                        # Distributor
                        if sel_prov_s != 'å…¨éƒ¨':
                            dist_opts_s = ['å…¨éƒ¨'] + sorted(df_scan_raw[df_scan_raw['çœåŒº'] == sel_prov_s]['ç»é”€å•†åç§°'].unique().tolist())
                        else:
                            dist_opts_s = ['å…¨éƒ¨'] + sorted(df_scan_raw['ç»é”€å•†åç§°'].unique().tolist())
                        sel_dist_s = c_s2.selectbox("ç»é”€å•†", dist_opts_s, key="scan_dist")
                        
                        # Category
                        cat_opts_s = ['å…¨éƒ¨'] + sorted(df_scan_raw['äº§å“å¤§ç±»'].unique().tolist())
                        sel_cat_s = c_s3.selectbox("äº§å“å¤§ç±»", cat_opts_s, key="scan_cat")

                    # Apply Filters
                    df_s_flt = df_scan_raw.copy()
                    last_year = cur_year - 1
                    out_base_df = None
                    out_day_df = None
                    out_day_last_df = None
                    if df_q4_raw is not None and not getattr(df_q4_raw, "empty", True):
                        tmp = df_q4_raw.copy()
                        for c in ['å¹´ä»½', 'æœˆä»½']:
                            if c in tmp.columns:
                                tmp[c] = pd.to_numeric(tmp[c], errors='coerce').fillna(0).astype(int)
                        day_col_out = None
                        if 'æ—¥' in tmp.columns:
                            day_col_out = 'æ—¥'
                            tmp['æ—¥'] = pd.to_numeric(tmp['æ—¥'], errors='coerce').fillna(0).astype(int)
                        else:
                            cand = next((c for c in tmp.columns if 'æ—¥æœŸ' in str(c)), None)
                            if cand:
                                dt = pd.to_datetime(tmp[cand], errors='coerce')
                                tmp['å¹´ä»½'] = dt.dt.year
                                tmp['æœˆä»½'] = dt.dt.month
                                tmp['æ—¥'] = dt.dt.day
                                day_col_out = 'æ—¥'
                        qty_col_out = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in tmp.columns else next((c for c in tmp.columns if 'æ•°é‡' in str(c) or 'ç®±' in str(c)), None)
                        if qty_col_out:
                            tmp['æ•°é‡(ç®±)'] = pd.to_numeric(tmp[qty_col_out], errors='coerce').fillna(0)
                            if all(k in tmp.columns for k in ['å¹´ä»½', 'æœˆä»½', 'æ—¥']):
                                out_base_df = tmp.copy()
                                for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'äº§å“å¤§ç±»', 'å¤§åˆ†ç±»']:
                                    if c in out_base_df.columns:
                                        out_base_df[c] = out_base_df[c].fillna('').astype(str).str.strip()

                    if sel_prov_s != 'å…¨éƒ¨':
                        df_s_flt = df_s_flt[df_s_flt['çœåŒº'] == sel_prov_s]
                        if out_base_df is not None and 'çœåŒº' in out_base_df.columns:
                            out_base_df = out_base_df[out_base_df['çœåŒº'] == sel_prov_s]
                    if sel_dist_s != 'å…¨éƒ¨':
                        df_s_flt = df_s_flt[df_s_flt['ç»é”€å•†åç§°'] == sel_dist_s]
                        if out_base_df is not None and 'ç»é”€å•†åç§°' in out_base_df.columns:
                            out_base_df = out_base_df[out_base_df['ç»é”€å•†åç§°'] == sel_dist_s]
                    if sel_cat_s != 'å…¨éƒ¨':
                        df_s_flt = df_s_flt[df_s_flt['äº§å“å¤§ç±»'] == sel_cat_s]
                        if out_base_df is not None:
                            if 'äº§å“å¤§ç±»' in out_base_df.columns:
                                out_base_df = out_base_df[out_base_df['äº§å“å¤§ç±»'] == sel_cat_s]
                            elif 'å¤§åˆ†ç±»' in out_base_df.columns:
                                out_base_df = out_base_df[out_base_df['å¤§åˆ†ç±»'] == sel_cat_s]

                    if out_base_df is not None:
                        out_day_df = out_base_df[(out_base_df['å¹´ä»½'] == cur_year) & (out_base_df['æœˆä»½'] == cur_month) & (out_base_df['æ—¥'] == cur_day)].copy()
                        out_day_last_df = out_base_df[(out_base_df['å¹´ä»½'] == last_year) & (out_base_df['æœˆä»½'] == cur_month) & (out_base_df['æ—¥'] == cur_day)].copy()

                    # 3. Calculate Metrics (Scan vs Outbound)
                    # Unit: Box (6 tins = 1 box)
                    # Scan Count (Rows) / 6
                    
                    # --- Current Period (2026) ---
                    # Day
                    scan_day = len(df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month) & (df_s_flt['æ—¥'] == cur_day)]) / 6.0
                    out_day = 0
                    if out_day_df is not None:
                        qty_col_out = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in out_day_df.columns else next((c for c in out_day_df.columns if 'æ•°é‡' in str(c) or 'ç®±' in str(c)), None)
                        if qty_col_out:
                            out_day = float(pd.to_numeric(out_day_df[qty_col_out], errors='coerce').fillna(0).sum())
                    out_day_last = 0
                    if out_day_last_df is not None:
                        qty_col_out = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in out_day_last_df.columns else next((c for c in out_day_last_df.columns if 'æ•°é‡' in str(c) or 'ç®±' in str(c)), None)
                        if qty_col_out:
                            out_day_last = float(pd.to_numeric(out_day_last_df[qty_col_out], errors='coerce').fillna(0).sum())
                    
                    # Month
                    scan_month = len(df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month)]) / 6.0
                    out_month = float(pd.to_numeric(out_base_df[(out_base_df['å¹´ä»½'] == cur_year) & (out_base_df['æœˆä»½'] == cur_month)]['æ•°é‡(ç®±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0
                    
                    # Year
                    scan_year = len(df_s_flt[df_s_flt['å¹´ä»½'] == cur_year]) / 6.0
                    out_year = float(pd.to_numeric(out_base_df[out_base_df['å¹´ä»½'] == cur_year]['æ•°é‡(ç®±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0

                    # --- Same Period Last Year (2025) ---
                    scan_day_last = len(df_s_flt[(df_s_flt['å¹´ä»½'] == last_year) & (df_s_flt['æœˆä»½'] == cur_month) & (df_s_flt['æ—¥'] == cur_day)]) / 6.0
                    
                    # Month
                    scan_month_last = len(df_s_flt[(df_s_flt['å¹´ä»½'] == last_year) & (df_s_flt['æœˆä»½'] == cur_month)]) / 6.0
                    out_month_last = float(pd.to_numeric(out_base_df[(out_base_df['å¹´ä»½'] == last_year) & (out_base_df['æœˆä»½'] == cur_month)]['æ•°é‡(ç®±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0
                    
                    # Year (YTD? or Full Year? Usually YTD for comparison or Full Year 2025)
                    # "åŒæœŸ" usually means same period. For Year, it means 2025 Full Year or YTD.
                    # Let's use Full Year 2025 for now as 2026 is incomplete.
                    scan_year_last = len(df_s_flt[df_s_flt['å¹´ä»½'] == last_year]) / 6.0
                    out_year_last = float(pd.to_numeric(out_base_df[out_base_df['å¹´ä»½'] == last_year]['æ•°é‡(ç®±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0

                    # Rates
                    rate_month = (scan_month / out_month) if out_month > 0 else 0
                    rate_month_last = (scan_month_last / out_month_last) if out_month_last > 0 else 0
                    rate_year = (scan_year / out_year) if out_year > 0 else 0
                    rate_year_last = (scan_year_last / out_year_last) if out_year_last > 0 else 0
                    rate_day = (scan_day / out_day) if out_day > 0 else 0
                    rate_day_last = (scan_day_last / out_day_last) if out_day_last > 0 else 0

                    tab_overview, tab_s_cat, tab_s_prov, tab_s_map = st.tabs(["ğŸ“Š æ‰«ç ç‡æ¦‚è§ˆ", "ğŸ§© åˆ†å“ç±»æ‰«ç ç‡", "ğŸ—ºï¸ çœåŒºæ‰«ç ç‡", "ğŸ§­ åœ°å›¾çƒ­åŠ›"])

                    with tab_overview:
                        st.caption(f"å£å¾„ï¼šä»Šæ—¥ {cur_year}å¹´{cur_month}æœˆ{cur_day}æ—¥ï½œæœ¬æœˆ {cur_month}æœˆï½œæœ¬å¹´ {cur_year}å¹´")

                        def _trend_cls(x):
                            if x is None or (isinstance(x, float) and pd.isna(x)):
                                return "trend-neutral"
                            return "trend-up" if x > 0 else ("trend-down" if x < 0 else "trend-neutral")

                        def _arrow(x):
                            if x is None or (isinstance(x, float) and pd.isna(x)):
                                return ""
                            return "â†‘" if x > 0 else ("â†“" if x < 0 else "")

                        yoy_rate_day = (rate_day - rate_day_last) if out_day_last > 0 else None
                        yoy_rate_month = (rate_month - rate_month_last) if out_month_last > 0 else None
                        yoy_rate_year = (rate_year - rate_year_last) if out_year_last > 0 else None
                        yoy_rate_day_pct = (yoy_rate_day * 100.0) if yoy_rate_day is not None else None
                        yoy_rate_month_pct = (yoy_rate_month * 100.0) if yoy_rate_month is not None else None
                        yoy_rate_year_pct = (yoy_rate_year * 100.0) if yoy_rate_year is not None else None

                        c1, c2, c3 = st.columns(3)
                        with c1:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸ“±</div>
                                    <div class="out-kpi-title">æœ¬æ—¥æ‰«ç ç‡</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_day)}</div>
                                <div class="out-kpi-sub"><span>å‡ºåº“(ç®±)</span><span>{fmt_num(out_day)}</span></div>
                                <div class="out-kpi-sub"><span>æ‰«ç (ç®±)</span><span>{fmt_num(scan_day)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({last_year})</span><span>{fmt_num(out_day_last)} ç®± / {fmt_num(scan_day_last)} ç®±</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆæ‰«ç ç‡ï¼‰</span><span class="{_trend_cls(yoy_rate_day)}">{_arrow(yoy_rate_day)} {fmt_pct_value(yoy_rate_day_pct) if yoy_rate_day_pct is not None else "â€”"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c2:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸ—“ï¸</div>
                                    <div class="out-kpi-title">æœ¬æœˆæ‰«ç ç‡</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_month)}</div>
                                <div class="out-kpi-sub"><span>å‡ºåº“(ç®±)</span><span>{fmt_num(out_month)}</span></div>
                                <div class="out-kpi-sub"><span>æ‰«ç (ç®±)</span><span>{fmt_num(scan_month)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({last_year})</span><span>{fmt_num(out_month_last)} ç®± / {fmt_num(scan_month_last)} ç®±</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆæ‰«ç ç‡ï¼‰</span><span class="{_trend_cls(yoy_rate_month)}">{_arrow(yoy_rate_month)} {fmt_pct_value(yoy_rate_month_pct) if yoy_rate_month_pct is not None else "â€”"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c3:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸ“ˆ</div>
                                    <div class="out-kpi-title">æœ¬å¹´æ‰«ç ç‡</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_year)}</div>
                                <div class="out-kpi-sub"><span>å‡ºåº“(ç®±)</span><span>{fmt_num(out_year)}</span></div>
                                <div class="out-kpi-sub"><span>æ‰«ç (ç®±)</span><span>{fmt_num(scan_year)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({last_year})</span><span>{fmt_num(out_year_last)} ç®± / {fmt_num(scan_year_last)} ç®±</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆæ‰«ç ç‡ï¼‰</span><span class="{_trend_cls(yoy_rate_year)}">{_arrow(yoy_rate_year)} {fmt_pct_value(yoy_rate_year_pct) if yoy_rate_year_pct is not None else "â€”"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    # --- Sub-Tab 1: Category ---
                    with tab_s_cat:
                        # Group by Big Category
                        
                        # --- Day Level (Sync) ---
                        s_cat_day = df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month) & (df_s_flt['æ—¥'] == cur_day)].groupby('äº§å“å¤§ç±»').size().reset_index(name='æœ¬æ—¥æ‰«ç å¬æ•°')
                        s_cat_day['æœ¬æ—¥æ‰«ç (ç®±)'] = s_cat_day['æœ¬æ—¥æ‰«ç å¬æ•°'] / 6.0
                        o_cat_day = None
                        if out_day_df is not None:
                            if 'äº§å“å¤§ç±»' in out_day_df.columns:
                                group_col = 'äº§å“å¤§ç±»'
                            elif 'å¤§åˆ†ç±»' in out_day_df.columns:
                                group_col = 'å¤§åˆ†ç±»'
                            else:
                                group_col = None
                            qty_col_out = 'æ•°é‡(ç®±)' if 'æ•°é‡(ç®±)' in (out_day_df.columns if out_day_df is not None else []) else next((c for c in out_day_df.columns if 'æ•°é‡' in str(c) or 'ç®±' in str(c)), None) if out_day_df is not None else None
                            if group_col and qty_col_out:
                                o_cat_day = out_day_df.groupby(group_col)[qty_col_out].sum().reset_index().rename(columns={group_col: 'äº§å“å¤§ç±»', qty_col_out: 'ä»Šæ—¥å‡ºåº“(ç®±)'})
                        
                        # --- Month Level (Sync) ---
                        s_cat_month = df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month)].groupby('äº§å“å¤§ç±»').size().reset_index(name='æœ¬æœˆæ‰«ç å¬æ•°')
                        s_cat_month['æœ¬æœˆæ‰«ç (ç®±)'] = s_cat_month['æœ¬æœˆæ‰«ç å¬æ•°'] / 6.0
                        
                        o_cat_month = pd.DataFrame(columns=['äº§å“å¤§ç±»', 'æœ¬æœˆå‡ºåº“(ç®±)'])
                        if out_base_df is not None:
                            group_col_m = 'äº§å“å¤§ç±»' if 'äº§å“å¤§ç±»' in out_base_df.columns else ('å¤§åˆ†ç±»' if 'å¤§åˆ†ç±»' in out_base_df.columns else None)
                            if group_col_m:
                                o_cat_month = out_base_df[(out_base_df['å¹´ä»½'] == cur_year) & (out_base_df['æœˆä»½'] == cur_month)].groupby(group_col_m)['æ•°é‡(ç®±)'].sum().reset_index()
                                o_cat_month = o_cat_month.rename(columns={group_col_m: 'äº§å“å¤§ç±»', 'æ•°é‡(ç®±)': 'æœ¬æœˆå‡ºåº“(ç®±)'})

                        # --- Year Level (Sync) ---
                        s_cat_year = df_s_flt[df_s_flt['å¹´ä»½'] == cur_year].groupby('äº§å“å¤§ç±»').size().reset_index(name='æœ¬å¹´æ‰«ç å¬æ•°')
                        s_cat_year['æœ¬å¹´æ‰«ç (ç®±)'] = s_cat_year['æœ¬å¹´æ‰«ç å¬æ•°'] / 6.0
                        
                        o_cat_year = pd.DataFrame(columns=['äº§å“å¤§ç±»', 'æœ¬å¹´å‡ºåº“(ç®±)'])
                        if out_base_df is not None:
                            group_col_y = 'äº§å“å¤§ç±»' if 'äº§å“å¤§ç±»' in out_base_df.columns else ('å¤§åˆ†ç±»' if 'å¤§åˆ†ç±»' in out_base_df.columns else None)
                            if group_col_y:
                                o_cat_year = out_base_df[out_base_df['å¹´ä»½'] == cur_year].groupby(group_col_y)['æ•°é‡(ç®±)'].sum().reset_index()
                                o_cat_year = o_cat_year.rename(columns={group_col_y: 'äº§å“å¤§ç±»', 'æ•°é‡(ç®±)': 'æœ¬å¹´å‡ºåº“(ç®±)'})
                            
                        # Merge All
                        cat_final = pd.merge(s_cat_day[['äº§å“å¤§ç±»', 'æœ¬æ—¥æ‰«ç (ç®±)']], s_cat_month[['äº§å“å¤§ç±»', 'æœ¬æœˆæ‰«ç (ç®±)']], on='äº§å“å¤§ç±»', how='outer')
                        if o_cat_day is not None:
                            cat_final = pd.merge(cat_final, o_cat_day, on='äº§å“å¤§ç±»', how='outer')
                        cat_final = pd.merge(cat_final, o_cat_month, on='äº§å“å¤§ç±»', how='outer')
                        cat_final = pd.merge(cat_final, s_cat_year[['äº§å“å¤§ç±»', 'æœ¬å¹´æ‰«ç (ç®±)']], on='äº§å“å¤§ç±»', how='outer')
                        cat_final = pd.merge(cat_final, o_cat_year, on='äº§å“å¤§ç±»', how='outer').fillna(0)
                        
                        # Calculate Rates
                        # Day Rate: Outbound usually monthly, so Day Rate might not be accurate unless assumed uniform or N/A
                        # User requirement: "æœ¬æ—¥ã€æœ¬æœˆçš„ç»´åº¦ï¼Œä¹Ÿéœ€è¦åŠ åˆ°åˆ†å“ç±»å’Œåˆ†çœåŒº". 
                        # Let's show Day Scan Qty. Day Rate is tricky without Day Outbound. We will show Day Scan Qty only or N/A for Rate.
                        # Month Rate
                        cat_final['æœ¬æœˆæ‰«ç ç‡'] = cat_final.apply(lambda x: x['æœ¬æœˆæ‰«ç (ç®±)'] / x['æœ¬æœˆå‡ºåº“(ç®±)'] if x['æœ¬æœˆå‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        # Year Rate
                        cat_final['æœ¬å¹´æ‰«ç ç‡'] = cat_final.apply(lambda x: x['æœ¬å¹´æ‰«ç (ç®±)'] / x['æœ¬å¹´å‡ºåº“(ç®±)'] if x['æœ¬å¹´å‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        # Day Rate
                        if 'ä»Šæ—¥å‡ºåº“(ç®±)' in cat_final.columns:
                            cat_final['æœ¬æ—¥æ‰«ç ç‡'] = cat_final.apply(lambda x: x['æœ¬æ—¥æ‰«ç (ç®±)'] / x['ä»Šæ—¥å‡ºåº“(ç®±)'] if x['ä»Šæ—¥å‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        else:
                            cat_final['ä»Šæ—¥å‡ºåº“(ç®±)'] = 0.0
                            cat_final['æœ¬æ—¥æ‰«ç ç‡'] = 0.0
                        
                        cat_final = cat_final.sort_values('æœ¬æœˆæ‰«ç (ç®±)', ascending=False)
                        
                        # Format for display
                        # Display
                        cat_disp = cat_final[['äº§å“å¤§ç±»', 'ä»Šæ—¥å‡ºåº“(ç®±)', 'æœ¬æ—¥æ‰«ç (ç®±)', 'æœ¬æ—¥æ‰«ç ç‡', 'æœ¬æœˆå‡ºåº“(ç®±)', 'æœ¬æœˆæ‰«ç (ç®±)', 'æœ¬æœˆæ‰«ç ç‡', 'æœ¬å¹´å‡ºåº“(ç®±)', 'æœ¬å¹´æ‰«ç (ç®±)', 'æœ¬å¹´æ‰«ç ç‡']].copy()
                        cat_disp = cat_disp.rename(columns={'æœ¬æ—¥æ‰«ç (ç®±)': 'ä»Šæ—¥æ‰«ç (ç®±)'})
                        cat_column_defs = [
                            {"headerName": "äº§å“å¤§ç±»", "field": "äº§å“å¤§ç±»", "pinned": "left", "minWidth": 120},
                            {"headerName": f"ä»Šæ—¥ï¼ˆ{cur_month}æœˆ{cur_day}æ—¥ï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "ä»Šæ—¥å‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "ä»Šæ—¥æ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "æœ¬æ—¥æ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"æœ¬æœˆï¼ˆ{cur_month}æœˆï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "æœ¬æœˆå‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "æœ¬æœˆæ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "æœ¬æœˆæ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"æœ¬å¹´ï¼ˆ{cur_year}å¹´ï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "æœ¬å¹´å‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "æœ¬å¹´æ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "æœ¬å¹´æ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                        ]

                        show_aggrid_table(cat_disp, key="scan_cat_ag", column_defs=cat_column_defs)

                    # --- Sub-Tab 2: Province ---
                    with tab_s_prov:
                        # --- Day Level ---
                        s_prov_day = df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month) & (df_s_flt['æ—¥'] == cur_day)].groupby('çœåŒº').size().reset_index(name='æœ¬æ—¥æ‰«ç å¬æ•°')
                        s_prov_day['æœ¬æ—¥æ‰«ç (ç®±)'] = s_prov_day['æœ¬æ—¥æ‰«ç å¬æ•°'] / 6.0
                        o_prov_day = None
                        if out_day_df is not None:
                            o_prov_day = out_day_df.groupby('çœåŒº')['æ•°é‡(ç®±)'].sum().reset_index().rename(columns={'æ•°é‡(ç®±)': 'ä»Šæ—¥å‡ºåº“(ç®±)'})

                        # --- Month Level (Current) ---
                        s_prov_cur = df_s_flt[(df_s_flt['å¹´ä»½'] == cur_year) & (df_s_flt['æœˆä»½'] == cur_month)].groupby('çœåŒº').size().reset_index(name='æ‰«ç å¬æ•°')
                        s_prov_cur['æ‰«ç ç®±æ•°'] = s_prov_cur['æ‰«ç å¬æ•°'] / 6.0
                        o_prov_cur = pd.DataFrame(columns=['çœåŒº', 'æœ¬æœˆå‡ºåº“(ç®±)'])
                        if out_base_df is not None:
                            o_prov_cur = out_base_df[(out_base_df['å¹´ä»½'] == cur_year) & (out_base_df['æœˆä»½'] == cur_month)].groupby('çœåŒº')['æ•°é‡(ç®±)'].sum().reset_index().rename(columns={'æ•°é‡(ç®±)': 'æœ¬æœˆå‡ºåº“(ç®±)'})
                        prov_cur = pd.merge(s_prov_cur[['çœåŒº', 'æ‰«ç ç®±æ•°']], o_prov_cur, on='çœåŒº', how='outer').fillna(0)
                        prov_cur['æœ¬æœˆæ‰«ç (ç®±)'] = prov_cur['æ‰«ç ç®±æ•°']
                        prov_cur['æœ¬æœˆæ‰«ç ç‡'] = prov_cur.apply(lambda x: x['æœ¬æœˆæ‰«ç (ç®±)'] / x['æœ¬æœˆå‡ºåº“(ç®±)'] if x['æœ¬æœˆå‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        prov_cur = prov_cur[['çœåŒº', 'æœ¬æœˆå‡ºåº“(ç®±)', 'æœ¬æœˆæ‰«ç (ç®±)', 'æœ¬æœˆæ‰«ç ç‡']]

                        # --- Same Period Last Year (Month) ---
                        s_prov_last = df_s_flt[(df_s_flt['å¹´ä»½'] == last_year) & (df_s_flt['æœˆä»½'] == cur_month)].groupby('çœåŒº').size().reset_index(name='æ‰«ç å¬æ•°')
                        s_prov_last['æ‰«ç ç®±æ•°'] = s_prov_last['æ‰«ç å¬æ•°'] / 6.0
                        o_prov_last = pd.DataFrame(columns=['çœåŒº', 'åŒæœŸå‡ºåº“(ç®±)'])
                        if out_base_df is not None:
                            o_prov_last = out_base_df[(out_base_df['å¹´ä»½'] == last_year) & (out_base_df['æœˆä»½'] == cur_month)].groupby('çœåŒº')['æ•°é‡(ç®±)'].sum().reset_index().rename(columns={'æ•°é‡(ç®±)': 'åŒæœŸå‡ºåº“(ç®±)'})
                        prov_last = pd.merge(s_prov_last[['çœåŒº', 'æ‰«ç ç®±æ•°']], o_prov_last, on='çœåŒº', how='outer').fillna(0)
                        prov_last['åŒæœŸæ‰«ç (ç®±)'] = prov_last['æ‰«ç ç®±æ•°']
                        prov_last['åŒæœŸæ‰«ç ç‡'] = prov_last.apply(lambda x: x['åŒæœŸæ‰«ç (ç®±)'] / x['åŒæœŸå‡ºåº“(ç®±)'] if x['åŒæœŸå‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        prov_last = prov_last[['çœåŒº', 'åŒæœŸå‡ºåº“(ç®±)', 'åŒæœŸæ‰«ç (ç®±)', 'åŒæœŸæ‰«ç ç‡']]

                        # --- Ring Period (Month) ---
                        if cur_month == 1:
                            ring_year = cur_year - 1
                            ring_month = 12
                        else:
                            ring_year = cur_year
                            ring_month = cur_month - 1

                        s_prov_ring = df_s_flt[(df_s_flt['å¹´ä»½'] == ring_year) & (df_s_flt['æœˆä»½'] == ring_month)].groupby('çœåŒº').size().reset_index(name='æ‰«ç å¬æ•°')
                        s_prov_ring['æ‰«ç ç®±æ•°'] = s_prov_ring['æ‰«ç å¬æ•°'] / 6.0
                        o_prov_ring = pd.DataFrame(columns=['çœåŒº', 'ç¯æ¯”å‡ºåº“(ç®±)'])
                        if out_base_df is not None:
                            o_prov_ring = out_base_df[(out_base_df['å¹´ä»½'] == ring_year) & (out_base_df['æœˆä»½'] == ring_month)].groupby('çœåŒº')['æ•°é‡(ç®±)'].sum().reset_index().rename(columns={'æ•°é‡(ç®±)': 'ç¯æ¯”å‡ºåº“(ç®±)'})
                        prov_ring = pd.merge(s_prov_ring[['çœåŒº', 'æ‰«ç ç®±æ•°']], o_prov_ring, on='çœåŒº', how='outer').fillna(0)
                        prov_ring['ç¯æ¯”æ‰«ç (ç®±)'] = prov_ring['æ‰«ç ç®±æ•°']
                        prov_ring['ç¯æ¯”æ‰«ç ç‡'] = prov_ring.apply(lambda x: x['ç¯æ¯”æ‰«ç (ç®±)'] / x['ç¯æ¯”å‡ºåº“(ç®±)'] if x['ç¯æ¯”å‡ºåº“(ç®±)'] > 0 else 0, axis=1)
                        prov_ring = prov_ring[['çœåŒº', 'ç¯æ¯”æ‰«ç ç‡']]

                        # Merge All
                        prov_final = pd.merge(prov_cur, s_prov_day[['çœåŒº', 'æœ¬æ—¥æ‰«ç (ç®±)']], on='çœåŒº', how='outer')
                        if o_prov_day is not None:
                            prov_final = pd.merge(prov_final, o_prov_day, on='çœåŒº', how='outer')
                        prov_final = pd.merge(prov_final, prov_last[['çœåŒº', 'åŒæœŸå‡ºåº“(ç®±)', 'åŒæœŸæ‰«ç (ç®±)', 'åŒæœŸæ‰«ç ç‡']], on='çœåŒº', how='outer')
                        prov_final = pd.merge(prov_final, prov_ring[['çœåŒº', 'ç¯æ¯”æ‰«ç ç‡']], on='çœåŒº', how='left').fillna(0)
                        prov_final['ç¯æ¯”å¢é•¿'] = prov_final['æœ¬æœˆæ‰«ç ç‡'] - prov_final['ç¯æ¯”æ‰«ç ç‡']
                        if 'ä»Šæ—¥å‡ºåº“(ç®±)' not in prov_final.columns:
                            prov_final['ä»Šæ—¥å‡ºåº“(ç®±)'] = 0.0
                        prov_final['æœ¬æ—¥æ‰«ç ç‡'] = prov_final.apply(lambda x: x['æœ¬æ—¥æ‰«ç (ç®±)'] / x['ä»Šæ—¥å‡ºåº“(ç®±)'] if x.get('ä»Šæ—¥å‡ºåº“(ç®±)', 0) > 0 else 0, axis=1)

                        prov_disp = prov_final[['çœåŒº', 'æœ¬æ—¥æ‰«ç (ç®±)', 'ä»Šæ—¥å‡ºåº“(ç®±)', 'æœ¬æ—¥æ‰«ç ç‡', 'æœ¬æœˆå‡ºåº“(ç®±)', 'æœ¬æœˆæ‰«ç (ç®±)', 'æœ¬æœˆæ‰«ç ç‡', 'åŒæœŸå‡ºåº“(ç®±)', 'åŒæœŸæ‰«ç (ç®±)', 'åŒæœŸæ‰«ç ç‡', 'ç¯æ¯”æ‰«ç ç‡', 'ç¯æ¯”å¢é•¿']].copy()
                        prov_disp = prov_disp.sort_values('æœ¬æœˆæ‰«ç (ç®±)', ascending=False)
                        prov_disp = prov_disp.rename(columns={'æœ¬æ—¥æ‰«ç (ç®±)': 'ä»Šæ—¥æ‰«ç (ç®±)'})
                        prov_column_defs = [
                            {"headerName": "çœåŒº", "field": "çœåŒº", "pinned": "left", "minWidth": 110},
                            {"headerName": f"ä»Šæ—¥ï¼ˆ{cur_month}æœˆ{cur_day}æ—¥ï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "ä»Šæ—¥å‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "ä»Šæ—¥æ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "æœ¬æ—¥æ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"æœ¬æœˆï¼ˆ{cur_month}æœˆï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "æœ¬æœˆå‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "æœ¬æœˆæ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "æœ¬æœˆæ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"åŒæœŸï¼ˆ{last_year}å¹´{cur_month}æœˆï¼‰", "children": [
                                {"headerName": "å‡ºåº“(ç®±)", "field": "åŒæœŸå‡ºåº“(ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç (ç®±)", "field": "åŒæœŸæ‰«ç (ç®±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "æ‰«ç ç‡", "field": "åŒæœŸæ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": "ç¯æ¯”", "children": [
                                {"headerName": "æ‰«ç ç‡", "field": "ç¯æ¯”æ‰«ç ç‡", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                                {"headerName": "å¢é•¿", "field": "ç¯æ¯”å¢é•¿", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO, "cellStyle": JS_COLOR_CONDITIONAL},
                            ]},
                        ]

                        show_aggrid_table(prov_disp, key="scan_prov_ag", column_defs=prov_column_defs)

                    with tab_s_map:
                        if ("ç»åº¦" not in df_s_flt.columns) or ("çº¬åº¦" not in df_s_flt.columns):
                            st.info("æœªæ£€æµ‹åˆ°ç»çº¬åº¦åˆ—ï¼šè¯·ç¡®è®¤æ‰«ç æ•°æ®Sheetçš„Måˆ—ä¸ºç»çº¬åº¦ï¼ˆå½¢å¦‚ 116.4,39.9 æˆ– 39.9,116.4ï¼‰ã€‚")
                        else:
                            c_map1, c_map2, c_map3 = st.columns([1.1, 1.1, 1.2])
                            metric_mode = c_map1.radio("å¯¹æ¯”å£å¾„", ["æ‰«ç æ•°", "æ‰«ç ç‡"], horizontal=True, key="scan_map_metric_mode")
                            period_mode = c_map2.radio("æ—¶é—´èŒƒå›´", ["ä»Šæ—¥", "æœ¬æœˆ", "æœ¬å¹´"], horizontal=True, key="scan_map_period")
                            style_mode = c_map3.radio("åœ°å›¾æ ·å¼", ["è¯¦ç»†", "ç®€æ´"], horizontal=True, key="scan_map_style_mode")

                            c_map4, c_map5 = st.columns([1.3, 1.0])
                            prov_opts_map = ["å…¨å›½"] + sorted([p for p in df_s_flt["çœåŒº"].unique().tolist() if str(p).strip() != ""])
                            focus_prov = c_map4.selectbox("çœåŒºèšç„¦", prov_opts_map, key="scan_map_focus_prov")
                            palette_mode = c_map5.radio("é…è‰²", ["é«˜å¯¹æ¯”", "è‰²ç›²å‹å¥½"], horizontal=True, key="scan_map_palette")

                            c_map6, c_map7 = st.columns([1.2, 1.1])
                            basemap_provider = c_map6.selectbox("åº•å›¾æ¥æº", ["é«˜å¾·(å›½å†…)", "OpenStreetMap(å¤–ç½‘)", "æ— åº•å›¾(ç¦»çº¿)", "è‡ªå®šä¹‰ç“¦ç‰‡(å†…ç½‘/è‡ªå»º)"], key="scan_map_basemap_provider")
                            custom_tile_url = ""
                            if basemap_provider == "è‡ªå®šä¹‰ç“¦ç‰‡(å†…ç½‘/è‡ªå»º)":
                                custom_tile_url = c_map7.text_input("ç“¦ç‰‡URLæ¨¡æ¿", value="http://127.0.0.1:8080/{z}/{x}/{y}.png", key="scan_map_custom_tile_url")
                            else:
                                c_map7.write("")

                            show_cb_key = "scan_map_show_colorbar"
                            if show_cb_key not in st.session_state:
                                st.session_state[show_cb_key] = False
                            cb_label = "æ˜¾ç¤ºé¢œè‰²åˆ»åº¦" if not st.session_state[show_cb_key] else "éšè—é¢œè‰²åˆ»åº¦"
                            if st.button(cb_label, key="scan_map_toggle_colorbar"):
                                st.session_state[show_cb_key] = not bool(st.session_state[show_cb_key])
                                st.rerun()

                            df_map = df_s_flt.copy()
                            if period_mode == "ä»Šæ—¥":
                                df_map = df_map[(df_map["å¹´ä»½"] == cur_year) & (df_map["æœˆä»½"] == cur_month) & (df_map["æ—¥"] == cur_day)]
                            elif period_mode == "æœ¬æœˆ":
                                df_map = df_map[(df_map["å¹´ä»½"] == cur_year) & (df_map["æœˆä»½"] == cur_month)]
                            else:
                                df_map = df_map[df_map["å¹´ä»½"] == cur_year]

                            if focus_prov != "å…¨å›½":
                                df_map = df_map[df_map["çœåŒº"] == focus_prov]

                            df_map = df_map.dropna(subset=["ç»åº¦", "çº¬åº¦"])
                            df_map = df_map[df_map["ç»åº¦"].between(70, 140) & df_map["çº¬åº¦"].between(0, 60)]

                            if df_map.empty:
                                st.info("å½“å‰ç­›é€‰ä¸å£å¾„ä¸‹æ²¡æœ‰å¯ç”¨çš„ç»çº¬åº¦æ•°æ®ã€‚")
                            else:
                                center_lat = float(df_map["çº¬åº¦"].mean())
                                center_lon = float(df_map["ç»åº¦"].mean())
                                default_zoom = 3.1 if focus_prov == "å…¨å›½" else 4.9
                                min_zoom, max_zoom = 2.2, 10.5

                                zoom_key = "scan_map_zoom"
                                if zoom_key not in st.session_state:
                                    st.session_state[zoom_key] = default_zoom
                                if st.session_state[zoom_key] < min_zoom or st.session_state[zoom_key] > max_zoom:
                                    st.session_state[zoom_key] = default_zoom

                                zc1, zc2, zc3, zc4 = st.columns([0.13, 0.13, 0.18, 0.56])
                                if zc1.button("ï¼‹", key="scan_map_zoom_in"):
                                    st.session_state[zoom_key] = min(max_zoom, float(st.session_state[zoom_key]) + 0.6)
                                    st.rerun()
                                if zc2.button("ï¼", key="scan_map_zoom_out"):
                                    st.session_state[zoom_key] = max(min_zoom, float(st.session_state[zoom_key]) - 0.6)
                                    st.rerun()
                                if zc3.button("å¤ä½", key="scan_map_zoom_reset"):
                                    st.session_state[zoom_key] = default_zoom
                                    st.rerun()
                                zc4.slider("ç¼©æ”¾", min_value=min_zoom, max_value=max_zoom, value=float(st.session_state[zoom_key]), step=0.1, key=zoom_key)

                                basemap_layers = None
                                if basemap_provider == "OpenStreetMap(å¤–ç½‘)":
                                    map_style = "carto-positron" if style_mode == "ç®€æ´" else "open-street-map"
                                elif basemap_provider == "é«˜å¾·(å›½å†…)":
                                    map_style = "white-bg"
                                    gaode_style = "7" if style_mode == "è¯¦ç»†" else "8"
                                    gaode_url = f"https://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&size=1&scale=1&style={gaode_style}&x={{x}}&y={{y}}&z={{z}}"
                                    basemap_layers = [{"sourcetype": "raster", "source": [gaode_url], "below": "traces"}]
                                elif basemap_provider == "è‡ªå®šä¹‰ç“¦ç‰‡(å†…ç½‘/è‡ªå»º)":
                                    map_style = "white-bg"
                                    _u = (custom_tile_url or "").strip()
                                    if _u:
                                        basemap_layers = [{"sourcetype": "raster", "source": [_u], "below": "traces"}]
                                else:
                                    map_style = "white-bg"
                                marker_opacity = 0.86
                                color_scale_count = "Turbo" if palette_mode == "é«˜å¯¹æ¯”" else "Cividis"
                                color_scale_rate = "Viridis" if palette_mode == "é«˜å¯¹æ¯”" else "Cividis"
                                point_scale = [
                                    [0.0, "#00C853"],
                                    [0.35, "#00C853"],
                                    [0.65, "#FFEB3B"],
                                    [0.82, "#FF9800"],
                                    [1.0, "#F44336"],
                                ]

                                if metric_mode == "æ‰«ç æ•°":
                                    c_u1, c_u2 = st.columns([0.55, 0.45])
                                    unit_mode = c_u1.radio("å•ä½", ["å¬", "ç®±"], horizontal=True, key="scan_map_unit")
                                    render_mode = c_u2.radio("æ¸²æŸ“æ–¹å¼", ["çƒ­åŠ›", "æ ‡ç‚¹"], horizontal=True, key="scan_map_render_mode")
                                    precision = st.slider("åæ ‡èšåˆç²¾åº¦(å°æ•°ä½)", 0, 3, 2, key="scan_map_precision")
                                    df_grid = df_map[["ç»åº¦", "çº¬åº¦"]].copy()
                                    df_grid["ç»åº¦"] = df_grid["ç»åº¦"].round(int(precision))
                                    df_grid["çº¬åº¦"] = df_grid["çº¬åº¦"].round(int(precision))
                                    df_grid = df_grid.groupby(["ç»åº¦", "çº¬åº¦"]).size().reset_index(name="æ‰«ç å¬æ•°")
                                    df_grid["æ‰«ç ç®±æ•°"] = df_grid["æ‰«ç å¬æ•°"] / 6.0
                                    val_col = "æ‰«ç å¬æ•°" if unit_mode == "å¬" else "æ‰«ç ç®±æ•°"

                                    if render_mode == "çƒ­åŠ›":
                                        fig = px.density_mapbox(
                                            df_grid,
                                            lat="çº¬åº¦",
                                            lon="ç»åº¦",
                                            z=val_col,
                                            radius=18 if focus_prov == "å…¨å›½" else 14,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=color_scale_count,
                                            hover_data={"æ‰«ç å¬æ•°": ":,.0f", "æ‰«ç ç®±æ•°": ":,.2f"}
                                        )
                                        fig.update_traces(opacity=0.82)
                                    else:
                                        fig = px.scatter_mapbox(
                                            df_grid,
                                            lat="çº¬åº¦",
                                            lon="ç»åº¦",
                                            color=val_col,
                                            size=val_col,
                                            size_max=26,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=point_scale,
                                            hover_data={"æ‰«ç å¬æ•°": ":,.0f", "æ‰«ç ç®±æ•°": ":,.2f"}
                                        )
                                        fig.update_traces(marker={"opacity": marker_opacity})

                                    _layout_kwargs = {
                                        "mapbox_style": map_style,
                                        "margin": {"r": 0, "t": 0, "l": 0, "b": 0},
                                        "transition": {"duration": 260, "easing": "cubic-in-out"},
                                    }
                                    if basemap_layers is not None:
                                        _layout_kwargs["mapbox_layers"] = basemap_layers
                                    fig.update_layout(**_layout_kwargs)
                                    show_cb = bool(st.session_state.get(show_cb_key, False))
                                    cb_style = {"thickness": 10, "len": 0.55, "x": 1.0, "xpad": 0, "y": 0.5, "bgcolor": "rgba(255,255,255,0.25)", "outlinewidth": 0, "title": {"text": ""}}
                                    for _ax_name in [k for k in fig.layout if str(k).startswith("coloraxis")]:
                                        try:
                                            fig.layout[_ax_name].showscale = show_cb
                                        except Exception:
                                            pass
                                        if show_cb:
                                            try:
                                                fig.layout[_ax_name].colorbar = cb_style
                                            except Exception:
                                                pass
                                    for _t in fig.data:
                                        try:
                                            _t.update(showscale=show_cb)
                                        except Exception:
                                            pass
                                    st.plotly_chart(
                                        fig,
                                        use_container_width=True,
                                        config={"scrollZoom": True, "displayModeBar": True, "displaylogo": False, "responsive": True}
                                    )
                                else:
                                    render_mode_rate = st.radio("æ¸²æŸ“æ–¹å¼", ["çƒ­åŠ›", "æ ‡ç‚¹"], horizontal=True, key="scan_map_render_mode_rate")
                                    scan_by_prov = df_map.groupby("çœåŒº").size().reset_index(name="æ‰«ç å¬æ•°")
                                    scan_by_prov["æ‰«ç ç®±æ•°"] = scan_by_prov["æ‰«ç å¬æ•°"] / 6.0
                                    cent = df_map.groupby("çœåŒº")[["ç»åº¦", "çº¬åº¦"]].mean().reset_index()
                                    prov_map = pd.merge(scan_by_prov, cent, on="çœåŒº", how="left")
                                    prov_map["å‡ºåº“(ç®±)"] = 0.0

                                    if out_base_df is not None and not getattr(out_base_df, "empty", True) and ("çœåŒº" in out_base_df.columns) and ("æ•°é‡(ç®±)" in out_base_df.columns):
                                        out_map = out_base_df.copy()
                                        if period_mode == "ä»Šæ—¥":
                                            out_map = out_map[(out_map["å¹´ä»½"] == cur_year) & (out_map["æœˆä»½"] == cur_month) & (out_map["æ—¥"] == cur_day)]
                                        elif period_mode == "æœ¬æœˆ":
                                            out_map = out_map[(out_map["å¹´ä»½"] == cur_year) & (out_map["æœˆä»½"] == cur_month)]
                                        else:
                                            out_map = out_map[out_map["å¹´ä»½"] == cur_year]
                                        out_prov = out_map.groupby("çœåŒº")["æ•°é‡(ç®±)"].sum().reset_index().rename(columns={"æ•°é‡(ç®±)": "å‡ºåº“(ç®±)"})
                                        prov_map = pd.merge(prov_map.drop(columns=["å‡ºåº“(ç®±)"], errors="ignore"), out_prov, on="çœåŒº", how="left")
                                        prov_map["å‡ºåº“(ç®±)"] = pd.to_numeric(prov_map.get("å‡ºåº“(ç®±)"), errors="coerce").fillna(0.0)

                                    prov_map["æ‰«ç ç‡"] = prov_map.apply(lambda x: x["æ‰«ç ç®±æ•°"] / x["å‡ºåº“(ç®±)"] if x["å‡ºåº“(ç®±)"] > 0 else None, axis=1)
                                    prov_map = prov_map.dropna(subset=["ç»åº¦", "çº¬åº¦"])

                                    if render_mode_rate == "çƒ­åŠ›":
                                        fig = px.density_mapbox(
                                            prov_map.dropna(subset=["æ‰«ç ç‡"]),
                                            lat="çº¬åº¦",
                                            lon="ç»åº¦",
                                            z="æ‰«ç ç‡",
                                            radius=36 if focus_prov == "å…¨å›½" else 24,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=color_scale_rate,
                                            hover_data={"çœåŒº": True, "æ‰«ç å¬æ•°": ":,.0f", "æ‰«ç ç®±æ•°": ":,.2f", "å‡ºåº“(ç®±)": ":,.0f", "æ‰«ç ç‡": ":.2%"}
                                        )
                                        fig.update_traces(opacity=0.82)
                                    else:
                                        fig = px.scatter_mapbox(
                                            prov_map,
                                            lat="çº¬åº¦",
                                            lon="ç»åº¦",
                                            color="æ‰«ç ç‡",
                                            size="æ‰«ç ç®±æ•°",
                                            size_max=42,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=point_scale,
                                            hover_name="çœåŒº",
                                            hover_data={"æ‰«ç å¬æ•°": ":,.0f", "æ‰«ç ç®±æ•°": ":,.2f", "å‡ºåº“(ç®±)": ":,.0f", "æ‰«ç ç‡": ":.2%"}
                                        )
                                        fig.update_traces(marker={"opacity": marker_opacity})
                                    _layout_kwargs = {
                                        "mapbox_style": map_style,
                                        "margin": {"r": 0, "t": 0, "l": 0, "b": 0},
                                        "transition": {"duration": 260, "easing": "cubic-in-out"},
                                    }
                                    if basemap_layers is not None:
                                        _layout_kwargs["mapbox_layers"] = basemap_layers
                                    fig.update_layout(**_layout_kwargs)
                                    show_cb = bool(st.session_state.get(show_cb_key, False))
                                    cb_style = {"thickness": 10, "len": 0.55, "x": 1.0, "xpad": 0, "y": 0.5, "bgcolor": "rgba(255,255,255,0.25)", "outlinewidth": 0, "title": {"text": ""}}
                                    for _ax_name in [k for k in fig.layout if str(k).startswith("coloraxis")]:
                                        try:
                                            fig.layout[_ax_name].showscale = show_cb
                                        except Exception:
                                            pass
                                        if show_cb:
                                            try:
                                                fig.layout[_ax_name].colorbar = cb_style
                                            except Exception:
                                                pass
                                    for _t in fig.data:
                                        try:
                                            _t.update(showscale=show_cb)
                                        except Exception:
                                            pass
                                    st.plotly_chart(
                                        fig,
                                        use_container_width=True,
                                        config={"scrollZoom": True, "displayModeBar": True, "displaylogo": False, "responsive": True}
                                    )

                else:
                    st.info("è¯·åœ¨Excelä¸­åŒ…å«ç¬¬6ä¸ªSheetï¼ˆæ‰«ç æ•°æ®ï¼‰ä»¥æŸ¥çœ‹æ­¤åˆ†æã€‚")

            # === TAB 3: ABCD ANALYSIS ===
            with tab3:
                st.subheader("ğŸ“Š Q3 vs Q4 é—¨åº—æ•ˆèƒ½å¯¹æ¯”åˆ†æ")
                
                # Check for Q3/Q4 columns
                q3_cols = [c for c in month_cols if c in ['7æœˆ', '8æœˆ', '9æœˆ']]
                q4_cols = [c for c in month_cols if c in ['10æœˆ', '11æœˆ', '12æœˆ']]
                
                if not q3_cols or not q4_cols:
                    st.warning("âš ï¸ æ•°æ®æºç¼ºå¤±7-12æœˆçš„å®Œæ•´æ•°æ®ï¼Œæ— æ³•è¿›è¡ŒQ3 vs Q4å¯¹æ¯”åˆ†æ")
                else:
                    # Logic
                    # Calculate Q3 Class
                    df['Q3_Sum'] = df[q3_cols].sum(axis=1)
                    df['Q3_Avg'] = df['Q3_Sum'] / 3
                    
                    # Calculate Q4 Class
                    df['Q4_Sum'] = df[q4_cols].sum(axis=1)
                    df['Q4_Avg'] = df['Q4_Sum'] / 3
                    
                    def classify_score(x):
                        if x >= 4: return 'A'
                        elif 2 <= x < 4: return 'B'
                        elif 1 <= x < 2: return 'C'
                        else: return 'D'
                        
                    df['Class_Q3'] = df['Q3_Avg'].apply(classify_score)
                    df['Class_Q4'] = df['Q4_Avg'].apply(classify_score)
                    
                    # Comparison Metrics
                    q3_counts = df['Class_Q3'].value_counts().sort_index()
                    q4_counts = df['Class_Q4'].value_counts().sort_index()
                    
                    # Overview Cards
                    c1, c2, c3, c4 = st.columns(4)
                    
                    def render_metric(col, cls_label):
                        curr = q4_counts.get(cls_label, 0)
                        prev = q3_counts.get(cls_label, 0)
                        delta = curr - prev
                        col.metric(f"{cls_label}ç±»é—¨åº— (Q4)", fmt_num(curr), f"{fmt_num(delta)} (ç¯æ¯”)")
                        
                    render_metric(c1, 'A')
                    render_metric(c2, 'B')
                    render_metric(c3, 'C')
                    render_metric(c4, 'D')
                    
                    st.markdown("---")
                    
                    # Province Comparison Chart
                    st.subheader("ğŸ—ºï¸ å„çœåŒºABCDç±»é—¨åº—æ•°é‡å¯¹æ¯” (Q3 vs Q4)")
                    
                    # Prepare Data for Chart
                    # Group by Province and Class for Q3
                    prov_q3 = df.groupby(['çœåŒº', 'Class_Q3']).size().reset_index(name='Count')
                    prov_q3['Period'] = 'Q3'
                    prov_q3.rename(columns={'Class_Q3': 'Class'}, inplace=True)
                    
                    # Group by Province and Class for Q4
                    prov_q4 = df.groupby(['çœåŒº', 'Class_Q4']).size().reset_index(name='Count')
                    prov_q4['Period'] = 'Q4'
                    prov_q4.rename(columns={'Class_Q4': 'Class'}, inplace=True)
                    
                    # Combine
                    prov_comp = pd.concat([prov_q3, prov_q4])
                    
                    # Interactive Selection
                    sel_period = st.radio("é€‰æ‹©å±•ç¤ºå‘¨æœŸ:", ["Q4 (æœ¬æœŸ)", "Q3 (ä¸ŠæœŸ)"], horizontal=True)
                    target_period = 'Q4' if 'Q4' in sel_period else 'Q3'
                    
                    chart_data = prov_comp[prov_comp['Period'] == target_period]
                    
                    fig_bar_prov_class = px.bar(chart_data, x='çœåŒº', y='Count', color='Class',
                                               title=f"å„çœåŒºé—¨åº—ç­‰çº§åˆ†å¸ƒ ({target_period})",
                                               category_orders={"Class": ["A", "B", "C", "D"]},
                                               color_discrete_map={'A':'#FFC400', 'B':'#6A3AD0', 'C':'#B79BFF', 'D':'#8A8AA3'},
                                               text='Count')
                    fig_bar_prov_class.update_traces(textposition='inside', texttemplate='%{y:,.1~f}', hovertemplate='çœåŒº: %{x}<br>æ•°é‡: %{y:,.1~f}<extra></extra>')
                    fig_bar_prov_class.update_layout(yaxis_title="é—¨åº—æ•°é‡", xaxis_title="çœåŒº", yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                    st.plotly_chart(fig_bar_prov_class, use_container_width=True)
                    
                    st.markdown("---")
                    
                    # Migration Matrix
                    st.subheader("ğŸ”„ é—¨åº—ç­‰çº§å˜åŠ¨æ˜ç»†")
                    
                    # Define Change Type
                    def get_change_type(row):
                        order = {'A': 4, 'B': 3, 'C': 2, 'D': 1}
                        score_q3 = order[row['Class_Q3']]
                        score_q4 = order[row['Class_Q4']]
                        
                        if score_q3 == score_q4: return 'æŒå¹³'
                        elif score_q4 > score_q3: return 'å‡çº§ â¬†ï¸'
                        else: return 'é™çº§ â¬‡ï¸'
                        
                    df['å˜åŠ¨ç±»å‹'] = df.apply(get_change_type, axis=1)
                    
                    # Summary of Changes
                    change_counts = df['å˜åŠ¨ç±»å‹'].value_counts()
                    st.info(f"ğŸ“Š å˜åŠ¨æ¦‚è§ˆ: å‡çº§ {fmt_num(change_counts.get('å‡çº§ â¬†ï¸', 0), na='')} å®¶ | é™çº§ {fmt_num(change_counts.get('é™çº§ â¬‡ï¸', 0), na='')} å®¶ | æŒå¹³ {fmt_num(change_counts.get('æŒå¹³', 0), na='')} å®¶")
                    
                    # Detailed Table
                    # Filters
                    c_f1, c_f2, c_f3 = st.columns(3)
                    filter_prov = c_f1.selectbox("ç­›é€‰çœåŒº", ['å…¨éƒ¨'] + list(df['çœåŒº'].unique()), key='abcd_prov')
                    
                    # Distributor Filter (Dependent on Province)
                    if filter_prov != 'å…¨éƒ¨':
                        dist_opts = ['å…¨éƒ¨'] + sorted(list(df[df['çœåŒº'] == filter_prov]['ç»é”€å•†åç§°'].unique()))
                    else:
                        dist_opts = ['å…¨éƒ¨'] + sorted(list(df['ç»é”€å•†åç§°'].unique()))
                    filter_dist = c_f2.selectbox("ç­›é€‰ç»é”€å•†", dist_opts, key='abcd_dist')
                    
                    filter_change = c_f3.selectbox("ç­›é€‰å˜åŠ¨ç±»å‹", ['å…¨éƒ¨', 'å‡çº§ â¬†ï¸', 'é™çº§ â¬‡ï¸', 'æŒå¹³'], key='abcd_change')
                    
                    view_df = df.copy()
                    if filter_prov != 'å…¨éƒ¨':
                        view_df = view_df[view_df['çœåŒº'] == filter_prov]
                    if filter_dist != 'å…¨éƒ¨':
                        view_df = view_df[view_df['ç»é”€å•†åç§°'] == filter_dist]
                    if filter_change != 'å…¨éƒ¨':
                        view_df = view_df[view_df['å˜åŠ¨ç±»å‹'] == filter_change]
                        
                    show_aggrid_table(view_df[['çœåŒº', 'ç»é”€å•†åç§°', 'é—¨åº—åç§°', 'Class_Q3', 'Class_Q4', 'å˜åŠ¨ç±»å‹', 'Q3_Avg', 'Q4_Avg']])

            with tab_other:
                other_rank, other_query, other_detail, other_review_2025 = st.tabs(["ğŸ† æ¦œå•æ’å", "ğŸ” æŸ¥è¯¢åˆ†æ", "ğŸ“ æ•°æ®æ˜ç»†", "ğŸ“… 2025å¹´å¤ç›˜"])
                
                with other_rank:
                    # Initialize df_perf for this scope if not already present
                    if 'df_perf' not in locals():
                         if df_perf_raw is not None:
                             df_perf = df_perf_raw.copy()
                             if 'å¹´ä»½' in df_perf.columns:
                                 df_perf['å¹´ä»½'] = pd.to_numeric(df_perf['å¹´ä»½'], errors='coerce').fillna(0).astype(int)
                             if 'æœˆä»½' in df_perf.columns:
                                 df_perf['æœˆä»½'] = pd.to_numeric(df_perf['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                             
                             if 'å‘è´§é‡‘é¢' not in df_perf.columns:
                                     if 'å‘è´§ç®±æ•°' in df_perf.columns:
                                         df_perf['å‘è´§é‡‘é¢'] = df_perf['å‘è´§ç®±æ•°']
                                     else:
                                         df_perf['å‘è´§é‡‘é¢'] = 0.0
                             df_perf['å‘è´§é‡‘é¢'] = pd.to_numeric(df_perf['å‘è´§é‡‘é¢'], errors='coerce').fillna(0.0)

                             for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'å½’ç±»', 'å‘è´§ä»“', 'å¤§åˆ†ç±»', 'æœˆåˆ†æ']:
                                 if c in df_perf.columns:
                                     df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()

                             if 'å¹´ä»½' in df_perf.columns and 'æœˆä»½' in df_perf.columns:
                                 df_perf = df_perf[(df_perf['å¹´ä»½'] > 0) & (df_perf['æœˆä»½'].between(1, 12))]
                                 df_perf['å¹´æœˆ'] = pd.to_datetime(
                                     df_perf['å¹´ä»½'].astype(str) + '-' + df_perf['æœˆä»½'].astype(str).str.zfill(2) + '-01',
                                     errors='coerce'
                                 )
                             else:
                                 df_perf['å¹´æœˆ'] = pd.NaT
                         else:
                             df_perf = pd.DataFrame()

                    c_filter, c_main = st.columns([0.26, 0.74])
                    
                    with c_filter:
                        st.markdown("### ğŸ§­ ç­›é€‰åŒº")
                        
                        # Calculate Date Range from Data
                        if df_perf is not None and not df_perf.empty and 'å¹´æœˆ' in df_perf.columns:
                            valid_dates = df_perf['å¹´æœˆ'].dropna()
                            if not valid_dates.empty:
                                max_ym = valid_dates.max()
                                min_ym = valid_dates.min()
                            else:
                                max_ym = pd.Timestamp.now()
                                min_ym = max_ym - pd.DateOffset(months=12)
                        else:
                            max_ym = pd.Timestamp.now()
                            min_ym = max_ym - pd.DateOffset(months=12)

                        time_mode = st.selectbox(
                            "æ—¶é—´èŒƒå›´",
                            ["è¿‘3ä¸ªæœˆ", "è¿‘6ä¸ªæœˆ", "è¿‘12ä¸ªæœˆ", "è‡ªå®šä¹‰å¹´æœˆ"],
                            index=["è¿‘3ä¸ªæœˆ", "è¿‘6ä¸ªæœˆ", "è¿‘12ä¸ªæœˆ", "è‡ªå®šä¹‰å¹´æœˆ"].index(st.session_state.perf_time_mode) if st.session_state.perf_time_mode in ["è¿‘3ä¸ªæœˆ", "è¿‘6ä¸ªæœˆ", "è¿‘12ä¸ªæœˆ", "è‡ªå®šä¹‰å¹´æœˆ"] else 2,
                            key="perf_time_mode"
                        )

                        # Initialize default values before any condition
                        # Use pd.Timestamp to ensure correct type for comparisons
                        start_ym = pd.Timestamp(max_ym.year, max_ym.month, 1) - pd.DateOffset(months=11)
                        end_ym = pd.Timestamp(max_ym.year, max_ym.month, 1)

                        def _months_back(n):
                            end = pd.Timestamp(max_ym.year, max_ym.month, 1)
                            start = (end - pd.DateOffset(months=n - 1))
                            return start, end

                        if time_mode == "è¿‘3ä¸ªæœˆ":
                            start_ym, end_ym = _months_back(3)
                        elif time_mode == "è¿‘6ä¸ªæœˆ":
                            start_ym, end_ym = _months_back(6)
                        elif time_mode == "è¿‘12ä¸ªæœˆ":
                            start_ym, end_ym = _months_back(12)
                        else:
                                c_from, c_to = st.columns(2)
                                with c_from:
                                    start_ym = st.date_input("å¼€å§‹æœˆ", value=pd.Timestamp(max_ym.year, max_ym.month, 1) - pd.DateOffset(months=11), min_value=min_ym.date(), max_value=max_ym.date(), key="perf_start")
                                with c_to:
                                    end_ym = st.date_input("ç»“æŸæœˆ", value=max_ym.date(), min_value=min_ym.date(), max_value=max_ym.date(), key="perf_end")
                                start_ym = pd.Timestamp(pd.to_datetime(start_ym).year, pd.to_datetime(start_ym).month, 1)
                                end_ym = pd.Timestamp(pd.to_datetime(end_ym).year, pd.to_datetime(end_ym).month, 1)

                        prov_col = df_perf.get('çœåŒº', pd.Series(dtype=str))
                        prov_opts = sorted(prov_col.dropna().astype(str).str.strip().unique().tolist())
                        selected_provs = st.multiselect("çœåŒºï¼ˆå¤šé€‰ï¼‰", prov_opts, default=prov_opts if not st.session_state.perf_provs else st.session_state.perf_provs, key="perf_provs")

                        wh_opts = sorted([x for x in df_perf.get('å‘è´§ä»“', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        wh_sel = st.selectbox("å‘è´§ä»“", ["å…¨éƒ¨"] + wh_opts, index=0, key="perf_wh")

                        mid_opts = sorted([x for x in df_perf.get('ä¸­ç±»', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        mid_sel = st.selectbox("ä¸­ç±»", ["å…¨éƒ¨"] + mid_opts, index=0, key="perf_mid")

                        grp_opts = sorted([x for x in df_perf.get('å½’ç±»', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        grp_sel = st.selectbox("å½’ç±»", ["å…¨éƒ¨"] + grp_opts, index=0, key="perf_grp")

                        cat_col = 'ç±»ç›®' if 'ç±»ç›®' in df_perf.columns else ('å¤§ç±»' if 'å¤§ç±»' in df_perf.columns else None)
                        cat_opts = sorted([x for x in df_perf.get(cat_col, pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x]) if cat_col else []
                        
                        default_cats = []
                        if st.session_state.perf_cats:
                            default_cats = [c for c in st.session_state.perf_cats if c in cat_opts]
                        else:
                            default_cats = cat_opts
                            
                        cat_sel = st.multiselect("ç±»ç›®ï¼ˆå¤šé€‰ï¼‰", cat_opts, default=default_cats, key="perf_cats")

                        dist_opts = sorted([x for x in df_perf.get('ç»é”€å•†åç§°', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        dist_sel = st.multiselect("ç»é”€å•†ï¼ˆå¯é€‰ï¼‰", dist_opts, default=[], key="perf_dists")

                        df_f = df_perf.copy()
                        df_f = df_f[(df_f['å¹´æœˆ'] >= pd.Timestamp(start_ym)) & (df_f['å¹´æœˆ'] <= pd.Timestamp(end_ym))]
                        if selected_provs:
                            df_f = df_f[df_f['çœåŒº'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "å…¨éƒ¨" and 'å‘è´§ä»“' in df_f.columns:
                            df_f = df_f[df_f['å‘è´§ä»“'].astype(str) == str(wh_sel)]
                        if mid_sel != "å…¨éƒ¨" and 'ä¸­ç±»' in df_f.columns:
                            df_f = df_f[df_f['ä¸­ç±»'].astype(str) == str(mid_sel)]
                        if grp_sel != "å…¨éƒ¨" and 'å½’ç±»' in df_f.columns:
                            df_f = df_f[df_f['å½’ç±»'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_f = df_f[df_f[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_f = df_f[df_f['ç»é”€å•†åç§°'].astype(str).isin([str(x) for x in dist_sel])]

                        months_in_scope = sorted(df_f['å¹´æœˆ'].dropna().unique().tolist())
                        months_n = len(months_in_scope) if months_in_scope else 0

                        def _sum_by_month(_df):
                            return _df.groupby('å¹´æœˆ', as_index=False)['å‘è´§ç®±æ•°'].sum().rename(columns={'å‘è´§ç®±æ•°': 'å®é™…'})

                        actual_total = float(df_f['å‘è´§ç®±æ•°'].sum()) if 'å‘è´§ç®±æ•°' in df_f.columns else 0.0

                        base_start = pd.Timestamp(start_ym) - pd.DateOffset(years=1)
                        base_end = pd.Timestamp(end_ym) - pd.DateOffset(years=1)
                        df_base = df_perf.copy()
                        df_base = df_base[(df_base['å¹´æœˆ'] >= base_start) & (df_base['å¹´æœˆ'] <= base_end)]
                        if selected_provs:
                            df_base = df_base[df_base['çœåŒº'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "å…¨éƒ¨" and 'å‘è´§ä»“' in df_base.columns:
                            df_base = df_base[df_base['å‘è´§ä»“'].astype(str) == str(wh_sel)]
                        if mid_sel != "å…¨éƒ¨" and 'ä¸­ç±»' in df_base.columns:
                            df_base = df_base[df_base['ä¸­ç±»'].astype(str) == str(mid_sel)]
                        if grp_sel != "å…¨éƒ¨" and 'å½’ç±»' in df_base.columns:
                            df_base = df_base[df_base['å½’ç±»'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_base = df_base[df_base[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_base = df_base[df_base['ç»é”€å•†åç§°'].astype(str).isin([str(x) for x in dist_sel])]
                        plan_total = float(df_base['å‘è´§ç®±æ•°'].sum()) if 'å‘è´§ç®±æ•°' in df_base.columns else 0.0

                        yoy_pct = None
                        if plan_total > 0:
                            yoy_pct = (actual_total - plan_total) / plan_total

                        prev_start = pd.Timestamp(start_ym) - pd.DateOffset(months=months_n) if months_n else pd.Timestamp(start_ym) - pd.DateOffset(months=12)
                        prev_end = pd.Timestamp(end_ym) - pd.DateOffset(months=months_n) if months_n else pd.Timestamp(end_ym) - pd.DateOffset(months=12)
                        df_prev = df_perf.copy()
                        df_prev = df_prev[(df_prev['å¹´æœˆ'] >= prev_start) & (df_prev['å¹´æœˆ'] <= prev_end)]
                        if selected_provs:
                            df_prev = df_prev[df_prev['çœåŒº'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "å…¨éƒ¨" and 'å‘è´§ä»“' in df_prev.columns:
                            df_prev = df_prev[df_prev['å‘è´§ä»“'].astype(str) == str(wh_sel)]
                        if mid_sel != "å…¨éƒ¨" and 'ä¸­ç±»' in df_prev.columns:
                            df_prev = df_prev[df_prev['ä¸­ç±»'].astype(str) == str(mid_sel)]
                        if grp_sel != "å…¨éƒ¨" and 'å½’ç±»' in df_prev.columns:
                            df_prev = df_prev[df_prev['å½’ç±»'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_prev = df_prev[df_prev[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_prev = df_prev[df_prev['ç»é”€å•†åç§°'].astype(str).isin([str(x) for x in dist_sel])]
                        prev_total = float(df_prev['å‘è´§ç®±æ•°'].sum()) if 'å‘è´§ç®±æ•°' in df_prev.columns else 0.0

                        mom_pct = None
                        if prev_total > 0:
                            mom_pct = (actual_total - prev_total) / prev_total
        
                    with c_main:
                        st.subheader("ğŸª TOP 10 é—¨åº—")
                        store_rank = df.nlargest(10, 'æ€»å‡ºåº“æ•°')[['é—¨åº—åç§°', 'æ€»å‡ºåº“æ•°', 'çœåŒº']]
                        fig_store = px.bar(store_rank, x='æ€»å‡ºåº“æ•°', y='é—¨åº—åç§°', orientation='h', text='æ€»å‡ºåº“æ•°',
                                          title="é—¨åº—å‡ºåº“æ’è¡Œ (å‰10)", color='çœåŒº')
                        fig_store.update_traces(texttemplate='%{x:,.1~f}', hovertemplate='é—¨åº—: %{y}<br>æ€»å‡ºåº“æ•°: %{x:,.1~f}<extra></extra>')
                        fig_store.update_layout(yaxis_title="", yaxis={'categoryorder':'total ascending'}, xaxis=dict(tickformat=",.1~f"))
                        st.plotly_chart(fig_store, use_container_width=True)
                        
                        st.subheader("ğŸŒ çœåŒºæ’å")
                        prov_rank = df.groupby('çœåŒº')['æ€»å‡ºåº“æ•°'].sum().sort_values(ascending=False).reset_index()
                        prov_rank['æ€»å‡ºåº“æ•°'] = prov_rank['æ€»å‡ºåº“æ•°'].astype(int)
                        n_rows = len(prov_rank)
                        calc_height = (n_rows + 1) * 35 + 10
                        final_height = max(150, min(calc_height, 2000))
                        show_aggrid_table(
                            prov_rank,
                            height=final_height,
                            columns_props={'æ€»å‡ºåº“æ•°': {'type': 'bar'}}
                        )

                with other_query:
                    st.subheader("ğŸ” å¤šç»´åº¦æŸ¥è¯¢åˆ†æ")
                    
                    sc1, sc2, sc3 = st.columns(3)
                    search_provinces = ['å…¨éƒ¨'] + sorted(list(df['çœåŒº'].unique()))
                    s_prov = sc1.selectbox("é€‰æ‹©çœåŒº (Province)", search_provinces, key='s_prov')
                    
                    if s_prov != 'å…¨éƒ¨':
                        s_dist_opts = ['å…¨éƒ¨'] + sorted(list(df[df['çœåŒº'] == s_prov]['ç»é”€å•†åç§°'].unique()))
                    else:
                        s_dist_opts = ['å…¨éƒ¨'] + sorted(list(df['ç»é”€å•†åç§°'].unique()))
                    s_dist = sc2.selectbox("é€‰æ‹©ç»é”€å•† (Distributor)", s_dist_opts, key='s_dist')
                    
                    df_store_filter = df.copy()
                    if s_prov != 'å…¨éƒ¨':
                        df_store_filter = df_store_filter[df_store_filter['çœåŒº'] == s_prov]
                    if s_dist != 'å…¨éƒ¨':
                        df_store_filter = df_store_filter[df_store_filter['ç»é”€å•†åç§°'] == s_dist]
                        
                    s_store_opts = ['å…¨éƒ¨'] + sorted(list(df_store_filter['é—¨åº—åç§°'].unique()))
                    s_store = sc3.selectbox("é€‰æ‹©é—¨åº— (Store)", s_store_opts, key='s_store')

                    st.markdown("---")
                    
                    if s_store != 'å…¨éƒ¨':
                        store_row = df_store_filter[df_store_filter['é—¨åº—åç§°'] == s_store].iloc[0]
                        st.markdown(f"### ğŸª é—¨åº—è¯¦æƒ…: {s_store}")
                        st.caption(f"æ‰€å±ç»é”€å•†: {store_row['ç»é”€å•†åç§°']} | æ‰€å±çœåŒº: {store_row['çœåŒº']}")
                        
                        if month_cols:
                            row_trend = pd.DataFrame({'æœˆä»½': month_cols, 'å‡ºåº“æ•°': [store_row[c] for c in month_cols]})
                            row_trend['Month_Num'] = row_trend['æœˆä»½'].str.extract(r'(\d+)')[0].astype(int)
                            row_trend = row_trend.sort_values('Month_Num')
                            fig_s = px.line(row_trend, x='æœˆä»½', y='å‡ºåº“æ•°', markers=True, text='å‡ºåº“æ•°', title=f"{s_store} - æœˆåº¦å‡ºåº“è¶‹åŠ¿")
                            fig_s.update_traces(
                                mode='lines+markers+text',
                                line_color='#6A3AD0',
                                line_width=3,
                                hovertemplate='æœˆä»½: %{x}<br>å‡ºåº“æ•°: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_s.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_s, use_container_width=True)
                            show_aggrid_table(pd.DataFrame([store_row]), height=150, key="s_store_table")

                    elif s_dist != 'å…¨éƒ¨':
                        st.markdown(f"### ğŸ¢ ç»é”€å•†è¯¦æƒ…: {s_dist}")
                        dist_sub = df[df['ç»é”€å•†åç§°'] == s_dist]
                        st.caption(f"è¦†ç›–çœåŒº: {', '.join(dist_sub['çœåŒº'].unique())} | æ——ä¸‹é—¨åº—æ•°: {len(dist_sub)}")
                        
                        if month_cols:
                            dist_trend = pd.DataFrame({'æœˆä»½': month_cols, 'å‡ºåº“æ•°': dist_sub[month_cols].sum().values})
                            dist_trend['Month_Num'] = dist_trend['æœˆä»½'].str.extract(r'(\d+)')[0].astype(int)
                            dist_trend = dist_trend.sort_values('Month_Num')
                            fig_d = px.line(dist_trend, x='æœˆä»½', y='å‡ºåº“æ•°', markers=True, text='å‡ºåº“æ•°', title=f"{s_dist} - æ•´ä½“æœˆåº¦å‡ºåº“è¶‹åŠ¿")
                            fig_d.update_traces(
                                mode='lines+markers+text',
                                line_color='#FFC400',
                                line_width=3,
                                hovertemplate='æœˆä»½: %{x}<br>åˆè®¡å‡ºåº“: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_d.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_d, use_container_width=True)
                            st.markdown("#### æ——ä¸‹é—¨åº—åˆ—è¡¨")
                            show_aggrid_table(dist_sub[['çœåŒº', 'é—¨åº—åç§°', 'æ€»å‡ºåº“æ•°', 'é—¨åº—åˆ†ç±»']], height=300, key="s_dist_table")

                    elif s_prov != 'å…¨éƒ¨':
                        st.markdown(f"### ğŸ™ï¸ çœåŒºè¯¦æƒ…: {s_prov}")
                        prov_sub = df[df['çœåŒº'] == s_prov]
                        st.caption(f"ç»é”€å•†æ•°é‡: {prov_sub['ç»é”€å•†åç§°'].nunique()} | é—¨åº—æ€»æ•°: {len(prov_sub)}")
                        
                        if month_cols:
                            prov_trend = pd.DataFrame({'æœˆä»½': month_cols, 'å‡ºåº“æ•°': prov_sub[month_cols].sum().values})
                            prov_trend['Month_Num'] = prov_trend['æœˆä»½'].str.extract(r'(\d+)')[0].astype(int)
                            prov_trend = prov_trend.sort_values('Month_Num')
                            fig_p = px.line(prov_trend, x='æœˆä»½', y='å‡ºåº“æ•°', markers=True, text='å‡ºåº“æ•°', title=f"{s_prov} - å…¨çœæœˆåº¦å‡ºåº“è¶‹åŠ¿")
                            fig_p.update_traces(
                                mode='lines+markers+text',
                                line_color='#5B2EA6',
                                line_width=3,
                                hovertemplate='æœˆä»½: %{x}<br>åˆè®¡å‡ºåº“: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_p.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_p, use_container_width=True)
                            st.markdown("#### çœå†…ç»é”€å•†æ¦‚è§ˆ")
                            dist_summary = prov_sub.groupby('ç»é”€å•†åç§°')['æ€»å‡ºåº“æ•°'].sum().reset_index().sort_values('æ€»å‡ºåº“æ•°', ascending=False)
                            show_aggrid_table(dist_summary, height=400, key="s_prov_table")
                    else:
                        st.info("ğŸ‘ˆ è¯·åœ¨ä¸Šæ–¹é€‰æ‹© çœåŒº / ç»é”€å•† / é—¨åº— è¿›è¡ŒæŸ¥è¯¢")

                with other_detail:
                    st.subheader("ğŸ“ æ•°æ®æ˜ç»†")
                    ds_opts = ["é—¨åº—å‡ºåº“æ±‡æ€»(Sheet1)", "åº“å­˜æ˜ç»†(Sheet2)", "å‡ºåº“åº•è¡¨(Sheet3)", "å‘è´§ä¸šç»©(Sheet4)", "ä»»åŠ¡è¡¨(Sheet5)"]
                    ds = st.selectbox("é€‰æ‹©æ•°æ®é›†", ds_opts, key="other_ds_sel")

                    df_show = None
                    if ds.startswith("é—¨åº—å‡ºåº“"):
                        df_show = df.copy()
                    elif ds.startswith("åº“å­˜") and (df_stock_raw is not None):
                        df_show = df_stock_raw.copy()
                    elif ds.startswith("å‡ºåº“åº•è¡¨") and (df_q4_raw is not None):
                        df_show = df_q4_raw.copy()
                    elif ds.startswith("å‘è´§ä¸šç»©") and (df_perf_raw is not None):
                        df_show = df_perf_raw.copy()
                    elif ds.startswith("ä»»åŠ¡è¡¨") and (df_target_raw is not None):
                        df_show = df_target_raw.copy()

                    if df_show is None or df_show.empty:
                        st.info("å½“å‰æ•°æ®é›†æ— æ•°æ®ã€‚")
                    else:
                        show_aggrid_table(df_show, height=520, key="other_detail_table")
                        out_buf = io.BytesIO()
                        try:
                            with pd.ExcelWriter(out_buf, engine='openpyxl') as writer:
                                df_show.to_excel(writer, index=False, sheet_name='data')
                        except Exception:
                            with pd.ExcelWriter(out_buf, engine='xlsxwriter') as writer:
                                df_show.to_excel(writer, index=False, sheet_name='data')
                        st.download_button(
                            "ğŸ“¥ å¯¼å‡ºå½“å‰æ•°æ®é›†ï¼ˆExcelï¼‰",
                            data=out_buf.getvalue(),
                            file_name=f"{ds}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="other_detail_download"
                        )
                
                # --- New Tab for 2025 Review ---
                with other_review_2025:
                     st.header("ğŸ“… 2025å¹´å¤ç›˜ (2025 Review)")
                     
                     # Construct df_2025 from df_perf_raw and df_target_raw
                     # Needs: 'çœåŒº', 'å®é™…å‘è´§', 'å¹´åº¦ä»»åŠ¡', 'åŒæ¯”å¢é•¿', 'äº§å“å“ç±»'
                     df_2025 = None
                     if df_perf_raw is not None and df_target_raw is not None:
                         # 1. Actuals 2025
                         # Ensure numeric
                         if 'å¹´ä»½' in df_perf_raw.columns:
                            perf_2025 = df_perf_raw[df_perf_raw['å¹´ä»½'] == 2025].copy()
                         else:
                            perf_2025 = pd.DataFrame()

                         if not perf_2025.empty:
                            if 'å‘è´§é‡‘é¢' not in perf_2025.columns and 'å‘è´§ç®±æ•°' in perf_2025.columns:
                                perf_2025['å‘è´§é‡‘é¢'] = perf_2025['å‘è´§ç®±æ•°'] # Fallback
                            
                            # Agg by Prov
                            act_prov = perf_2025.groupby('çœåŒº')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'å®é™…å‘è´§'})
                            
                            # 2. Targets 2025 (Assuming df_target_raw is 2025 targets)
                            # Target sheet: C=Prov, D=Cat, E=Month, F=Task
                            # We need to sum Task by Prov
                            tgt_prov = df_target_raw.groupby('çœåŒº')['ä»»åŠ¡é‡'].sum().reset_index().rename(columns={'ä»»åŠ¡é‡': 'å¹´åº¦ä»»åŠ¡'})
                            
                            # 3. Merge
                            df_2025 = pd.merge(act_prov, tgt_prov, on='çœåŒº', how='outer').fillna(0)
                            
                            # 4. YoY (Need 2024 data)
                            perf_2024 = df_perf_raw[df_perf_raw['å¹´ä»½'] == 2024].copy()
                            if not perf_2024.empty:
                                if 'å‘è´§é‡‘é¢' not in perf_2024.columns and 'å‘è´§ç®±æ•°' in perf_2024.columns:
                                    perf_2024['å‘è´§é‡‘é¢'] = perf_2024['å‘è´§ç®±æ•°']
                                act_2024 = perf_2024.groupby('çœåŒº')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                df_2025 = pd.merge(df_2025, act_2024, on='çœåŒº', how='left').fillna(0)
                                df_2025['åŒæ¯”å¢é•¿'] = df_2025.apply(lambda x: ((x['å®é™…å‘è´§'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                            else:
                                df_2025['åŒæ¯”å¢é•¿'] = 0.0
                                
                            # 5. Category Breakdown (Optional, if 'äº§å“å“ç±»' needed)
                            # Create a separate df for category view if needed, or try to add it to df_2025?
                            # The code expects df_2025 to have 'äº§å“å“ç±»' column if possible. 
                            # But df_2025 above is aggregated by Province. 
                            # If we want Category breakdown, we need a different aggregation.
                            # Let's check usage: 
                            # prov_summ = df_2025.groupby('çœåŒº')... -> This works on the prov-agg df
                            # cat_summ = df_2025.groupby('äº§å“å“ç±»')... -> This implies df_2025 should be granular?
                            # If df_2025 is granular (Prov, Cat), we can do both.
                            
                            # Let's try to build granular df_2025 (Prov, Cat)
                            cat_col_p = 'ç±»ç›®' if 'ç±»ç›®' in perf_2025.columns else ('å¤§ç±»' if 'å¤§ç±»' in perf_2025.columns else 'å¤§åˆ†ç±»')
                            if cat_col_p not in perf_2025.columns: cat_col_p = 'çœåŒº' # Fallback
                            
                            act_gran = perf_2025.groupby(['çœåŒº', cat_col_p])['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'å®é™…å‘è´§', cat_col_p: 'äº§å“å“ç±»'})
                            
                            # Target Granular
                            # Sheet 5: 'å“ç±»' column exists?
                            if 'å“ç±»' in df_target_raw.columns:
                                tgt_gran = df_target_raw.groupby(['çœåŒº', 'å“ç±»'])['ä»»åŠ¡é‡'].sum().reset_index().rename(columns={'ä»»åŠ¡é‡': 'å¹´åº¦ä»»åŠ¡', 'å“ç±»': 'äº§å“å“ç±»'})
                            else:
                                tgt_gran = pd.DataFrame(columns=['çœåŒº', 'äº§å“å“ç±»', 'å¹´åº¦ä»»åŠ¡'])
                                
                            df_2025_g = pd.merge(act_gran, tgt_gran, on=['çœåŒº', 'äº§å“å“ç±»'], how='outer').fillna(0)
                            
                            # YoY Granular
                            if not perf_2024.empty:
                                cat_col_24 = 'ç±»ç›®' if 'ç±»ç›®' in perf_2024.columns else ('å¤§ç±»' if 'å¤§ç±»' in perf_2024.columns else 'å¤§åˆ†ç±»')
                                if cat_col_24 not in perf_2024.columns: cat_col_24 = 'çœåŒº'
                                act_2024_g = perf_2024.groupby(['çœåŒº', cat_col_24])['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ', cat_col_24: 'äº§å“å“ç±»'})
                                df_2025_g = pd.merge(df_2025_g, act_2024_g, on=['çœåŒº', 'äº§å“å“ç±»'], how='left').fillna(0)
                                df_2025_g['åŒæ¯”å¢é•¿'] = df_2025_g.apply(lambda x: ((x['å®é™…å‘è´§'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                            else:
                                df_2025_g['åŒæ¯”å¢é•¿'] = 0.0
                                
                            df_2025 = df_2025_g

                     if df_2025 is None or df_2025.empty:
                         st.warning("âš ï¸ æœªæ‰¾åˆ° 2025 å¹´å¤ç›˜æ•°æ® (Sheet2)ã€‚è¯·æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶ã€‚")
                     else:
                         # 1. Total KPI
                         st.subheader("1. æ•´ä½“å…³é”®æŒ‡æ ‡")
                         c1, c2, c3, c4 = st.columns(4)
                         total_sales = df_2025['å®é™…å‘è´§'].sum()
                         total_target = df_2025['å¹´åº¦ä»»åŠ¡'].sum()
                         ach_rate = total_sales / total_target if total_target else 0
                         yoy_growth = df_2025['åŒæ¯”å¢é•¿'].mean()  # This might need weighted avg
                         
                         c1.metric("2025æ€»å®é™…å‘è´§", fmt_num(total_sales), delta=fmt_pct_value(yoy_growth))
                         c2.metric("2025æ€»å¹´åº¦ä»»åŠ¡", fmt_num(total_target))
                         c3.metric("å¹´åº¦è¾¾æˆç‡", fmt_pct_ratio(ach_rate))
                         
                         # 2. Province Performance
                         st.subheader("2. çœåŒºè¡¨ç°æ¦‚è§ˆ")
                         prov_summ = df_2025.groupby('çœåŒº')[['å¹´åº¦ä»»åŠ¡', 'å®é™…å‘è´§', 'åŒæ¯”å¢é•¿']].sum().reset_index()
                         prov_summ['è¾¾æˆç‡'] = prov_summ['å®é™…å‘è´§'] / prov_summ['å¹´åº¦ä»»åŠ¡']
                         prov_summ = prov_summ.sort_values('å®é™…å‘è´§', ascending=False)
                         
                         show_aggrid_table(prov_summ, height=400, key="review_2025_prov")
                         
                         # 3. Category Breakdown (if available)
                         if 'äº§å“å“ç±»' in df_2025.columns:
                             st.subheader("3. å“ç±»è¡¨ç°")
                             cat_summ = df_2025.groupby('äº§å“å“ç±»')[['å®é™…å‘è´§', 'å¹´åº¦ä»»åŠ¡']].sum().reset_index()
                             cat_summ['è¾¾æˆç‡'] = cat_summ['å®é™…å‘è´§'] / cat_summ['å¹´åº¦ä»»åŠ¡']
                             
                             c_chart, c_data = st.columns([2, 1])
                             with c_chart:
                                 fig_cat = px.bar(cat_summ, x='äº§å“å“ç±»', y=['å®é™…å‘è´§', 'å¹´åº¦ä»»åŠ¡'], barmode='group', title="å“ç±»ä»»åŠ¡ vs å®é™…")
                                 st.plotly_chart(fig_cat, use_container_width=True)
                             with c_data:
                                 show_aggrid_table(cat_summ, height=300, key="review_2025_cat")


            # --- Tab 6: Inventory Analysis ---
            with tab6:
                if df_stock_raw is None:
                    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°åº“å­˜æ•°æ® (Sheet2)ã€‚è¯·ç¡®ä¿ä¸Šä¼ çš„ Excel æ–‡ä»¶åŒ…å«ç¬¬äºŒä¸ª Sheet é¡µï¼Œä¸”æ ¼å¼æ­£ç¡®ã€‚")
                    st.info("æ•°æ®æ ¼å¼è¦æ±‚ï¼š\nSheet2 éœ€åŒ…å« A-L åˆ—ï¼Œé¡ºåºä¸ºï¼šç»é”€å•†ç¼–ç ã€ç»é”€å•†åç§°ã€äº§å“ç¼–ç ã€äº§å“åç§°ã€åº“å­˜æ•°é‡ã€ç®±æ•°ã€çœåŒºåç§°ã€å®¢æˆ·ç®€ç§°ã€äº§å“å¤§ç±»ã€äº§å“å°ç±»ã€é‡é‡ã€è§„æ ¼ã€‚")
                else:
                    st.caption(f"ğŸ•’ æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    with st.expander("ğŸ› ï¸ åº“å­˜ç­›é€‰", expanded=False):
                        # Prepare filter lists
                        stock_provs = ['å…¨éƒ¨'] + sorted(list(df_stock_raw['çœåŒºåç§°'].dropna().unique()))
                        stock_dists = ['å…¨éƒ¨'] + sorted(list(df_stock_raw['ç»é”€å•†åç§°'].dropna().unique()))
                        stock_cats = ['å…¨éƒ¨'] + sorted(list(df_stock_raw['äº§å“å¤§ç±»'].dropna().unique()))
                        
                        # Helper to reset drill status
                        def reset_inv_drill():
                            st.session_state.drill_level = 1
                            st.session_state.selected_prov = None
                            st.session_state.selected_dist = None

                        # --- Subcategory Logic Adjustment ---
                        # User requirement: "Subcategory" dropdown should include 'Segment' and 'Ya Series'.
                        # When 'Segment' is selected, Specific Category options are ['1æ®µ', '2æ®µ', '3æ®µ'].
                        # When 'Ya Series' is selected, Specific Category options are ['é›…èµ‹', 'é›…è€€', 'é›…èˆ’', 'é›…æŠ¤'].
                        
                        # 1. Base Subcategories
                        base_subcats = sorted(list(df_stock_raw['äº§å“å°ç±»'].dropna().unique()))
                        # 2. Add Virtual Subcategories (Ensure uniqueness)
                        virtual_subcats = ['åˆ†æ®µ', 'é›…ç³»åˆ—']
                        stock_subcats = ['å…¨éƒ¨'] + virtual_subcats + [s for s in base_subcats if s not in virtual_subcats]
                        
                        c1, c2, c3, c4, c5 = st.columns(5)
                        with c1: s_prov = st.selectbox("çœåŒºåç§°", stock_provs, key='stock_s_prov', on_change=reset_inv_drill)
                        with c2: 
                            if s_prov != 'å…¨éƒ¨':
                                valid_dists = df_stock_raw[df_stock_raw['çœåŒºåç§°'] == s_prov]['ç»é”€å•†åç§°'].unique()
                                s_dist_opts = ['å…¨éƒ¨'] + sorted(list(valid_dists))
                            else:
                                s_dist_opts = stock_dists
                            s_dist = st.selectbox("ç»é”€å•†åç§°", s_dist_opts, key='stock_s_dist', on_change=reset_inv_drill)
                            
                        with c3: s_cat = st.selectbox("äº§å“å¤§ç±»", stock_cats, key='stock_s_cat', on_change=reset_inv_drill)
                        
                        with c4: 
                            # Dynamic filter for subcat based on cat
                            # If we are using virtual subcats, we might want to show them regardless of Category?
                            # Or only if the Category allows? Assuming 'ç¾æ€é›…æ®µç²‰' allows them.
                            if s_cat != 'å…¨éƒ¨':
                                valid_sub = df_stock_raw[df_stock_raw['äº§å“å¤§ç±»'] == s_cat]['äº§å“å°ç±»'].unique()
                                # Mix in virtuals if they make sense (assuming they are always available for filtering)
                                current_sub_opts = ['å…¨éƒ¨'] + virtual_subcats + sorted([s for s in valid_sub if s not in virtual_subcats])
                                s_sub_opts = current_sub_opts
                            else:
                                s_sub_opts = stock_subcats
                            if 'stock_s_sub' in st.session_state:
                                st.session_state.pop('stock_s_sub', None)
                            s_sub_selected = st.multiselect("äº§å“å°ç±»(å¯å¤šé€‰)", s_sub_opts, default=['å…¨éƒ¨'], key='stock_s_sub_ms', on_change=reset_inv_drill)
                        
                        with c5:
                            # --- Dynamic Specific Category Options based on Subcategory Selection ---
                            if 'åˆ†æ®µ' in s_sub_selected and 'é›…ç³»åˆ—' in s_sub_selected:
                                stock_specs = ['1æ®µ', '2æ®µ', '3æ®µ', 'é›…èµ‹', 'é›…è€€', 'é›…èˆ’', 'é›…æŠ¤']
                            elif 'åˆ†æ®µ' in s_sub_selected:
                                stock_specs = ['1æ®µ', '2æ®µ', '3æ®µ']
                            elif 'é›…ç³»åˆ—' in s_sub_selected:
                                stock_specs = ['é›…èµ‹', 'é›…è€€', 'é›…èˆ’', 'é›…æŠ¤']
                            else:
                                raw_specs = df_stock_raw['å…·ä½“åˆ†ç±»'].dropna().unique()
                                spec_opts = set(raw_specs)
                                stock_specs = sorted(list(spec_opts))
                                
                            s_spec = st.multiselect("å…·ä½“åˆ†ç±» (æ”¯æŒå¤šé€‰)", stock_specs, default=[], placeholder="é€‰æ‹©å…·ä½“åˆ†ç±»...", on_change=reset_inv_drill)
                        
                        # Apply Filters
                        df_s_filtered = df_stock_raw.copy()
                        if s_prov != 'å…¨éƒ¨': df_s_filtered = df_s_filtered[df_s_filtered['çœåŒºåç§°'] == s_prov]
                        if s_dist != 'å…¨éƒ¨': df_s_filtered = df_s_filtered[df_s_filtered['ç»é”€å•†åç§°'] == s_dist]
                        if s_cat != 'å…¨éƒ¨': df_s_filtered = df_s_filtered[df_s_filtered['äº§å“å¤§ç±»'] == s_cat]
                        
                        # --- Subcategory Filter Logic ---
                        if s_sub_selected and ('å…¨éƒ¨' not in s_sub_selected):
                            mask_sub = pd.Series(False, index=df_s_filtered.index)
                            if 'åˆ†æ®µ' in s_sub_selected:
                                mask_sub = mask_sub | (
                                    (df_s_filtered['äº§å“å¤§ç±»'].astype(str) == 'ç¾æ€é›…æ®µç²‰')
                                    & (df_s_filtered['å…·ä½“åˆ†ç±»'].fillna('').astype(str).isin(['1æ®µ', '2æ®µ', '3æ®µ']))
                                )
                            if 'é›…ç³»åˆ—' in s_sub_selected:
                                mask_sub = mask_sub | (
                                    df_s_filtered['å…·ä½“åˆ†ç±»'].fillna('').astype(str).isin(['é›…èµ‹', 'é›…è€€', 'é›…èˆ’', 'é›…æŠ¤'])
                                )
                            normal_subs = [x for x in s_sub_selected if x not in ['åˆ†æ®µ', 'é›…ç³»åˆ—', 'å…¨éƒ¨']]
                            if normal_subs:
                                mask_sub = mask_sub | df_s_filtered['äº§å“å°ç±»'].astype(str).isin([str(x) for x in normal_subs])
                            df_s_filtered = df_s_filtered[mask_sub]
                        
                        # Apply Specific Category Filter
                        if s_spec:
                            def match_spec(row_val):
                                row_val = str(row_val)
                                for sel in s_spec:
                                    if sel in row_val: return True
                                return False
                            
                            mask = df_s_filtered['å…·ä½“åˆ†ç±»'].apply(match_spec)
                            df_s_filtered = df_s_filtered[mask]
                    
                    st.markdown("---")

                    outbound_pivot = pd.DataFrame()
                    df_o_filtered = pd.DataFrame()
                    sales_agg_q4 = pd.DataFrame(columns=['ç»é”€å•†åç§°', 'Q4_Total', 'Q4_Avg'])

                    with st.expander("ğŸšš å‡ºåº“ç­›é€‰", expanded=False):
                        if df_q4_raw is None or df_q4_raw.empty:
                            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°å‡ºåº“åº•è¡¨æ•°æ® (Sheet3)ã€‚")
                        else:
                            o_raw = df_q4_raw.copy()
                            required_out_cols = ['çœåŒº', 'ç»é”€å•†åç§°', 'æ•°é‡(ç®±)', 'æœˆä»½']
                            missing_out = [c for c in required_out_cols if c not in o_raw.columns]

                            if missing_out:
                                st.warning(f"âš ï¸ å‡ºåº“åº•è¡¨ç¼ºå¤±å­—æ®µï¼š{', '.join(missing_out)}")
                            else:
                                if 'äº§å“å¤§ç±»' not in o_raw.columns:
                                    o_raw['äº§å“å¤§ç±»'] = 'å…¨éƒ¨'
                                if 'äº§å“å°ç±»' not in o_raw.columns:
                                    o_raw['äº§å“å°ç±»'] = 'å…¨éƒ¨'
                                else:
                                    o_raw['äº§å“å°ç±»'] = o_raw['äº§å“å°ç±»'].astype(str).str.strip()
                                    o_raw.loc[o_raw['äº§å“å°ç±»'].isin(['', 'nan', 'None', 'NULL', 'NaN']), 'äº§å“å°ç±»'] = pd.NA

                            out_provs = ['å…¨éƒ¨'] + sorted(o_raw['çœåŒº'].dropna().astype(str).unique().tolist())
                            out_dists_all = ['å…¨éƒ¨'] + sorted(o_raw['ç»é”€å•†åç§°'].dropna().astype(str).unique().tolist())
                            out_cats = ['å…¨éƒ¨'] + sorted(o_raw['äº§å“å¤§ç±»'].dropna().astype(str).unique().tolist())
                            out_subs_clean = o_raw['äº§å“å°ç±»'].dropna().astype(str).str.strip()
                            out_subs_clean = out_subs_clean[out_subs_clean != '']
                            out_subs_list = sorted(out_subs_clean.unique().tolist())
                            out_subs = ['å…¨éƒ¨'] + out_subs_list
                            empty_sub_cnt = int(o_raw['äº§å“å°ç±»'].isna().sum()) if 'äº§å“å°ç±»' in o_raw.columns else 0
                            dup_sub_cnt = int(out_subs_clean.shape[0] - out_subs_clean.nunique())
                            if empty_sub_cnt > 0:
                                st.warning(f"âš ï¸ Sheet3 çš„Måˆ—(äº§å“å°ç±»)å­˜åœ¨ç©ºå€¼ï¼š{empty_sub_cnt} è¡Œ")
                            if dup_sub_cnt > 0:
                                st.info(f"â„¹ï¸ Sheet3 çš„Måˆ—(äº§å“å°ç±»)å­˜åœ¨é‡å¤å€¼ï¼š{dup_sub_cnt} è¡Œï¼ˆä¸‹æ‹‰å·²è‡ªåŠ¨å»é‡ï¼‰")
                            out_month_opts = list(range(1, 13))

                            oc1, oc2, oc3, oc4, oc5 = st.columns(5)
                            with oc1:
                                o_prov = st.selectbox("çœåŒº", out_provs, key='out_s_prov')
                            with oc2:
                                if o_prov != 'å…¨éƒ¨':
                                    dists_in_prov = o_raw[o_raw['çœåŒº'].astype(str) == str(o_prov)]['ç»é”€å•†åç§°'].dropna().astype(str).unique().tolist()
                                    out_dists = ['å…¨éƒ¨'] + sorted(dists_in_prov)
                                else:
                                    out_dists = out_dists_all
                                o_dist = st.selectbox("ç»é”€å•†", out_dists, key='out_s_dist')
                            with oc3:
                                o_cat = st.selectbox("äº§å“å¤§ç±»", out_cats, key='out_s_cat')
                            with oc4:
                                if o_cat != 'å…¨éƒ¨':
                                    subs_in_cat = o_raw[o_raw['äº§å“å¤§ç±»'].astype(str) == str(o_cat)]['äº§å“å°ç±»'].dropna().astype(str).unique().tolist()
                                    out_subs2 = ['å…¨éƒ¨'] + sorted(subs_in_cat)
                                else:
                                    out_subs2 = out_subs
                                if 'out_s_sub' in st.session_state:
                                    st.session_state.pop('out_s_sub', None)
                                o_sub_selected = st.multiselect("äº§å“å°ç±»(å¯å¤šé€‰)", out_subs2, default=['å…¨éƒ¨'], key='out_s_sub_ms')
                            with oc5:
                                o_months = st.multiselect("æ—¶é—´ï¼ˆæœˆï¼‰", out_month_opts, default=[10, 11, 12], key='out_s_months')

                            df_o_filtered = o_raw.copy()
                            
                            # Filter for Year 2025 (as per Q4 definition)
                            if 'å¹´ä»½' in df_o_filtered.columns:
                                df_o_filtered = df_o_filtered[df_o_filtered['å¹´ä»½'] == 2025]
                                
                            if o_prov != 'å…¨éƒ¨':
                                df_o_filtered = df_o_filtered[df_o_filtered['çœåŒº'].astype(str) == str(o_prov)]
                            if o_dist != 'å…¨éƒ¨':
                                df_o_filtered = df_o_filtered[df_o_filtered['ç»é”€å•†åç§°'].astype(str) == str(o_dist)]
                            if o_cat != 'å…¨éƒ¨':
                                df_o_filtered = df_o_filtered[df_o_filtered['äº§å“å¤§ç±»'].astype(str) == str(o_cat)]
                            if o_sub_selected and ('å…¨éƒ¨' not in o_sub_selected):
                                df_o_filtered = df_o_filtered[df_o_filtered['äº§å“å°ç±»'].astype(str).isin([str(x) for x in o_sub_selected])]

                            def _to_month(v):
                                if pd.isna(v):
                                    return None
                                if isinstance(v, (int, float)) and not pd.isna(v):
                                    m = int(v)
                                    return m if 1 <= m <= 12 else None
                                s = str(v).strip()
                                if s.isdigit():
                                    m = int(s)
                                    return m if 1 <= m <= 12 else None
                                if 'æœˆ' in s:
                                    digits = ''.join([ch for ch in s if ch.isdigit()])
                                    if digits:
                                        for k in (2, 1):
                                            if len(digits) >= k:
                                                m = int(digits[-k:])
                                                if 1 <= m <= 12:
                                                    return m
                                    return None
                                dt = pd.to_datetime(s, errors='coerce')
                                if pd.isna(dt):
                                    return None
                                m = int(dt.month)
                                return m if 1 <= m <= 12 else None

                            df_o_filtered['æœˆ'] = df_o_filtered['æœˆä»½'].apply(_to_month)
                            df_o_filtered = df_o_filtered[df_o_filtered['æœˆ'].notna()].copy()
                            df_o_filtered['æœˆ'] = df_o_filtered['æœˆ'].astype(int)

                            if o_months:
                                df_o_filtered = df_o_filtered[df_o_filtered['æœˆ'].isin(o_months)].copy()

                            df_o_filtered['æœˆåˆ—'] = df_o_filtered['æœˆ'].astype(str) + 'æœˆ'

                            idx_cols = ['çœåŒº', 'ç»é”€å•†åç§°', 'äº§å“å¤§ç±»', 'äº§å“å°ç±»']
                            outbound_pivot = (
                                df_o_filtered
                                .pivot_table(index=idx_cols, columns='æœˆåˆ—', values='æ•°é‡(ç®±)', aggfunc='sum', fill_value=0)
                                .reset_index()
                            )

                            month_cols_full = [f"{i}æœˆ" for i in range(1, 13)]
                            for mc in month_cols_full:
                                if mc not in outbound_pivot.columns:
                                    outbound_pivot[mc] = 0

                            outbound_pivot['Q4æœˆå‡é”€'] = (outbound_pivot['10æœˆ'] + outbound_pivot['11æœˆ'] + outbound_pivot['12æœˆ']) / 3
                            outbound_pivot = outbound_pivot[idx_cols + month_cols_full + ['Q4æœˆå‡é”€']]

                            with st.expander("ğŸ“„ å‡ºåº“åˆ†æåº•è¡¨ï¼ˆSheet3ï¼‰", expanded=False):
                                show_aggrid_table(outbound_pivot, height=520, key="outbound_pivot_table")

                            if not outbound_pivot.empty:
                                dist_q4 = outbound_pivot.groupby('ç»é”€å•†åç§°')[['10æœˆ', '11æœˆ', '12æœˆ']].sum().reset_index()
                                dist_q4['Q4_Total'] = dist_q4['10æœˆ'] + dist_q4['11æœˆ'] + dist_q4['12æœˆ']
                                dist_q4['Q4_Avg'] = dist_q4['Q4_Total'] / 3
                                sales_agg_q4 = dist_q4[['ç»é”€å•†åç§°', 'Q4_Total', 'Q4_Avg']].copy()

                            out_xlsx = io.BytesIO()
                            try:
                                with pd.ExcelWriter(out_xlsx, engine='openpyxl') as writer:
                                    outbound_pivot.to_excel(writer, index=False, sheet_name='Sheet3')
                            except Exception:
                                with pd.ExcelWriter(out_xlsx, engine='xlsxwriter') as writer:
                                    outbound_pivot.to_excel(writer, index=False, sheet_name='Sheet3')
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½å‡ºåº“åˆ†æåº•è¡¨ (Excel)",
                                    data=out_xlsx.getvalue(),
                                    file_name="å‡ºåº“åˆ†æåº•è¡¨_Sheet3.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                )
                    
                    # --- Drill-down State Management ---
                    # (Initialized at top of script)
                    
                    # Threshold Config
                    with st.expander("âš™ï¸ é˜ˆå€¼é…ç½®", expanded=False):
                        c_th1, c_th2 = st.columns(2)
                        high_th = c_th1.number_input("åº“å­˜è¿‡é«˜é˜ˆå€¼ (DOS >)", value=2.0, step=0.1)
                        low_th = c_th2.number_input("åº“å­˜è¿‡ä½é˜ˆå€¼ (DOS <)", value=0.5, step=0.1)

                    # Logic:
                    # 1. Sum Stock 'ç®±æ•°' by Distributor (from filtered stock df_s_filtered)
                    # 2. Match with Sheet3 Sales 'Q4_Avg' by Distributor
                    
                    # Note: df_s_filtered 'ç»é”€å•†åç§°' is now 'å®¢æˆ·ç®€ç§°' (H column) due to load_data mapping
                    stock_agg = df_s_filtered.groupby(['çœåŒºåç§°', 'ç»é”€å•†åç§°'])['ç®±æ•°'].sum().reset_index()
                    stock_agg.rename(columns={'ç®±æ•°': 'å½“å‰åº“å­˜_ç®±'}, inplace=True)
                    stock_agg['ç»é”€å•†åç§°'] = stock_agg['ç»é”€å•†åç§°'].astype(str).str.strip()
                    
                    # Merge with Q4 sales data from Sheet3
                    # LEFT JOIN ensures we only keep distributors present in the STOCK file (filtered by top filters)
                    # However, if we filter by province in top filter, df_s_filtered only has that province.
                    # sales_agg_q4 has ALL distributors from Sheet3.
                    # Merging them attaches Sales info to the Stock info.
                    analysis_df = pd.merge(stock_agg, sales_agg_q4[['ç»é”€å•†åç§°', 'Q4_Avg']], on='ç»é”€å•†åç§°', how='left')
                    analysis_df['Q4_Avg'] = analysis_df['Q4_Avg'].fillna(0)
                    
                    # 3. Calc DOS & Status
                    analysis_df['è¿‘ä¸‰æœˆæœªå‡ºåº“'] = (analysis_df['Q4_Avg'] <= 0) & (analysis_df['å½“å‰åº“å­˜_ç®±'] > 0)

                    # Calculate DOS
                    # Optimized: Vectorized
                    q4_avg_series = analysis_df['Q4_Avg']
                    stock_series = analysis_df['å½“å‰åº“å­˜_ç®±']
                    mask_no_outbound = analysis_df.get('è¿‘ä¸‰æœˆæœªå‡ºåº“', pd.Series(False, index=analysis_df.index)).astype(bool)
                    
                    analysis_df['å¯é”€æœˆ(DOS)'] = np.where(
                        mask_no_outbound, np.nan,
                        np.where(
                            q4_avg_series <= 0, 0.0,
                            (stock_series / q4_avg_series)
                        )
                    )
                    
                    # Ensure thresholds are defined before use
                    if 'high_th' not in locals(): high_th = 2.0
                    if 'low_th' not in locals(): low_th = 0.5

                    # Optimized: Vectorized select
                    # Pre-calculate boolean mask for 'è¿‘ä¸‰æœˆæœªå‡ºåº“'
                    mask_no_outbound = analysis_df.get('è¿‘ä¸‰æœˆæœªå‡ºåº“', pd.Series(False, index=analysis_df.index)).astype(bool)
                    
                    dos_series = analysis_df['å¯é”€æœˆ(DOS)']
                    
                    conditions = [
                        mask_no_outbound,
                        pd.isna(dos_series),
                        dos_series > high_th,
                        dos_series < low_th
                    ]
                    choices = [
                        'âš« è¿‘ä¸‰æœˆæœªå‡ºåº“',
                        'ğŸŸ¢ æ­£å¸¸',
                        'ğŸ”´ åº“å­˜è¿‡é«˜',
                        'ğŸŸ  åº“å­˜ä¸è¶³'
                    ]
                    analysis_df['åº“å­˜çŠ¶æ€'] = np.select(conditions, choices, default='ğŸŸ¢ æ­£å¸¸')

                    # --- OVERVIEW METRICS (Moved Back & Enhanced) ---
                    # Calculate metrics based on the CURRENT context (filtered data analysis_df)
                    # If drill level is 1 (All Provs), it shows total.
                    # If drill level is 2 (One Prov), we should filter analysis_df to that prov for metrics?
                    # Or should metrics always reflect the TOP filters (df_s_filtered)?
                    # User request: "When I select a specific province (in filter), real-time update."
                    # df_s_filtered IS filtered by the top dropdowns. analysis_df is derived from it.
                    # So calculating from analysis_df is correct for the top filters.
                    # However, if user clicks "Drill Down" to level 2, should the metrics update to that province?
                    # User said "When I select to specific province". 
                    # If the user uses the *Sidebar/Top Filter*, df_s_filtered updates, so analysis_df updates.
                    # If the user uses *Drill Down*, st.session_state.selected_prov is set.
                    # Usually Overview Metrics reflect the *Global Context* of the current view.
                    # Let's support both: If Drill Level > 1, filter metrics to selected scope.
                    
                    metrics_df = analysis_df.copy()
                    if st.session_state.drill_level == 2 and st.session_state.selected_prov:
                        metrics_df = metrics_df[metrics_df['çœåŒºåç§°'] == st.session_state.selected_prov]
                    elif st.session_state.drill_level == 3 and st.session_state.selected_dist:
                        # For level 3, it's single distributor
                         metrics_df = metrics_df[metrics_df['ç»é”€å•†åç§°'] == st.session_state.selected_dist]

                    # Calc Metrics
                    total_stock_show = metrics_df['å½“å‰åº“å­˜_ç®±'].sum()
                    if sales_agg_q4 is not None and not sales_agg_q4.empty and 'Q4_Total' in sales_agg_q4.columns:
                        dist_scope = (
                            metrics_df['ç»é”€å•†åç§°']
                            .dropna()
                            .astype(str)
                            .str.strip()
                            .unique()
                            .tolist()
                        )
                        sales_scope = sales_agg_q4[sales_agg_q4['ç»é”€å•†åç§°'].isin(dist_scope)].copy()
                        total_q4_avg_show = float(sales_scope['Q4_Total'].sum()) / 3 if not sales_scope.empty else 0.0
                    else:
                        total_q4_avg_show = 0.0
                    
                    # DOS = Total Stock / Total Sales
                    if total_q4_avg_show > 0:
                        dos_show = total_stock_show / total_q4_avg_show
                    else:
                        dos_show = 0.0
                    
                    if metrics_df is None or metrics_df.empty or 'åº“å­˜çŠ¶æ€' not in metrics_df.columns:
                        abnormal_count_show = 0
                    else:
                        abnormal_count_show = int(
                            metrics_df['åº“å­˜çŠ¶æ€']
                            .fillna('')
                            .astype(str)
                            .str.contains('ğŸ”´|ğŸŸ |âš«', na=False)
                            .sum()
                        )
                    
                    st.markdown("### ğŸ“Š å…³é”®æŒ‡æ ‡æ¦‚è§ˆ")
                    col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                    col_m1.metric("ğŸ“¦ æ€»åº“å­˜ (ç®±)", fmt_num(total_stock_show))
                    col_m2.metric("ğŸ“‰ Q4æœˆå‡é”€", fmt_num(total_q4_avg_show))
                    col_m3.metric("ğŸ“… æ•´ä½“å¯é”€æœˆ", fmt_num(dos_show))
                    col_m4.metric("ğŸš¨ å¼‚å¸¸å®¢æˆ·æ•°", f"{abnormal_count_show} å®¶")
                    st.markdown("---")

                    rank_stock = (
                        metrics_df.groupby('ç»é”€å•†åç§°', as_index=False)['å½“å‰åº“å­˜_ç®±']
                        .sum()
                        .rename(columns={'å½“å‰åº“å­˜_ç®±': 'åº“å­˜æ•°(ç®±)'})
                    )
                    rank_stock['ç»é”€å•†åç§°'] = rank_stock['ç»é”€å•†åç§°'].astype(str).str.strip()
                    rank_stock = pd.merge(
                        rank_stock,
                        sales_agg_q4[['ç»é”€å•†åç§°', 'Q4_Avg']] if (sales_agg_q4 is not None and 'Q4_Avg' in sales_agg_q4.columns) else pd.DataFrame(columns=['ç»é”€å•†åç§°', 'Q4_Avg']),
                        on='ç»é”€å•†åç§°',
                        how='left'
                    )
                    rank_stock['Q4_Avg'] = pd.to_numeric(rank_stock.get('Q4_Avg', 0), errors='coerce').fillna(0)
                    rank_stock['è¿‘ä¸‰æœˆæœªå‡ºåº“'] = (rank_stock['Q4_Avg'] <= 0) & (rank_stock['åº“å­˜æ•°(ç®±)'] > 0)

                    def _rank_dos(row):
                        q4 = float(row.get('Q4_Avg', 0) or 0)
                        stk = float(row.get('åº“å­˜æ•°(ç®±)', 0) or 0)
                        if q4 <= 0:
                            return float('nan') if stk > 0 else 0.0
                        return stk / q4

                    rank_stock['å¯é”€æœˆ'] = rank_stock.apply(_rank_dos, axis=1)
                    rank_stock['è¿‡é«˜å·®å€¼'] = (rank_stock['å¯é”€æœˆ'] - float(high_th))
                    rank_stock['è¿‡ä½å·®å€¼'] = (float(low_th) - rank_stock['å¯é”€æœˆ'])

                    rank_stock_rankable = rank_stock[~rank_stock['è¿‘ä¸‰æœˆæœªå‡ºåº“']].copy()
                    high_top = rank_stock_rankable[rank_stock_rankable['è¿‡é«˜å·®å€¼'] > 0].copy().sort_values('è¿‡é«˜å·®å€¼', ascending=False).head(10)
                    low_top = rank_stock_rankable[rank_stock_rankable['è¿‡ä½å·®å€¼'] > 0].copy().sort_values('è¿‡ä½å·®å€¼', ascending=False).head(10)

                    st.markdown("### ğŸ† å¼‚å¸¸åº“å­˜TOP10ç»é”€å•†")
                    r1, r2 = st.columns(2)
                    with r1:
                        st.subheader("ğŸ”´ åº“å­˜è¿‡é«˜ TOP10")
                        if high_top.empty:
                            st.info("å½“å‰èŒƒå›´æ— åº“å­˜è¿‡é«˜ç»é”€å•†")
                        else:
                            high_chart = high_top.sort_values('è¿‡é«˜å·®å€¼', ascending=True).copy()
                            high_chart['æ ‡æ³¨'] = high_chart['è¿‡é«˜å·®å€¼'].map(lambda x: f"+{fmt_num(x, na='')}")
                            high_chart['_åº“å­˜æ•°_fmt'] = high_chart['åº“å­˜æ•°(ç®±)'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_q4_fmt'] = high_chart['Q4_Avg'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_dos_fmt'] = high_chart['å¯é”€æœˆ'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_diff_fmt'] = high_chart['è¿‡é«˜å·®å€¼'].map(lambda x: fmt_num(x, na=''))
                            fig_high = px.bar(
                                high_chart,
                                x='è¿‡é«˜å·®å€¼',
                                y='ç»é”€å•†åç§°',
                                orientation='h',
                                text='æ ‡æ³¨',
                                title="è¶…å‡ºè¿‡é«˜é˜ˆå€¼çš„å·®å€¼ï¼ˆå¯é”€æœˆ - é˜ˆå€¼ï¼‰",
                                color_discrete_sequence=['#E5484D'],
                                custom_data=['_åº“å­˜æ•°_fmt', '_q4_fmt', '_dos_fmt', '_diff_fmt']
                            )
                            fig_high.update_traces(
                                textposition='outside',
                                hovertemplate=(
                                    "ç»é”€å•†: %{y}<br>"
                                    "åº“å­˜æ•°(ç®±): %{customdata[0]}<br>"
                                    "Q4æœˆå‡é”€: %{customdata[1]}<br>"
                                    "å¯é”€æœˆ: %{customdata[2]}<br>"
                                    "è¶…é˜ˆå€¼å·®å€¼: +%{customdata[3]}<extra></extra>"
                                )
                            )
                            fig_high.update_layout(height=420, xaxis_title="å·®å€¼", yaxis_title="")
                            st.plotly_chart(fig_high, use_container_width=True)
                            show_aggrid_table(high_top[['ç»é”€å•†åç§°', 'åº“å­˜æ•°(ç®±)', 'Q4_Avg', 'å¯é”€æœˆ', 'è¿‡é«˜å·®å€¼']], height=250, key='high_stock_ag')

                    with r2:
                        st.subheader("ğŸŸ  åº“å­˜è¿‡ä½ TOP10")
                        if low_top.empty:
                            st.info("å½“å‰èŒƒå›´æ— åº“å­˜è¿‡ä½ç»é”€å•†")
                        else:
                            low_chart = low_top.sort_values('è¿‡ä½å·®å€¼', ascending=True).copy()
                            low_chart['æ ‡æ³¨'] = low_chart['è¿‡ä½å·®å€¼'].map(lambda x: f"+{fmt_num(x, na='')}")
                            low_chart['_åº“å­˜æ•°_fmt'] = low_chart['åº“å­˜æ•°(ç®±)'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_q4_fmt'] = low_chart['Q4_Avg'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_dos_fmt'] = low_chart['å¯é”€æœˆ'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_diff_fmt'] = low_chart['è¿‡ä½å·®å€¼'].map(lambda x: fmt_num(x, na=''))
                            fig_low = px.bar(
                                low_chart,
                                x='è¿‡ä½å·®å€¼',
                                y='ç»é”€å•†åç§°',
                                orientation='h',
                                text='æ ‡æ³¨',
                                title="ä½äºè¿‡ä½é˜ˆå€¼çš„å·®å€¼ï¼ˆé˜ˆå€¼ - å¯é”€æœˆï¼‰",
                                color_discrete_sequence=['#FFB000'],
                                custom_data=['_åº“å­˜æ•°_fmt', '_q4_fmt', '_dos_fmt', '_diff_fmt']
                            )
                            fig_low.update_traces(
                                textposition='outside',
                                hovertemplate=(
                                    "ç»é”€å•†: %{y}<br>"
                                    "åº“å­˜æ•°(ç®±): %{customdata[0]}<br>"
                                    "Q4æœˆå‡é”€: %{customdata[1]}<br>"
                                    "å¯é”€æœˆ: %{customdata[2]}<br>"
                                    "ä½äºé˜ˆå€¼å·®å€¼: +%{customdata[3]}<extra></extra>"
                                )
                            )
                            fig_low.update_layout(height=420, xaxis_title="å·®å€¼", yaxis_title="")
                            st.plotly_chart(fig_low, use_container_width=True)
                            show_aggrid_table(low_top[['ç»é”€å•†åç§°', 'åº“å­˜æ•°(ç®±)', 'Q4_Avg', 'å¯é”€æœˆ', 'è¿‡ä½å·®å€¼']], height=250, key='low_stock_ag')

                    with st.expander("ğŸ” å¯¹è´¦ä¿¡æ¯", expanded=False):
                        if df_o_filtered is None or df_o_filtered.empty or 'æœˆ' not in df_o_filtered.columns:
                            st.warning("å½“å‰ç­›é€‰ä¸‹æ— å‡ºåº“æ˜ç»†å¯å¯¹è´¦ã€‚")
                        else:
                            s10 = float(df_o_filtered[df_o_filtered['æœˆ'] == 10]['æ•°é‡(ç®±)'].sum()) if 'æ•°é‡(ç®±)' in df_o_filtered.columns else 0.0
                            s11 = float(df_o_filtered[df_o_filtered['æœˆ'] == 11]['æ•°é‡(ç®±)'].sum()) if 'æ•°é‡(ç®±)' in df_o_filtered.columns else 0.0
                            s12 = float(df_o_filtered[df_o_filtered['æœˆ'] == 12]['æ•°é‡(ç®±)'].sum()) if 'æ•°é‡(ç®±)' in df_o_filtered.columns else 0.0
                            st.write(f"å½“å‰ç­›é€‰ä¸‹Sheet3åˆè®¡ï¼š10æœˆ={fmt_num(s10)}ï¼Œ11æœˆ={fmt_num(s11)}ï¼Œ12æœˆ={fmt_num(s12)}")
                            st.write(f"å½“å‰ç­›é€‰ä¸‹Q4æœˆå‡é”€=(10+11+12)/3 = {fmt_num((s10+s11+s12)/3)}")
                            if sales_agg_q4 is not None and 'Q4_Total' in sales_agg_q4.columns:
                                dist_scope_dbg = (
                                    metrics_df['ç»é”€å•†åç§°']
                                    .dropna()
                                    .astype(str)
                                    .str.strip()
                                    .unique()
                                    .tolist()
                                )
                                matched = sales_agg_q4[sales_agg_q4['ç»é”€å•†åç§°'].isin(dist_scope_dbg)]
                                st.write(f"å½“å‰èŒƒå›´ç»é”€å•†æ•°(å»é‡)ï¼š{len(dist_scope_dbg)}ï¼ŒSheet3åŒ¹é…åˆ°ï¼š{len(matched)}")
                                st.write(f"å½“å‰èŒƒå›´Q4æœˆå‡é”€=(sum(Q4_Total))/3 = {fmt_num(float(matched['Q4_Total'].sum())/3)}")

                    # --- Navigation & Breadcrumbs ---
                    cols_nav = st.columns([1, 8])
                    if st.session_state.drill_level > 1:
                        if cols_nav[0].button("â¬…ï¸ è¿”å›"):
                            st.session_state.drill_level -= 1
                            st.rerun()
                    
                    breadcrumbs = "ğŸ  å…¨éƒ¨çœåŒº"
                    if st.session_state.drill_level >= 2:
                        breadcrumbs += f" > ğŸ“ {st.session_state.selected_prov}"
                    if st.session_state.drill_level >= 3:
                        breadcrumbs += f" > ğŸ¢ {st.session_state.selected_dist}"
                    cols_nav[1].markdown(f"**å½“å‰ä½ç½®**: {breadcrumbs}")

                    # --- Level 1: Province View ---
                    if st.session_state.drill_level == 1:
                        
                        # Agg by Prov
                        prov_agg = analysis_df.groupby('çœåŒºåç§°').agg({
                            'å½“å‰åº“å­˜_ç®±': 'sum',
                            'Q4_Avg': 'sum',
                            'ç»é”€å•†åç§°': 'count' # Count of distributors
                        }).reset_index()
                        
                        # Calc Prov DOS
                        prov_agg['å¯é”€æœˆ(DOS)'] = prov_agg.apply(lambda x: (x['å½“å‰åº“å­˜_ç®±'] / x['Q4_Avg']) if x['Q4_Avg'] > 0 else (float('nan') if x['å½“å‰åº“å­˜_ç®±'] > 0 else 0.0), axis=1)
                        
                        # Count Abnormal Distributors per Prov
                        abnormal_counts = analysis_df.groupby('çœåŒºåç§°')['åº“å­˜çŠ¶æ€'].value_counts().unstack(fill_value=0)
                        if 'ğŸ”´ åº“å­˜è¿‡é«˜' not in abnormal_counts.columns: abnormal_counts['ğŸ”´ åº“å­˜è¿‡é«˜'] = 0
                        if 'ğŸŸ  åº“å­˜ä¸è¶³' not in abnormal_counts.columns: abnormal_counts['ğŸŸ  åº“å­˜ä¸è¶³'] = 0
                        if 'âš« è¿‘ä¸‰æœˆæœªå‡ºåº“' not in abnormal_counts.columns: abnormal_counts['âš« è¿‘ä¸‰æœˆæœªå‡ºåº“'] = 0
                        
                        prov_view = pd.merge(prov_agg, abnormal_counts[['ğŸ”´ åº“å­˜è¿‡é«˜', 'ğŸŸ  åº“å­˜ä¸è¶³', 'âš« è¿‘ä¸‰æœˆæœªå‡ºåº“']], on='çœåŒºåç§°', how='left').fillna(0)
                        
                        # New Logic: Calculate Total Abnormal Count and Sort
                        prov_view['åˆè®¡å¼‚å¸¸æ•°'] = prov_view['ğŸ”´ åº“å­˜è¿‡é«˜'] + prov_view['ğŸŸ  åº“å­˜ä¸è¶³'] + prov_view['âš« è¿‘ä¸‰æœˆæœªå‡ºåº“']
                        prov_view['ç»é”€å•†æ€»æ•°'] = prov_view['ç»é”€å•†åç§°'] # Rename for clarity
                        
                        # Filter slider
                        max_abnormal = int(prov_view['åˆè®¡å¼‚å¸¸æ•°'].max()) if not prov_view.empty else 10
                        c_filter, _ = st.columns([1, 2])
                        min_abnormal_filter = c_filter.slider("ğŸ” å¼‚å¸¸æ•°è¿‡æ»¤ (â‰¥)", 0, max_abnormal, 0)
                        
                        prov_view_filtered = prov_view[prov_view['åˆè®¡å¼‚å¸¸æ•°'] >= min_abnormal_filter].copy()
                        
                        # Sort Descending by Total Abnormal Count
                        prov_view_filtered = prov_view_filtered.sort_values('åˆè®¡å¼‚å¸¸æ•°', ascending=False)
                        
                        st.markdown("### ğŸ“‹ çœåŒºåº“å­˜å¼‚å¸¸è¯¦æƒ…åˆ—è¡¨")
                        st.caption("ğŸ’¡ æç¤ºï¼š**ç›´æ¥ç‚¹å‡»è¡¨æ ¼ä¸­çš„æŸä¸€è¡Œ**ï¼Œå³å¯ä¸‹é’»æŸ¥çœ‹è¯¥çœåŒºçš„ç»é”€å•†è¯¦æƒ…ã€‚")
                        
                        # Prepare DF for display
                        display_df = prov_view_filtered[["çœåŒºåç§°", "åˆè®¡å¼‚å¸¸æ•°", "ğŸ”´ åº“å­˜è¿‡é«˜", "ğŸŸ  åº“å­˜ä¸è¶³", "âš« è¿‘ä¸‰æœˆæœªå‡ºåº“", "å½“å‰åº“å­˜_ç®±", "Q4_Avg", "å¯é”€æœˆ(DOS)"]].reset_index(drop=True)
                        
                        # Use interactive dataframe with selection
                        # Dynamic height to show all rows
                        n_rows = len(display_df)
                        # Estimate height: 35px per row + 35px header + buffer
                        calc_height = (n_rows + 1) * 35 + 10
                        # Ensure a minimum height and reasonable max height (e.g., 2000px)
                        final_height = max(150, min(calc_height, 2000))

                        ag_inv = show_aggrid_table(
                            display_df,
                            height=final_height,
                            columns_props={'åˆè®¡å¼‚å¸¸æ•°': {'type': 'bar_count'}, 'å¯é”€æœˆ(DOS)': {'type': 'number'}},
                            on_row_selected='single',
                            key='inv_prov_ag'
                        )
                        
                        # Show all province names as tags below for quick view
                        with st.expander("æŸ¥çœ‹æ‰€æœ‰çœåŒºåç§°åˆ—è¡¨ (ç‚¹å‡»å±•å¼€)", expanded=False):
                            st.markdown("  ".join([f"`{p}`" for p in display_df['çœåŒºåç§°'].tolist()]))
                        
                        # Handle Selection
                        selected_rows = ag_inv.get('selected_rows') if ag_inv else None
                        if selected_rows is not None and len(selected_rows) > 0:
                            if isinstance(selected_rows, pd.DataFrame):
                                first_row = selected_rows.iloc[0]
                            else:
                                first_row = selected_rows[0]
                            
                            selected_prov_name = first_row.get("çœåŒºåç§°") if isinstance(first_row, dict) else first_row["çœåŒºåç§°"]
                            st.session_state.selected_prov = selected_prov_name
                            st.session_state.drill_level = 2
                            st.rerun()

                        # Visualization: Stacked Bar Chart of Abnormalities
                        if not prov_view_filtered.empty:
                            fig_abnormal = px.bar(
                                prov_view_filtered,
                                x='çœåŒºåç§°',
                                y=['ğŸ”´ åº“å­˜è¿‡é«˜', 'ğŸŸ  åº“å­˜ä¸è¶³'],
                                title='å„çœå¼‚å¸¸åº“å­˜åˆ†å¸ƒ',
                                labels={'value': 'ç»é”€å•†æ•°é‡', 'variable': 'å¼‚å¸¸ç±»å‹'},
                                color_discrete_map={'ğŸ”´ åº“å­˜è¿‡é«˜': '#E5484D', 'ğŸŸ  åº“å­˜ä¸è¶³': '#FFB000'}
                            )
                            fig_abnormal.update_layout(height=350, margin=dict(l=20, r=20, t=40, b=20))
                            st.plotly_chart(fig_abnormal, use_container_width=True)

                    # --- Level 2: Distributor View ---
                    elif st.session_state.drill_level == 2:
                        prov = st.session_state.selected_prov
                        st.caption("ğŸ’¡ æç¤ºï¼š**ç‚¹å‡»è¡¨æ ¼è¡Œ** å¯æŸ¥çœ‹è¯¥ç»é”€å•†çš„ SKU åº“å­˜æ˜ç»†ã€‚")
                        
                        # Filter by Prov
                        dist_view = analysis_df[analysis_df['çœåŒºåç§°'] == prov].copy().reset_index(drop=True)
                        
                        # Interactive Table
                        ag_dist_inv = show_aggrid_table(
                            dist_view[['ç»é”€å•†åç§°', 'å½“å‰åº“å­˜_ç®±', 'Q4_Avg', 'å¯é”€æœˆ(DOS)', 'åº“å­˜çŠ¶æ€']],
                            height=520,
                            columns_props={'å¯é”€æœˆ(DOS)': {'type': 'number'}},
                            on_row_selected='single',
                            key='inv_dist_ag'
                        )
                        
                        # Handle Selection
                        selected_rows_d = ag_dist_inv.get('selected_rows') if ag_dist_inv else None
                        if selected_rows_d is not None and len(selected_rows_d) > 0:
                            if isinstance(selected_rows_d, pd.DataFrame):
                                first_row_d = selected_rows_d.iloc[0]
                            else:
                                first_row_d = selected_rows_d[0]
                            
                            selected_dist_name = first_row_d.get("ç»é”€å•†åç§°") if isinstance(first_row_d, dict) else first_row_d["ç»é”€å•†åç§°"]
                            st.session_state.selected_dist = selected_dist_name
                            st.session_state.drill_level = 3
                            st.rerun()

                    # --- Level 3: SKU/Store View ---
                    elif st.session_state.drill_level == 3:
                        dist = st.session_state.selected_dist
                        
                        # Get SKU details for this distributor from filtered stock data
                        # Note: We don't have store-level sales in Sheet3 (only Dist level), 
                        # so we can only show Stock Details here, potentially calculating SKU-level DOS if we had SKU-level sales (which we don't from Sheet3).
                        # We will show SKU stock details.
                        
                        sku_view = df_s_filtered[df_s_filtered['ç»é”€å•†åç§°'] == dist][['äº§å“åç§°', 'äº§å“ç¼–ç ', 'ç®±æ•°', 'è§„æ ¼', 'é‡é‡']].copy()
                        
                        show_aggrid_table(sku_view, height=520, key='inv_sku_ag')
                        st.caption("æ³¨ï¼šå› Q4å‡ºåº“æ•°æ®ä»…ç²¾ç¡®åˆ°ç»é”€å•†å±‚çº§ï¼Œæ­¤å¤„ä»…å±•ç¤ºSKUåº“å­˜æ˜ç»†ï¼Œä¸è®¡ç®—å•å“DOSã€‚")

            with tab_out:
                if df_q4_raw is None or df_q4_raw.empty:
                    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°å‡ºåº“æ•°æ® (Sheet3)ã€‚è¯·ç¡®è®¤ExcelåŒ…å«Sheet3ä¸”æ•°æ®å®Œæ•´ã€‚")
                    with st.expander("ğŸ› ï¸ è°ƒè¯•ä¿¡æ¯", expanded=False):
                        for log in debug_logs:
                            st.text(log)
                else:
                    st.caption(f"ğŸ•’ æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

                    o_raw = df_q4_raw.copy()

                    if 'äº§å“å¤§ç±»' not in o_raw.columns:
                        o_raw['äº§å“å¤§ç±»'] = 'å…¨éƒ¨'
                    if 'äº§å“å°ç±»' not in o_raw.columns:
                        o_raw['äº§å“å°ç±»'] = 'å…¨éƒ¨'

                    day_col = next((c for c in o_raw.columns if str(c).strip() == 'æ—¥'), None)
                    if day_col is None:
                        day_col = next((c for c in o_raw.columns if ('æ—¥æœŸ' in str(c)) or (str(c).strip().endswith('æ—¥') and 'æœˆ' not in str(c))), None)
                    if day_col is None and len(o_raw.columns) > 14:
                        day_col = o_raw.columns[14]

                    store_name_col = o_raw.columns[5] if len(o_raw.columns) > 5 else None

                    if 'æ•°é‡(ç®±)' in o_raw.columns:
                        o_raw['æ•°é‡(ç®±)'] = pd.to_numeric(o_raw['æ•°é‡(ç®±)'], errors='coerce').fillna(0.0)
                    else:
                        o_raw['æ•°é‡(ç®±)'] = 0.0

                    if store_name_col is not None and store_name_col in o_raw.columns:
                        o_raw['_é—¨åº—å'] = (
                            o_raw[store_name_col]
                            .fillna('')
                            .astype(str)
                            .str.replace(r'\s+', '', regex=True)
                        )
                        o_raw.loc[o_raw['_é—¨åº—å'].isin(['', 'nan', 'None', 'NULL', 'NaN']), '_é—¨åº—å'] = pd.NA
                    else:
                        o_raw['_é—¨åº—å'] = pd.NA

                    def _to_month(v):
                        if pd.isna(v):
                            return None
                        if isinstance(v, (int, float)) and not pd.isna(v):
                            m = int(v)
                            return m if 1 <= m <= 12 else None
                        s = str(v).strip()
                        if s.isdigit():
                            m = int(s)
                            return m if 1 <= m <= 12 else None
                        if 'æœˆ' in s:
                            digits = ''.join([ch for ch in s if ch.isdigit()])
                            if digits:
                                for k in (2, 1):
                                    if len(digits) >= k:
                                        m = int(digits[-k:])
                                        if 1 <= m <= 12:
                                            return m
                            return None
                        dt = pd.to_datetime(s, errors='coerce')
                        if pd.isna(dt):
                            return None
                        m = int(dt.month)
                        return m if 1 <= m <= 12 else None

                    def _to_day(v):
                        if pd.isna(v):
                            return None
                        if isinstance(v, (int, float)) and not pd.isna(v):
                            d = int(v)
                            return d if 1 <= d <= 31 else None
                        s = str(v).strip()
                        digits = ''.join([ch for ch in s if ch.isdigit()])
                        if not digits:
                            return None
                        d = int(digits[-2:]) if len(digits) >= 2 else int(digits)
                        return d if 1 <= d <= 31 else None

                    if 'å¹´ä»½' in o_raw.columns:
                        o_raw['_å¹´'] = pd.to_numeric(o_raw['å¹´ä»½'], errors='coerce').fillna(0).astype(int)
                    else:
                        o_raw['_å¹´'] = 0
                    if 'æœˆä»½' in o_raw.columns:
                        o_raw['_æœˆ'] = o_raw['æœˆä»½'].apply(_to_month)
                    else:
                        o_raw['_æœˆ'] = None

                    if day_col is not None and day_col in o_raw.columns:
                        if 'æ—¥æœŸ' in str(day_col):
                            dt_series = pd.to_datetime(o_raw[day_col], errors='coerce')
                            o_raw['_å¹´'] = np.where(dt_series.notna(), dt_series.dt.year, o_raw['_å¹´']).astype(int)
                            o_raw['_æœˆ'] = np.where(dt_series.notna(), dt_series.dt.month, o_raw['_æœˆ'])
                            o_raw['_æ—¥'] = np.where(dt_series.notna(), dt_series.dt.day, None)
                        else:
                            o_raw['_æ—¥'] = o_raw[day_col].apply(_to_day)
                    else:
                        o_raw['_æ—¥'] = None

                    o_raw = o_raw[o_raw['_å¹´'] > 0].copy()
                    o_raw = o_raw[o_raw['_æœˆ'].notna()].copy()
                    o_raw['_æœˆ'] = o_raw['_æœˆ'].astype(int)
                    o_raw['_æ—¥'] = pd.to_numeric(o_raw['_æ—¥'], errors='coerce')

                    with st.expander("ğŸ› ï¸ å‡ºåº“ç­›é€‰", expanded=False):
                        out_provs = ['å…¨éƒ¨'] + sorted(o_raw['çœåŒº'].dropna().astype(str).unique().tolist()) if 'çœåŒº' in o_raw.columns else ['å…¨éƒ¨']
                        oc1, oc2, oc3, oc4, oc5 = st.columns(5)
                        with oc1:
                            o_prov = st.selectbox("çœåŒº", out_provs, key='out2_prov')
                        with oc2:
                            if 'ç»é”€å•†åç§°' in o_raw.columns:
                                if o_prov != 'å…¨éƒ¨' and 'çœåŒº' in o_raw.columns:
                                    dists_in_prov = o_raw[o_raw['çœåŒº'].astype(str) == str(o_prov)]['ç»é”€å•†åç§°'].dropna().astype(str).unique().tolist()
                                    out_dists = ['å…¨éƒ¨'] + sorted(dists_in_prov)
                                else:
                                    out_dists = ['å…¨éƒ¨'] + sorted(o_raw['ç»é”€å•†åç§°'].dropna().astype(str).unique().tolist())
                            else:
                                out_dists = ['å…¨éƒ¨']
                            o_dist = st.selectbox("ç»é”€å•†", out_dists, key='out2_dist')
                        with oc3:
                            out_cats = ['å…¨éƒ¨'] + sorted(o_raw['äº§å“å¤§ç±»'].dropna().astype(str).unique().tolist())
                            o_cat = st.selectbox("äº§å“å¤§ç±»", out_cats, key='out2_cat')
                        with oc4:
                            if o_cat != 'å…¨éƒ¨':
                                subs_in_cat = o_raw[o_raw['äº§å“å¤§ç±»'].astype(str) == str(o_cat)]['äº§å“å°ç±»'].dropna().astype(str).unique().tolist()
                                out_subs = ['å…¨éƒ¨'] + sorted(subs_in_cat)
                            else:
                                out_subs = ['å…¨éƒ¨'] + sorted(o_raw['äº§å“å°ç±»'].dropna().astype(str).unique().tolist())
                            o_sub = st.selectbox("äº§å“å°ç±»", out_subs, key='out2_sub')
                        with oc5:
                            year_opts = sorted([int(y) for y in o_raw['_å¹´'].dropna().unique().tolist() if int(y) > 0])
                            default_year = 2025 if 2025 in year_opts else (max(year_opts) if year_opts else 2025)
                            y_index = year_opts.index(default_year) if default_year in year_opts else 0
                            o_year = st.selectbox("å¹´ä»½", year_opts if year_opts else [2025], index=y_index, key='out2_year')
                            month_in_year = sorted([int(m) for m in o_raw[o_raw['_å¹´'] == int(o_year)]['_æœˆ'].dropna().unique().tolist() if 1 <= int(m) <= 12])
                            month_opts = ['å…¨éƒ¨'] + month_in_year
                            o_month = st.selectbox("æœˆä»½", month_opts, index=0, key='out2_month')

                    df_o = o_raw.copy()
                    if o_prov != 'å…¨éƒ¨' and 'çœåŒº' in df_o.columns:
                        df_o = df_o[df_o['çœåŒº'].astype(str) == str(o_prov)]
                    if o_dist != 'å…¨éƒ¨' and 'ç»é”€å•†åç§°' in df_o.columns:
                        df_o = df_o[df_o['ç»é”€å•†åç§°'].astype(str) == str(o_dist)]
                    if o_cat != 'å…¨éƒ¨':
                        df_o = df_o[df_o['äº§å“å¤§ç±»'].astype(str) == str(o_cat)]
                    if o_sub != 'å…¨éƒ¨':
                        df_o = df_o[df_o['äº§å“å°ç±»'].astype(str) == str(o_sub)]

                    def _agg_scope(df_scope: pd.DataFrame):
                        boxes = float(df_scope.get('æ•°é‡(ç®±)', 0).sum()) if df_scope is not None and not df_scope.empty else 0.0
                        if df_scope is None or df_scope.empty or '_é—¨åº—å' not in df_scope.columns:
                            stores = 0.0
                        else:
                            df_s = df_scope[df_scope['æ•°é‡(ç®±)'] > 0].copy()
                            stores = float(df_s['_é—¨åº—å'].dropna().astype(str).nunique()) if not df_s.empty else 0.0
                        return boxes, stores

                    def _yoy(cur, last):
                        if last is None:
                            return None
                        last_v = float(last or 0)
                        if last_v <= 0:
                            return None
                        return (float(cur or 0) - last_v) / last_v

                    def _avg(boxes, stores):
                        try:
                            s = float(stores or 0)
                            return float(boxes or 0) / s if s > 0 else 0.0
                        except Exception:
                            return 0.0

                    def _fmt_num(x):
                        return fmt_num(x, na="0")

                    def _fmt_pct(x):
                        return fmt_pct_ratio(x) if x is not None else "â€”"

                    def _trend_cls(x):
                        if x is None or (isinstance(x, float) and pd.isna(x)):
                            return "trend-neutral"
                        return "trend-up" if x > 0 else ("trend-down" if x < 0 else "trend-neutral")

                    def _arrow(x):
                        if x is None or (isinstance(x, float) and pd.isna(x)):
                            return ""
                        return "â†‘" if x > 0 else ("â†“" if x < 0 else "")

                    # === Use Native Tabs for Consistency with Other Modules ===
                    tab_kpi, tab_cat, tab_prov = st.tabs(["ğŸ“Š å…³é”®æŒ‡æ ‡", "ğŸ“¦ åˆ†å“ç±»", "ğŸ—ºï¸ åˆ†çœåŒº"])
                    
                    # Prepare Data Context (Shared)
                    sig = (o_prov, o_dist, o_cat, o_sub, o_year, o_month)
                    if "out_subtab_cache" not in st.session_state:
                        st.session_state.out_subtab_cache = {}
                    
                    def _get_ctx():
                        ck = ("ctx", sig)
                        if ck in st.session_state.out_subtab_cache:
                            return st.session_state.out_subtab_cache[ck]
                        
                        # No spinner here to avoid flashing on every rerun, 
                        # relying on Streamlit's natural execution speed or cache if possible.
                        # If slow, we might add st.spinner inside specific heavy blocks.
                        if o_month != 'å…¨éƒ¨':
                            _kpi_year = int(o_year)
                            _kpi_month = int(o_month)
                        else:
                            years_avail = sorted([int(y) for y in df_o['_å¹´'].dropna().unique().tolist() if int(y) > 0])
                            _kpi_year = 2026 if 2026 in years_avail else (max(years_avail) if years_avail else int(o_year))
                            months_avail = sorted([int(m) for m in df_o[df_o['_å¹´'] == int(_kpi_year)]['_æœˆ'].dropna().unique().tolist() if 1 <= int(m) <= 12])
                            _kpi_month = max(months_avail) if months_avail else 1

                        days_avail = sorted([int(d) for d in df_o[(df_o['_å¹´'] == int(_kpi_year)) & (df_o['_æœˆ'] == int(_kpi_month))]['_æ—¥'].dropna().unique().tolist() if 1 <= int(d) <= 31])
                        _kpi_day = max(days_avail) if days_avail else None
                        _cmp_year = int(_kpi_year) - 1

                        _cur_today = (df_o[(df_o['_å¹´'] == int(_kpi_year)) & (df_o['_æœˆ'] == int(_kpi_month)) & (df_o['_æ—¥'] == int(_kpi_day))] if _kpi_day is not None else df_o.iloc[0:0])
                        _cur_month = df_o[(df_o['_å¹´'] == int(_kpi_year)) & (df_o['_æœˆ'] == int(_kpi_month))]
                        _cur_year = df_o[(df_o['_å¹´'] == int(_kpi_year))]

                        _last_today = (df_o[(df_o['_å¹´'] == int(_cmp_year)) & (df_o['_æœˆ'] == int(_kpi_month)) & (df_o['_æ—¥'] == int(_kpi_day))] if _kpi_day is not None else df_o.iloc[0:0])
                        _last_month = df_o[(df_o['_å¹´'] == int(_cmp_year)) & (df_o['_æœˆ'] == int(_kpi_month))]
                        _last_year = df_o[(df_o['_å¹´'] == int(_cmp_year))]

                        ctx = {
                            "kpi_year": _kpi_year,
                            "kpi_month": _kpi_month,
                            "kpi_day": _kpi_day,
                            "cmp_year": _cmp_year,
                            "cur_today": _cur_today,
                            "cur_month": _cur_month,
                            "cur_year": _cur_year,
                            "last_today": _last_today,
                            "last_month": _last_month,
                            "last_year": _last_year,
                        }
                        st.session_state.out_subtab_cache[ck] = ctx
                        return ctx

                    ctx = _get_ctx()
                    
                    # Common Caption
                    st.caption(
                        f"å½“å‰é»˜è®¤å£å¾„ï¼š{ctx['kpi_year']}å¹´{int(ctx['kpi_month'])}æœˆ"
                        + (f"{int(ctx['kpi_day'])}æ—¥" if ctx["kpi_day"] is not None else "")
                    )

                    # --- Tab 1: KPI ---
                    with tab_kpi:
                        ck = ("kpi", sig)
                        if ck not in st.session_state.out_subtab_cache:
                             t_boxes, t_stores = _agg_scope(ctx["cur_today"])
                             tm_boxes, tm_stores = _agg_scope(ctx["cur_month"])
                             ty_boxes, ty_stores = _agg_scope(ctx["cur_year"])
                             lt_boxes, lt_stores = _agg_scope(ctx["last_today"])
                             ltm_boxes, ltm_stores = _agg_scope(ctx["last_month"])
                             lty_boxes, lty_stores = _agg_scope(ctx["last_year"])
                             t_yoy = _yoy(t_boxes, lt_boxes)
                             tm_yoy = _yoy(tm_boxes, ltm_boxes)
                             ty_yoy = _yoy(ty_boxes, lty_boxes)
                             t_avg = _avg(t_boxes, t_stores)
                             tm_avg = _avg(tm_boxes, tm_stores)
                             ty_avg = _avg(ty_boxes, ty_stores)
                             lt_avg = _avg(lt_boxes, lt_stores)
                             ltm_avg = _avg(ltm_boxes, ltm_stores)
                             lty_avg = _avg(lty_boxes, lty_stores)
                             st.session_state.out_subtab_cache[ck] = {
                                "t_boxes": t_boxes, "t_stores": t_stores, "t_yoy": t_yoy, "t_avg": t_avg, "lt_boxes": lt_boxes, "lt_stores": lt_stores, "lt_avg": lt_avg,
                                "tm_boxes": tm_boxes, "tm_stores": tm_stores, "tm_yoy": tm_yoy, "tm_avg": tm_avg, "ltm_boxes": ltm_boxes, "ltm_stores": ltm_stores, "ltm_avg": ltm_avg,
                                "ty_boxes": ty_boxes, "ty_stores": ty_stores, "ty_yoy": ty_yoy, "ty_avg": ty_avg, "lty_boxes": lty_boxes, "lty_stores": lty_stores, "lty_avg": lty_avg,
                             }
                        m = st.session_state.out_subtab_cache[ck]

                        k1, k2, k3 = st.columns(3)
                        with k1:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸšš</div>
                                    <div class="out-kpi-title">æœ¬æ—¥å‡ºåº“</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['t_boxes'])} ç®±</div>
                                <div class="out-kpi-sub"><span>é—¨åº—æ•°</span><span>{_fmt_num(m['t_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>åº—å‡ï¼ˆç®±/åº—ï¼‰</span><span>{fmt_num(m['t_avg'])} <span style="color:rgba(27,21,48,0.55);">ï½œåŒæœŸ {fmt_num(m['lt_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({ctx['cmp_year']})</span><span>{_fmt_num(m['lt_boxes'])} ç®± / {_fmt_num(m['lt_stores'])} åº—</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆç®±ï¼‰</span><span class="{_trend_cls(m['t_yoy'])}">{_arrow(m['t_yoy'])} {_fmt_pct(m['t_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                        with k2:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸ“¦</div>
                                    <div class="out-kpi-title">æœ¬æœˆç´¯è®¡å‡ºåº“</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['tm_boxes'])} ç®±</div>
                                <div class="out-kpi-sub"><span>é—¨åº—æ•°</span><span>{_fmt_num(m['tm_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>åº—å‡ï¼ˆç®±/åº—ï¼‰</span><span>{fmt_num(m['tm_avg'])} <span style="color:rgba(27,21,48,0.55);">ï½œåŒæœŸ {fmt_num(m['ltm_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({ctx['cmp_year']})</span><span>{_fmt_num(m['ltm_boxes'])} ç®± / {_fmt_num(m['ltm_stores'])} åº—</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆç®±ï¼‰</span><span class="{_trend_cls(m['tm_yoy'])}">{_arrow(m['tm_yoy'])} {_fmt_pct(m['tm_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                        with k3:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">ğŸ</div>
                                    <div class="out-kpi-title">æœ¬å¹´ç´¯è®¡å‡ºåº“</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['ty_boxes'])} ç®±</div>
                                <div class="out-kpi-sub"><span>é—¨åº—æ•°</span><span>{_fmt_num(m['ty_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>åº—å‡ï¼ˆç®±/åº—ï¼‰</span><span>{fmt_num(m['ty_avg'])} <span style="color:rgba(27,21,48,0.55);">ï½œåŒæœŸ {fmt_num(m['lty_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>åŒæœŸ({ctx['cmp_year']})</span><span>{_fmt_num(m['lty_boxes'])} ç®± / {_fmt_num(m['lty_stores'])} åº—</span></div>
                                <div class="out-kpi-sub2"><span>åŒæ¯”ï¼ˆç®±ï¼‰</span><span class="{_trend_cls(m['ty_yoy'])}">{_arrow(m['ty_yoy'])} {_fmt_pct(m['ty_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                    # --- Tab 2: Category ---
                    with tab_cat:
                        ck = ("cat", sig)
                        if ck not in st.session_state.out_subtab_cache:
                            with st.spinner("æ­£åœ¨åŠ è½½åˆ†å“ç±»â€¦"):
                                cat_dim = 'äº§å“å°ç±»' if o_cat != 'å…¨éƒ¨' else 'äº§å“å¤§ç±»'
                                st.session_state.out_subtab_cache[ck] = {"cat_dim": cat_dim}
                        cat_dim = st.session_state.out_subtab_cache[ck]["cat_dim"]
                        dim_label = 'äº§å“å°ç±»' if cat_dim == 'äº§å“å°ç±»' else 'äº§å“å¤§ç±»'

                        st.caption(f"ç»Ÿè®¡ç»´åº¦ï¼š{dim_label}ï¼ˆéšç­›é€‰æ¡ä»¶å®æ—¶æ›´æ–°ï¼‰")

                        def _cat_agg(df_scope: pd.DataFrame):
                            if df_scope is None or df_scope.empty:
                                return pd.DataFrame(columns=[cat_dim, 'ç®±æ•°', 'é—¨åº—æ•°'])
                            df_t = df_scope.copy()
                            if cat_dim not in df_t.columns:
                                df_t[cat_dim] = 'æœªçŸ¥'
                            df_t[cat_dim] = df_t[cat_dim].fillna('æœªçŸ¥').astype(str).str.strip()
                            df_t = df_t[df_t['æ•°é‡(ç®±)'] > 0].copy()
                            if df_t.empty:
                                return pd.DataFrame(columns=[cat_dim, 'ç®±æ•°', 'é—¨åº—æ•°'])
                            g_box = df_t.groupby(cat_dim, as_index=False)['æ•°é‡(ç®±)'].sum().rename(columns={'æ•°é‡(ç®±)': 'ç®±æ•°'})
                            if '_é—¨åº—å' in df_t.columns:
                                g_store = df_t[df_t['_é—¨åº—å'].notna()].groupby(cat_dim, as_index=False)['_é—¨åº—å'].nunique().rename(columns={'_é—¨åº—å': 'é—¨åº—æ•°'})
                            else:
                                g_store = pd.DataFrame({cat_dim: g_box[cat_dim], 'é—¨åº—æ•°': 0})
                            out = pd.merge(g_box, g_store, on=cat_dim, how='left').fillna(0)
                            out = out.sort_values('ç®±æ•°', ascending=False).reset_index(drop=True)
                            return out

                        def _topn_with_other(df_sum: pd.DataFrame, n: int = 15):
                            if df_sum is None or df_sum.empty:
                                return df_sum
                            head = df_sum.head(n).copy()
                            tail = df_sum.iloc[n:].copy()
                            if not tail.empty:
                                other = pd.DataFrame([{
                                    cat_dim: 'å…¶ä»–',
                                    'ç®±æ•°': float(tail['ç®±æ•°'].sum()),
                                    'é—¨åº—æ•°': float(tail['é—¨åº—æ•°'].sum())
                                }])
                                head = pd.concat([head, other], ignore_index=True)
                            return head

                        def _cat_table(df_cur: pd.DataFrame, df_last: pd.DataFrame):
                            cur_sum = _topn_with_other(_cat_agg(df_cur), 15)
                            last_sum = _topn_with_other(_cat_agg(df_last), 15)
                            if cur_sum is None or cur_sum.empty:
                                cur_sum = pd.DataFrame(columns=[cat_dim, 'ç®±æ•°', 'é—¨åº—æ•°'])
                            if last_sum is None or last_sum.empty:
                                last_sum = pd.DataFrame(columns=[cat_dim, 'ç®±æ•°', 'é—¨åº—æ•°'])
                            m = pd.merge(
                                cur_sum.rename(columns={'ç®±æ•°': 'ç®±æ•°', 'é—¨åº—æ•°': 'é—¨åº—æ•°'}),
                                last_sum[[cat_dim, 'ç®±æ•°']].rename(columns={'ç®±æ•°': 'åŒæœŸï¼ˆç®±æ•°ï¼‰'}),
                                on=cat_dim,
                                how='outer'
                            ).fillna(0)
                            m['åŒæ¯”'] = np.where(m['åŒæœŸï¼ˆç®±æ•°ï¼‰'] > 0, (m['ç®±æ•°'] - m['åŒæœŸï¼ˆç®±æ•°ï¼‰']) / m['åŒæœŸï¼ˆç®±æ•°ï¼‰'], None)
                            m = m.sort_values('ç®±æ•°', ascending=False).reset_index(drop=True)
                            m = m.rename(columns={cat_dim: 'å“ç±»'})
                            return m[['å“ç±»', 'ç®±æ•°', 'é—¨åº—æ•°', 'åŒæœŸï¼ˆç®±æ•°ï¼‰', 'åŒæ¯”']]

                        tab_cat_today, tab_cat_month, tab_cat_year = st.tabs(["æœ¬æ—¥", "æœ¬æœˆ", "æœ¬å¹´"])
                        with tab_cat_today:
                            cat_tbl = _cat_table(ctx["cur_today"], ctx["last_today"])
                            show_aggrid_table(cat_tbl, columns_props={'åŒæ¯”': {'type': 'percent'}}, auto_height_limit=520)
                        with tab_cat_month:
                            cat_tbl = _cat_table(ctx["cur_month"], ctx["last_month"])
                            show_aggrid_table(cat_tbl, columns_props={'åŒæ¯”': {'type': 'percent'}}, auto_height_limit=520)
                        with tab_cat_year:
                            cat_tbl = _cat_table(ctx["cur_year"], ctx["last_year"])
                            show_aggrid_table(cat_tbl, columns_props={'åŒæ¯”': {'type': 'percent'}}, auto_height_limit=520)

                    # --- Tab 3: Province ---
                    with tab_prov:

                        def _prov_agg(df_scope: pd.DataFrame):
                            if df_scope is None or df_scope.empty or 'çœåŒº' not in df_scope.columns:
                                return pd.DataFrame(columns=['çœåŒº', 'ç®±æ•°', 'é—¨åº—æ•°'])
                            g_box = (
                                df_scope
                                .groupby('çœåŒº', as_index=False)['æ•°é‡(ç®±)']
                                .sum()
                                .rename(columns={'æ•°é‡(ç®±)': 'ç®±æ•°'})
                            )

                            if '_é—¨åº—å' in df_scope.columns:
                                tmp = df_scope[(df_scope['æ•°é‡(ç®±)'] > 0) & (df_scope['_é—¨åº—å'].notna())].copy()
                                g_store = (
                                    tmp
                                    .groupby('çœåŒº', as_index=False)['_é—¨åº—å']
                                    .nunique()
                                    .rename(columns={'_é—¨åº—å': 'é—¨åº—æ•°'})
                                )
                            else:
                                g_store = pd.DataFrame(columns=['çœåŒº', 'é—¨åº—æ•°'])

                            return pd.merge(g_box, g_store, on='çœåŒº', how='left').fillna(0)

                        p_cur_today = _prov_agg(ctx["cur_today"])
                        p_cur_month = _prov_agg(ctx["cur_month"])
                        p_cur_year = _prov_agg(ctx["cur_year"])
                        p_last_today = _prov_agg(ctx["last_today"])
                        p_last_month = _prov_agg(ctx["last_month"])
                        p_last_year = _prov_agg(ctx["last_year"])

                        prov_all = sorted(set(
                            p_cur_today['çœåŒº'].astype(str).tolist()
                            + p_cur_month['çœåŒº'].astype(str).tolist()
                            + p_cur_year['çœåŒº'].astype(str).tolist()
                        ))
                        prov_df = pd.DataFrame({'çœåŒº': prov_all})

                        def _merge(prov_base, df_left, prefix):
                            d = df_left.copy()
                            d.columns = ['çœåŒº'] + [f"{prefix}{c}" for c in d.columns if c != 'çœåŒº']
                            return pd.merge(prov_base, d, on='çœåŒº', how='left').fillna(0)

                        prov_df = _merge(prov_df, p_cur_today, "ä»Šæ—¥")
                        prov_df = _merge(prov_df, p_last_today, "åŒæœŸä»Šæ—¥")
                        prov_df = _merge(prov_df, p_cur_month, "æœ¬æœˆ")
                        prov_df = _merge(prov_df, p_last_month, "åŒæœŸæœ¬æœˆ")
                        prov_df = _merge(prov_df, p_cur_year, "æœ¬å¹´")
                        prov_df = _merge(prov_df, p_last_year, "åŒæœŸæœ¬å¹´")

                        prov_df['ä»Šæ—¥åŒæ¯”(ç®±)'] = prov_df.apply(lambda r: _yoy(r.get('ä»Šæ—¥ç®±æ•°', 0), r.get('åŒæœŸä»Šæ—¥ç®±æ•°', 0)), axis=1)
                        prov_df['ä»Šæ—¥åŒæ¯”(é—¨åº—)'] = prov_df.apply(lambda r: _yoy(r.get('ä»Šæ—¥é—¨åº—æ•°', 0), r.get('åŒæœŸä»Šæ—¥é—¨åº—æ•°', 0)), axis=1)
                        prov_df['æœ¬æœˆåŒæ¯”(ç®±)'] = prov_df.apply(lambda r: _yoy(r.get('æœ¬æœˆç®±æ•°', 0), r.get('åŒæœŸæœ¬æœˆç®±æ•°', 0)), axis=1)
                        prov_df['æœ¬æœˆåŒæ¯”(é—¨åº—)'] = prov_df.apply(lambda r: _yoy(r.get('æœ¬æœˆé—¨åº—æ•°', 0), r.get('åŒæœŸæœ¬æœˆé—¨åº—æ•°', 0)), axis=1)
                        prov_df['æœ¬å¹´åŒæ¯”(ç®±)'] = prov_df.apply(lambda r: _yoy(r.get('æœ¬å¹´ç®±æ•°', 0), r.get('åŒæœŸæœ¬å¹´ç®±æ•°', 0)), axis=1)
                        prov_df['æœ¬å¹´åŒæ¯”(é—¨åº—)'] = prov_df.apply(lambda r: _yoy(r.get('æœ¬å¹´é—¨åº—æ•°', 0), r.get('åŒæœŸæœ¬å¹´é—¨åº—æ•°', 0)), axis=1)

                        prov_show = pd.DataFrame({
                            'çœåŒº': prov_df['çœåŒº'],
                            'ä»Šæ—¥ç®±æ•°': pd.to_numeric(prov_df.get('ä»Šæ—¥ç®±æ•°', 0), errors='coerce').fillna(0),
                            'ä»Šæ—¥é—¨åº—æ•°': pd.to_numeric(prov_df.get('ä»Šæ—¥é—¨åº—æ•°', 0), errors='coerce').fillna(0),
                            'ä»Šæ—¥åŒæœŸ(ç®±æ•°)': pd.to_numeric(prov_df.get('åŒæœŸä»Šæ—¥ç®±æ•°', 0), errors='coerce').fillna(0),
                            'ä»Šæ—¥åŒæ¯”(ç®±)': pd.to_numeric(prov_df.get('ä»Šæ—¥åŒæ¯”(ç®±)', None), errors='coerce'),
                            'æœ¬æœˆç®±æ•°': pd.to_numeric(prov_df.get('æœ¬æœˆç®±æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬æœˆé—¨åº—æ•°': pd.to_numeric(prov_df.get('æœ¬æœˆé—¨åº—æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬æœˆåŒæœŸ(ç®±æ•°)': pd.to_numeric(prov_df.get('åŒæœŸæœ¬æœˆç®±æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬æœˆåŒæ¯”(ç®±)': pd.to_numeric(prov_df.get('æœ¬æœˆåŒæ¯”(ç®±)', None), errors='coerce'),
                            'æœ¬å¹´ç®±æ•°': pd.to_numeric(prov_df.get('æœ¬å¹´ç®±æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬å¹´é—¨åº—æ•°': pd.to_numeric(prov_df.get('æœ¬å¹´é—¨åº—æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬å¹´åŒæœŸ(ç®±æ•°)': pd.to_numeric(prov_df.get('åŒæœŸæœ¬å¹´ç®±æ•°', 0), errors='coerce').fillna(0),
                            'æœ¬å¹´åŒæ¯”(ç®±)': pd.to_numeric(prov_df.get('æœ¬å¹´åŒæ¯”(ç®±)', None), errors='coerce'),
                        }).fillna({'ä»Šæ—¥åŒæ¯”(ç®±)': np.nan, 'æœ¬æœˆåŒæ¯”(ç®±)': np.nan, 'æœ¬å¹´åŒæ¯”(ç®±)': np.nan})

                        day_txt = f"{int(ctx['kpi_month'])}æœˆ{int(ctx['kpi_day'])}æ—¥" if ctx["kpi_day"] is not None else f"{int(ctx['kpi_month'])}æœˆ"
                        grp_today = f"ä»Šæ—¥ï¼ˆ{day_txt}ï¼‰"
                        grp_month = f"æœ¬æœˆï¼ˆ{int(ctx['kpi_month'])}æœˆï¼‰"
                        grp_year = f"æœ¬å¹´ï¼ˆ{int(ctx['kpi_year'])}å¹´ï¼‰"

                        col_defs = [
                            {'headerName': 'çœåŒº', 'field': 'çœåŒº', 'minWidth': 110, 'headerClass': 'ag-header-center'},
                            {
                                'headerName': grp_today,
                                'children': [
                                    {'headerName': 'ç®±æ•°', 'field': 'ä»Šæ—¥ç®±æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'é—¨åº—æ•°', 'field': 'ä»Šæ—¥é—¨åº—æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæœŸï¼ˆç®±æ•°ï¼‰', 'field': 'ä»Šæ—¥åŒæœŸ(ç®±æ•°)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæ¯”ï¼ˆç®±ï¼‰', 'field': 'ä»Šæ—¥åŒæ¯”(ç®±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                            {
                                'headerName': grp_month,
                                'children': [
                                    {'headerName': 'ç®±æ•°', 'field': 'æœ¬æœˆç®±æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'é—¨åº—æ•°', 'field': 'æœ¬æœˆé—¨åº—æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæœŸï¼ˆç®±æ•°ï¼‰', 'field': 'æœ¬æœˆåŒæœŸ(ç®±æ•°)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæ¯”ï¼ˆç®±ï¼‰', 'field': 'æœ¬æœˆåŒæ¯”(ç®±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                            {
                                'headerName': grp_year,
                                'children': [
                                    {'headerName': 'ç®±æ•°', 'field': 'æœ¬å¹´ç®±æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'é—¨åº—æ•°', 'field': 'æœ¬å¹´é—¨åº—æ•°', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæœŸï¼ˆç®±æ•°ï¼‰', 'field': 'æœ¬å¹´åŒæœŸ(ç®±æ•°)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'åŒæ¯”ï¼ˆç®±ï¼‰', 'field': 'æœ¬å¹´åŒæ¯”(ç®±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                        ]

                        def _sum_col(col_name: str) -> float:
                            if col_name not in prov_show.columns:
                                return 0.0
                            return float(pd.to_numeric(prov_show[col_name], errors='coerce').fillna(0).sum())

                        _t_cur = _sum_col('ä»Šæ—¥ç®±æ•°')
                        _t_last = _sum_col('ä»Šæ—¥åŒæœŸ(ç®±æ•°)')
                        _m_cur = _sum_col('æœ¬æœˆç®±æ•°')
                        _m_last = _sum_col('æœ¬æœˆåŒæœŸ(ç®±æ•°)')
                        _y_cur = _sum_col('æœ¬å¹´ç®±æ•°')
                        _y_last = _sum_col('æœ¬å¹´åŒæœŸ(ç®±æ•°)')

                        pinned_total = {
                            'çœåŒº': 'åˆè®¡',
                            'ä»Šæ—¥ç®±æ•°': _t_cur,
                            'ä»Šæ—¥é—¨åº—æ•°': _sum_col('ä»Šæ—¥é—¨åº—æ•°'),
                            'ä»Šæ—¥åŒæœŸ(ç®±æ•°)': _t_last,
                            'ä»Šæ—¥åŒæ¯”(ç®±)': ((_t_cur - _t_last) / _t_last) if _t_last > 0 else None,
                            'æœ¬æœˆç®±æ•°': _m_cur,
                            'æœ¬æœˆé—¨åº—æ•°': _sum_col('æœ¬æœˆé—¨åº—æ•°'),
                            'æœ¬æœˆåŒæœŸ(ç®±æ•°)': _m_last,
                            'æœ¬æœˆåŒæ¯”(ç®±)': ((_m_cur - _m_last) / _m_last) if _m_last > 0 else None,
                            'æœ¬å¹´ç®±æ•°': _y_cur,
                            'æœ¬å¹´é—¨åº—æ•°': _sum_col('æœ¬å¹´é—¨åº—æ•°'),
                            'æœ¬å¹´åŒæœŸ(ç®±æ•°)': _y_last,
                            'æœ¬å¹´åŒæ¯”(ç®±)': ((_y_cur - _y_last) / _y_last) if _y_last > 0 else None,
                        }

                        gridOptions = {
                            'pinnedBottomRowData': [pinned_total],
                            'columnDefs': col_defs,
                            'defaultColDef': {
                                'resizable': True,
                                'sortable': True,
                                'filter': True,
                                'wrapHeaderText': True,
                                'autoHeaderHeight': True,
                                'minWidth': 70,
                                'flex': 1,
                                'cellStyle': {'textAlign': 'center', 'display': 'flex', 'justifyContent': 'center', 'alignItems': 'center'},
                                'headerClass': 'ag-header-center',
                            },
                            'rowHeight': 40,
                            'headerHeight': 60,
                            'groupHeaderHeight': 60,
                            'animateRows': True,
                            'suppressCellFocus': True,
                            'enableCellTextSelection': True,
                            'suppressDragLeaveHidesColumns': True,
                            'sideBar': {
                                "toolPanels": [
                                    {
                                        "id": "columns",
                                        "labelDefault": "åˆ—",
                                        "iconKey": "columns",
                                        "toolPanel": "agColumnsToolPanel",
                                        "toolPanelParams": {
                                            "suppressRowGroups": True,
                                            "suppressValues": True,
                                            "suppressPivots": True,
                                            "suppressPivotMode": True
                                        }
                                    }
                                ],
                                "defaultToolPanel": None
                            },
                        }

                        AgGrid(
                            prov_show,
                            gridOptions=gridOptions,
                            height=520,
                            width='100%',
                            data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
                            update_mode=GridUpdateMode.NO_UPDATE,
                            fit_columns_on_grid_load=True,
                            allow_unsafe_jscode=True,
                            theme='streamlit',
                            key="outbound_prov_table"
                        )

                    st.markdown("</div>", unsafe_allow_html=True)

                    # === TAB 7: PERFORMANCE ===
            with tab7:
                st.markdown("""
                <style>
                  .perf-wrap {display:flex; flex-direction:column; gap:16px;}
                  .perf-kpis {display:grid; grid-template-columns: repeat(4, 1fr); gap:14px;}
                  .perf-card {background:#F3E5F5; border:1px solid rgba(156,39,176,0.18); border-radius:12px; padding:14px 16px; box-shadow:0 6px 20px rgba(18,12,28,0.06);}
                  .perf-k {font-size:13px; color:rgba(27,21,48,0.72);}
                  .perf-v {font-size:20px; font-weight:800; color:#9C27B0; margin-top:8px;}
                  .perf-sub {display:flex; justify-content:space-between; align-items:center; margin-top:8px; font-size:12px; color:rgba(27,21,48,0.72);}
                  .perf-up {color:#2FBF71; font-weight:700;}
                  .perf-down {color:#E5484D; font-weight:700;}
                  .perf-mid {color:#FFB000; font-weight:700;}
                  .stDataFrame td { vertical-align: middle !important; }
                  @media (max-width: 1100px) {.perf-kpis {grid-template-columns: repeat(2, 1fr);} }
                </style>
                """, unsafe_allow_html=True)

                if df_perf_raw is None or df_perf_raw.empty:
                    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°å‘è´§ä¸šç»©æ•°æ® (Sheet4)ã€‚è¯·ç¡®è®¤ExcelåŒ…å«Sheet4ä¸”æ•°æ®å®Œæ•´ã€‚")
                    with st.expander("ğŸ› ï¸ è°ƒè¯•ä¿¡æ¯", expanded=False):
                        for log in debug_logs: st.text(log)
                else:
                    df_perf = df_perf_raw.copy()
                    
                    # --- 1. Data Prep ---
                    # Load Targets from Sheet5 (C=Prov, D=Cat, E=Month, F=Task)
                    df_target = None
                    if df_target_raw is not None and len(df_target_raw.columns) >= 6:
                        try:
                            # Use iloc to be safe about column names
                            df_target = df_target_raw.iloc[:, [2, 3, 4, 5]].copy()
                            df_target.columns = ['çœåŒº', 'å“ç±»', 'æœˆä»½', 'ä»»åŠ¡é‡']
                            df_target['ä»»åŠ¡é‡'] = pd.to_numeric(df_target['ä»»åŠ¡é‡'], errors='coerce').fillna(0)
                            df_target['æœˆä»½'] = pd.to_numeric(df_target['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                            df_target['çœåŒº'] = df_target['çœåŒº'].astype(str).str.strip()
                            df_target['å“ç±»'] = df_target['å“ç±»'].astype(str).str.strip()
                        except Exception as e:
                            st.error(f"ä»»åŠ¡è¡¨è§£æå¤±è´¥: {e}")
                            df_target = None
                    
                    # Data Cleaning
                    df_track = df_perf.copy()
                    df_track['å¹´ä»½'] = pd.to_numeric(df_track['å¹´ä»½'], errors='coerce').fillna(0).astype(int)
                    df_track['æœˆä»½'] = pd.to_numeric(df_track['æœˆä»½'], errors='coerce').fillna(0).astype(int)
                    
                    # Fix: Check if 'å‘è´§é‡‘é¢' exists, if not, try to use 'å‘è´§ç®±æ•°' or create empty
                    if 'å‘è´§é‡‘é¢' not in df_track.columns:
                            if 'å‘è´§ç®±æ•°' in df_track.columns:
                                df_track['å‘è´§é‡‘é¢'] = df_track['å‘è´§ç®±æ•°'] # Fallback
                            else:
                                df_track['å‘è´§é‡‘é¢'] = 0.0
                    
                    df_track['å‘è´§é‡‘é¢'] = pd.to_numeric(df_track['å‘è´§é‡‘é¢'], errors='coerce').fillna(0.0)
                    
                    for c in ['çœåŒº', 'ç»é”€å•†åç§°', 'å½’ç±»', 'å‘è´§ä»“', 'å¤§åˆ†ç±»', 'æœˆåˆ†æ']:
                        if c in df_track.columns:
                            df_track[c] = df_track[c].fillna('').astype(str).str.strip()
                    
                    # Determine Year
                    years = sorted([y for y in df_track['å¹´ä»½'].unique() if y > 2000])
                    cur_year = 2026 if 2026 in years else (max(years) if years else 2025)
                    last_year = cur_year - 1
                    
                    # --- 2. Filters ---
                    with st.expander("ğŸ›ï¸ ç­›é€‰æ§åˆ¶é¢æ¿", expanded=False):
                        f1, f2, f3, f4, f5 = st.columns(5)
                        
                        # Province
                        prov_opts = ['å…¨éƒ¨'] + sorted([x for x in df_track['çœåŒº'].unique() if x])
                        with f1:
                            sel_prov = st.selectbox("çœåŒº", prov_opts, key="t26_prov")
                        
                        # Filter Step 1
                        df_f = df_track if sel_prov == 'å…¨éƒ¨' else df_track[df_track['çœåŒº'] == sel_prov]
                        
                        # Distributor
                        dist_opts = ['å…¨éƒ¨'] + sorted([x for x in df_f['ç»é”€å•†åç§°'].unique() if x])
                        with f2:
                            sel_dist = st.selectbox("ç»é”€å•†", dist_opts, key="t26_dist")
                        if sel_dist != 'å…¨éƒ¨':
                            df_f = df_f[df_f['ç»é”€å•†åç§°'] == sel_dist]
                            
                        if 'å¤§åˆ†ç±»' in df_track.columns:
                            cat_col_S = 'å¤§åˆ†ç±»'
                        elif 'æœˆåˆ†æ' in df_track.columns:
                            cat_col_S = 'æœˆåˆ†æ'
                            st.warning("âš ï¸ æœªæ‰¾åˆ°'Sheet4 Såˆ—å¤§åˆ†ç±»'å­—æ®µåâ€œå¤§åˆ†ç±»â€ï¼Œå·²ä½¿ç”¨â€œæœˆåˆ†æâ€åˆ—ä½œä¸ºæ›¿ä»£ã€‚è¯·ç¡®è®¤æºæ•°æ®åˆ—åã€‚")
                        else:
                            cat_col_S = 'å‘è´§ä»“'
                            st.error("âŒ æ•°æ®æºä¸­æœªæ‰¾åˆ°Sheet4 Såˆ—â€œå¤§åˆ†ç±»â€/â€œæœˆåˆ†æâ€åˆ—ï¼Œå·²ä¸´æ—¶ä½¿ç”¨â€œå‘è´§ä»“â€åˆ—ä½œä¸ºå¤§åˆ†ç±»ç­›é€‰ã€‚")

                        if cat_col_S in df_f.columns:
                            df_f[cat_col_S] = df_f[cat_col_S].fillna('').astype(str).str.strip()

                        if cat_col_S in df_track.columns:
                            df_track[cat_col_S] = df_track[cat_col_S].fillna('').astype(str).str.strip()

                        cat_check_value = "ç›Šç›Šæˆäººç²‰"
                        cat_exists_all = False
                        cat_exists_filtered = False
                        if cat_col_S in df_track.columns:
                            cat_exists_all = bool((df_track[cat_col_S] == cat_check_value).any())
                        if cat_col_S in df_f.columns:
                            cat_exists_filtered = bool((df_f[cat_col_S] == cat_check_value).any())

                        if cat_exists_all and (not cat_exists_filtered):
                            st.warning(f"âš ï¸ æºæ•°æ®â€œå¤§åˆ†ç±»â€åŒ…å«â€œ{cat_check_value}â€ï¼Œä½†åœ¨å½“å‰çœåŒº/ç»é”€å•†ç­›é€‰ä¸‹æ— æ•°æ®ã€‚è¯·è°ƒæ•´ç­›é€‰æŸ¥çœ‹ã€‚")

                        with st.expander("ğŸ” å¤§åˆ†ç±»æ•°æ®æ ¡éªŒ", expanded=False):
                            if cat_col_S not in df_track.columns:
                                st.error(f"æœªæ‰¾åˆ°ç”¨äºå¤§åˆ†ç±»çš„å­—æ®µï¼š{cat_col_S}")
                            else:
                                s_all = df_track[cat_col_S]
                                s_all_nonempty = s_all[s_all != ""]
                                st.write(f"å¤§åˆ†ç±»å­—æ®µï¼š{cat_col_S}")
                                st.write(f"å”¯ä¸€ç±»ç›®æ•°ï¼š{int(s_all_nonempty.nunique())}")
                                st.write(f"ç©ºå€¼å æ¯”ï¼š{fmt_pct_ratio(float((s_all == '').mean()))}")
                                st.write(f"æ˜¯å¦åŒ…å«â€œ{cat_check_value}â€ï¼š{'æ˜¯' if cat_exists_all else 'å¦'}")
                                top_counts = s_all_nonempty.value_counts().head(12).reset_index()
                                top_counts.columns = ["ç±»ç›®", "è¡Œæ•°"]
                                show_aggrid_table(top_counts, height=300, key="verify_table")

                        wh_opts = ['å…¨éƒ¨'] + sorted([x for x in df_f.get(cat_col_S, pd.Series(dtype=str)).unique() if x])
                        with f3:
                            sel_wh = st.selectbox(f"å¤§ç±» ({cat_col_S})", wh_opts, key="t26_wh")
                        
                        if sel_wh != 'å…¨éƒ¨':
                            df_f = df_f[df_f.get(cat_col_S, pd.Series(dtype=str)) == sel_wh]
                            
                        # Small Category (Group) - Multi Select
                        grp_opts = sorted([x for x in df_f['å½’ç±»'].unique() if x])
                        with f4:
                            sel_grp = st.multiselect("å°ç±» (å½’ç±»)", grp_opts, default=[], key="t26_grp")
                        if sel_grp:
                            df_f = df_f[df_f['å½’ç±»'].isin(sel_grp)]
                            
                        # Month Selection (Single)
                        avail_months = sorted(df_f[df_f['å¹´ä»½'] == cur_year]['æœˆä»½'].unique())
                        def_month = int(avail_months[-1]) if avail_months else 1
                        with f5:
                            sel_month = st.selectbox("ç»Ÿè®¡æœˆä»½", list(range(1, 13)), index=def_month-1, key="t26_month")
                    
                    # --- 3. Calculations ---
                    # Actuals
                    act_cur_year = df_f[df_f['å¹´ä»½'] == cur_year]['å‘è´§é‡‘é¢'].sum()
                    act_last_year = df_f[df_f['å¹´ä»½'] == last_year]['å‘è´§é‡‘é¢'].sum()
                    
                    act_cur_month = df_f[(df_f['å¹´ä»½'] == cur_year) & (df_f['æœˆä»½'] == sel_month)]['å‘è´§é‡‘é¢'].sum()
                    act_last_month = df_f[(df_f['å¹´ä»½'] == last_year) & (df_f['æœˆä»½'] == sel_month)]['å‘è´§é‡‘é¢'].sum()
                    
                    # Targets
                    target_cur_year = 0.0
                    target_cur_month = 0.0
                    if df_target is not None:
                        # Apply filters to target (Province, Category)
                        # Note: Distributor filter can't apply to Target usually, unless target is by dist. 
                        # User said Sheet5 has Province/Category.
                        df_t_f = df_target.copy()
                        if sel_prov != 'å…¨éƒ¨':
                            df_t_f = df_t_f[df_t_f['çœåŒº'] == sel_prov]
                        # Category mapping? Sheet5 'å“ç±»' vs Sheet4 'å½’ç±»'/'å‘è´§ä»“'.
                        # User said D col is Category. Assuming it matches 'å½’ç±»' or needs mapping.
                        # For now, we sum all if no specific match logic provided or if 'å…¨éƒ¨'.
                        # If user selected specific categories, we try to filter.
                        # BUT, without exact mapping, filtering Targets by Category is risky. 
                        # We'll calculate Total Target for selected Province.
                        
                        target_cur_year = df_t_f['ä»»åŠ¡é‡'].sum()
                        target_cur_month = df_t_f[df_t_f['æœˆä»½'] == sel_month]['ä»»åŠ¡é‡'].sum()
                    
                    # Rates & YoY
                    rate_year = (act_cur_year / target_cur_year) if target_cur_year > 0 else None
                    rate_month = (act_cur_month / target_cur_month) if target_cur_month > 0 else None
                    
                    yoy_year = (act_cur_year - act_last_year) / act_last_year if act_last_year > 0 else None
                    yoy_month = (act_cur_month - act_last_month) / act_last_month if act_last_month > 0 else None
                    
                    # --- 4. KPI Cards ---
                    def _fmt_wan(x): return fmt_num((x or 0) / 10000)
                    def _fmt_pct(x): return fmt_pct_ratio(x) if x is not None else "â€”"
                    def _color_pct(x): return "perf-up" if x and x>0 else "perf-down"
                    def _arrow(x): return "â†‘" if x and x>0 else ("â†“" if x and x<0 else "")

                    def _render_card(title, icon, val_wan, target_wan, rate, yoy_val_wan, yoy_pct):
                        trend_cls = "trend-up" if yoy_pct and yoy_pct > 0 else ("trend-down" if yoy_pct and yoy_pct < 0 else "trend-neutral")
                        arrow = _arrow(yoy_pct)
                        rate_txt = _fmt_pct(rate)
                        yoy_txt = _fmt_pct(yoy_pct)
                        pct_val = min(max(rate * 100 if rate else 0, 0), 100)
                        prog_color = "#28A745" if rate and rate >= 1.0 else ("#FFC107" if rate and rate >= 0.8 else "#DC3545")

                        st.markdown(f"""
                        <div class="out-kpi-card">
                            <div class="out-kpi-bar"></div>
                            <div class="out-kpi-head">
                                <div class="out-kpi-ico">{icon}</div>
                                <div class="out-kpi-title">{title}</div>
                            </div>
                            <div class="out-kpi-val">Â¥ {val_wan}ä¸‡</div>
                            <div class="out-kpi-sub2" style="margin-top:8px;">
                                <span>è¾¾æˆç‡</span>
                                <span style="font-weight:800; color:{prog_color}">{rate_txt}</span>
                            </div>
                            <div class="out-kpi-progress" style="margin-top:6px;">
                                <div class="out-kpi-progress-bar" style="background:{prog_color}; width:{pct_val}%;"></div>
                            </div>
                            <div class="out-kpi-sub2" style="margin-top:10px;">
                                <span>ç›®æ ‡</span>
                                <span>{target_wan}ä¸‡</span>
                            </div>
                            <div class="out-kpi-sub2">
                                <span>åŒæœŸ</span>
                                <span>{yoy_val_wan}ä¸‡</span>
                            </div>
                            <div class="out-kpi-sub2">
                                <span>åŒæ¯”</span>
                                <span class="{trend_cls}">{arrow} {yoy_txt}</span>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                    # --- TABS: KPI, Category, Province ---
                    tab_perf_kpi, tab_perf_cat, tab_perf_prov = st.tabs(["ğŸ“Š æ ¸å¿ƒä¸šç»©æŒ‡æ ‡", "ğŸ“¦ åˆ†å“ç±»", "ğŸ—ºï¸ åˆ†çœåŒº"])

                    with tab_perf_kpi:
                        k1, k2 = st.columns(2)
                        
                        with k1:
                            _render_card("æœ¬æœˆä¸šç»©", "ğŸ“…", _fmt_wan(act_cur_month), _fmt_wan(target_cur_month), rate_month, _fmt_wan(act_last_month), yoy_month)
                        with k2:
                            _render_card("å¹´åº¦ç´¯è®¡ä¸šç»©", "ğŸ†", _fmt_wan(act_cur_year), _fmt_wan(target_cur_year), rate_year, _fmt_wan(act_last_year), yoy_year)
                    
                    with tab_perf_cat:
                        # --- NEW: Category Performance Cards ---
                        
                        # Prepare Category Data
                        # Using cat_col_S ('å¤§åˆ†ç±»' or 'æœˆåˆ†æ' or 'å‘è´§ä»“')
                        
                        # 1. Monthly Category Data
                        cat_cur_m = df_f[(df_f['å¹´ä»½'] == cur_year) & (df_f['æœˆä»½'] == sel_month)].groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                        cat_last_m = df_f[(df_f['å¹´ä»½'] == last_year) & (df_f['æœˆä»½'] == sel_month)].groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                        
                        cat_m_final = pd.merge(cat_cur_m, cat_last_m, on=cat_col_S, how='outer').fillna(0)
                        cat_m_final['æœ¬æœˆ(ä¸‡)'] = cat_m_final['æœ¬æœˆ'] / 10000
                        cat_m_final['åŒæœŸ(ä¸‡)'] = cat_m_final['åŒæœŸ'] / 10000
                        cat_m_final['åŒæ¯”'] = np.where(cat_m_final['æœ¬æœˆ'] > 0, (cat_m_final['æœ¬æœˆ'] - cat_m_final['åŒæœŸ']) / cat_m_final['æœ¬æœˆ'], None)
                        cat_m_final = cat_m_final.sort_values('æœ¬æœˆ', ascending=False)

                        # 2. Yearly Category Data
                        cat_cur_y = df_f[df_f['å¹´ä»½'] == cur_year].groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬å¹´'})
                        cat_last_y = df_f[df_f['å¹´ä»½'] == last_year].groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                        
                        cat_y_final = pd.merge(cat_cur_y, cat_last_y, on=cat_col_S, how='outer').fillna(0)
                        cat_y_final['æœ¬å¹´(ä¸‡)'] = cat_y_final['æœ¬å¹´'] / 10000
                        cat_y_final['åŒæœŸ(ä¸‡)'] = cat_y_final['åŒæœŸ'] / 10000
                        cat_y_final['åŒæ¯”'] = np.where(cat_y_final['æœ¬å¹´'] > 0, (cat_y_final['æœ¬å¹´'] - cat_y_final['åŒæœŸ']) / cat_y_final['æœ¬å¹´'], None)
                        cat_y_final = cat_y_final.sort_values('æœ¬å¹´', ascending=False)

                        # Render 2 Columns for Tables
                        c_cat_m, c_cat_y = st.columns(2)

                        with c_cat_m:
                            st.markdown(
                                """
                                <div style="background-color: #F8F9FA; border-radius: 8px; padding: 16px; border: 1px solid #E9ECEF; box-shadow: 0 2px 4px rgba(0,0,0,0.05); height: 100%;">
                                    <div style="font-size: 14px; color: #6C757D; margin-bottom: 12px; font-weight: 500;">ğŸ“… æœ¬æœˆåˆ†å“ç±»ä¸šç»©</div>
                                """, 
                                unsafe_allow_html=True
                            )
                            # Replaced with AgGrid
                            show_aggrid_table(
                                cat_m_final[[cat_col_S, 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”']],
                                height=250,
                                key="ag_cat_m"
                            )
                            
                            # Donut Chart for Month
                            if not cat_m_final.empty and cat_m_final['æœ¬æœˆ(ä¸‡)'].sum() > 0:
                                total_m = cat_m_final['æœ¬æœˆ(ä¸‡)'].sum()
                                cat_m_final['legend_label'] = cat_m_final.apply(
                                    lambda r: f"{r[cat_col_S]}   {r['æœ¬æœˆ(ä¸‡)']:.1f}ä¸‡   {r['æœ¬æœˆ(ä¸‡)']/total_m:.1%}", axis=1
                                )
                                
                                fig_m = go.Figure(data=[go.Pie(
                                    labels=cat_m_final['legend_label'],
                                    values=cat_m_final['æœ¬æœˆ(ä¸‡)'],
                                    hole=0.6,
                                    marker=dict(colors=px.colors.qualitative.Pastel),
                                    textinfo='none',
                                    domain={'x': [0.4, 1.0]}
                                )])
                                fig_m.update_layout(
                                    showlegend=True,
                                    legend=dict(
                                        yanchor="middle", y=0.5,
                                        xanchor="left", x=0,
                                        font=dict(size=12, color="#333333")
                                    ),
                                    margin=dict(t=10, b=10, l=0, r=0), 
                                    height=250
                                )
                                st.plotly_chart(fig_m, use_container_width=True, key="perf_cat_month_donut")
                            else:
                                st.info("æš‚æ— æ•°æ®")
                                
                            st.markdown("</div>", unsafe_allow_html=True)

                        with c_cat_y:
                            st.markdown(
                                """
                                <div style="background-color: #F8F9FA; border-radius: 8px; padding: 16px; border: 1px solid #E9ECEF; box-shadow: 0 2px 4px rgba(0,0,0,0.05); height: 100%;">
                                    <div style="font-size: 14px; color: #6C757D; margin-bottom: 12px; font-weight: 500;">ğŸ† å¹´åº¦åˆ†å“ç±»ä¸šç»©</div>
                                """, 
                                unsafe_allow_html=True
                            )
                            # Replaced with AgGrid
                            show_aggrid_table(
                                cat_y_final[[cat_col_S, 'æœ¬å¹´(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”']],
                                height=250,
                                key="ag_cat_y"
                            )
                            
                            # Donut Chart for Year
                            if not cat_y_final.empty and cat_y_final['æœ¬å¹´(ä¸‡)'].sum() > 0:
                                total_y = cat_y_final['æœ¬å¹´(ä¸‡)'].sum()
                                cat_y_final['legend_label'] = cat_y_final.apply(
                                    lambda r: f"{r[cat_col_S]}   {r['æœ¬å¹´(ä¸‡)']:.1f}ä¸‡   {r['æœ¬å¹´(ä¸‡)']/total_y:.1%}", axis=1
                                )
                                
                                fig_y = go.Figure(data=[go.Pie(
                                    labels=cat_y_final['legend_label'],
                                    values=cat_y_final['æœ¬å¹´(ä¸‡)'],
                                    hole=0.6,
                                    marker=dict(colors=px.colors.qualitative.Pastel),
                                    textinfo='none',
                                    domain={'x': [0.4, 1.0]}
                                )])
                                fig_y.update_layout(
                                    showlegend=True,
                                    legend=dict(
                                        yanchor="middle", y=0.5,
                                        xanchor="left", x=0,
                                        font=dict(size=12, color="#333333")
                                    ),
                                    margin=dict(t=10, b=10, l=0, r=0), 
                                    height=250
                                )
                                st.plotly_chart(fig_y, use_container_width=True, key="perf_cat_year_donut")
                            else:
                                st.info("æš‚æ— æ•°æ®")
                                
                            st.markdown("</div>", unsafe_allow_html=True)

                    with tab_perf_prov:
                        # --- 5. Province Table (Detailed) ---
                        
                        # Prepare Data
                        # Group by Province
                        # 1. Actuals (Cur Month)
                        df_m_cur = df_f[(df_f['å¹´ä»½'] == cur_year) & (df_f['æœˆä»½'] == sel_month)]
                        prov_cur = df_m_cur.groupby('çœåŒº')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆä¸šç»©'})
                        
                        # 2. Actuals (Same Period)
                        df_m_last = df_f[(df_f['å¹´ä»½'] == last_year) & (df_f['æœˆä»½'] == sel_month)]
                        prov_last = df_m_last.groupby('çœåŒº')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸä¸šç»©'})
                        
                        # 3. Targets (Month)
                        if df_target is not None:
                            t_m = df_target[df_target['æœˆä»½'] == sel_month]
                            prov_target = t_m.groupby('çœåŒº')['ä»»åŠ¡é‡'].sum().reset_index().rename(columns={'ä»»åŠ¡é‡': 'æœ¬æœˆä»»åŠ¡'})
                        else:
                            prov_target = pd.DataFrame(columns=['çœåŒº', 'æœ¬æœˆä»»åŠ¡'])
                            
                        # Merge All
                        prov_final = pd.merge(prov_cur, prov_target, on='çœåŒº', how='outer')
                        prov_final = pd.merge(prov_final, prov_last, on='çœåŒº', how='outer').fillna(0)
                        
                        # Filter out rows with 0
                        prov_final = prov_final[(prov_final['æœ¬æœˆä¸šç»©']!=0) | (prov_final['æœ¬æœˆä»»åŠ¡']!=0) | (prov_final['åŒæœŸä¸šç»©']!=0)]
                        
                        # Metrics
                        prov_final['è¾¾æˆç‡'] = prov_final.apply(lambda x: (x['æœ¬æœˆä¸šç»©'] / x['æœ¬æœˆä»»åŠ¡']) if x['æœ¬æœˆä»»åŠ¡'] > 0 else 0, axis=1)
                        prov_final['åŒæ¯”å¢é•¿'] = prov_final.apply(lambda x: ((x['æœ¬æœˆä¸šç»©'] - x['åŒæœŸä¸šç»©']) / x['åŒæœŸä¸šç»©']) if x['åŒæœŸä¸šç»©'] > 0 else 0, axis=1)
                        
                        # Sort
                        prov_final = prov_final.sort_values('æœ¬æœˆä¸šç»©', ascending=False)
                        
                        # Format for Display
                        prov_final['æœ¬æœˆä¸šç»©(ä¸‡)'] = prov_final['æœ¬æœˆä¸šç»©'] / 10000
                        prov_final['æœ¬æœˆä»»åŠ¡(ä¸‡)'] = prov_final['æœ¬æœˆä»»åŠ¡'] / 10000
                        prov_final['åŒæœŸä¸šç»©(ä¸‡)'] = prov_final['åŒæœŸä¸šç»©'] / 10000
                        
                        # Display Columns
                        disp_df = prov_final[['çœåŒº', 'æœ¬æœˆä¸šç»©(ä¸‡)', 'æœ¬æœˆä»»åŠ¡(ä¸‡)', 'è¾¾æˆç‡', 'åŒæœŸä¸šç»©(ä¸‡)', 'åŒæ¯”å¢é•¿']].copy()
                        
                        # Interactive Table
                        st.caption("ğŸ‘‡ ç‚¹å‡»è¡¨æ ¼è¡Œå¯ä¸‹é’»æŸ¥çœ‹è¯¦ç»†æ•°æ®")
                        
                        # AgGrid for Province Performance
                        ag_prov = show_aggrid_table(
                            disp_df, 
                            key="perf_prov_ag",
                            on_row_selected=True
                        )
                        
                        # Drill Down
                        # Check if selected_rows exists and is not empty
                        selected_rows = ag_prov.get('selected_rows') if ag_prov else None
                        
                        if selected_rows is not None and len(selected_rows) > 0:
                            # AgGrid return structure might differ based on version
                            # Sometimes it returns a DataFrame, sometimes a list of dicts
                            if isinstance(selected_rows, pd.DataFrame):
                                first_row = selected_rows.iloc[0]
                            else:
                                first_row = selected_rows[0]
                                
                            # Handle if it returns a DataFrame row or dict
                            sel_prov_drill = first_row.get('çœåŒº') if isinstance(first_row, dict) else first_row['çœåŒº']
                            
                            # Drill Down Tabs
                            st.markdown("---")
                            st.subheader(f"ğŸ“ {sel_prov_drill} - æ˜ç»†æ•°æ®")
                            
                            tab_dist, tab_cat = st.tabs(["ğŸ¢ ç»é”€å•†æ˜ç»†", "ğŸ“¦ å“ç±»æ˜ç»†"])
                            
                            # Filter data for selected province
                            d_cur = df_f[(df_f['å¹´ä»½'] == cur_year) & (df_f['æœˆä»½'] == sel_month) & (df_f['çœåŒº'] == sel_prov_drill)]
                            d_last = df_f[(df_f['å¹´ä»½'] == last_year) & (df_f['æœˆä»½'] == sel_month) & (df_f['çœåŒº'] == sel_prov_drill)]

                            # --- Tab 1: Distributor Drill Down ---
                            with tab_dist:
                                st.caption(f"æ­£åœ¨æŸ¥çœ‹ï¼š{sel_prov_drill} > ç»é”€å•†æ˜ç»†")
                                d_cur_g = d_cur.groupby('ç»é”€å•†åç§°')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                                d_last_g = d_last.groupby('ç»é”€å•†åç§°')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                
                                d_final = pd.merge(d_cur_g, d_last_g, on='ç»é”€å•†åç§°', how='outer').fillna(0)
                                d_final['åŒæ¯”å¢é•¿'] = d_final.apply(lambda x: ((x['æœ¬æœˆ'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                                d_final = d_final.sort_values('æœ¬æœˆ', ascending=False)
                                
                                d_final['æœ¬æœˆ(ä¸‡)'] = d_final['æœ¬æœˆ'] / 10000
                                d_final['åŒæœŸ(ä¸‡)'] = d_final['åŒæœŸ'] / 10000
                                
                                ag_dist = show_aggrid_table(
                                    d_final[['ç»é”€å•†åç§°', 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”å¢é•¿']],
                                    key="perf_dist_ag",
                                    on_row_selected=True
                                )
                                
                                selected_rows_dist = ag_dist.get('selected_rows') if ag_dist else None
                                
                                if selected_rows_dist is not None and len(selected_rows_dist) > 0:
                                    if isinstance(selected_rows_dist, pd.DataFrame):
                                        first_row_dist = selected_rows_dist.iloc[0]
                                    else:
                                        first_row_dist = selected_rows_dist[0]
                                        
                                    sel_dist_drill = first_row_dist.get('ç»é”€å•†åç§°') if isinstance(first_row_dist, dict) else first_row_dist['ç»é”€å•†åç§°']
                                    st.info(f"ğŸ“ æ­£åœ¨æŸ¥çœ‹ {sel_prov_drill} > {sel_dist_drill} çš„å¤§åˆ†ç±»æ˜ç»†")
                                    
                                    if 'å¤§åˆ†ç±»' in d_cur.columns:
                                        cat_col_S = 'å¤§åˆ†ç±»'
                                    elif 'æœˆåˆ†æ' in d_cur.columns:
                                        cat_col_S = 'æœˆåˆ†æ'
                                    else:
                                        cat_col_S = 'å‘è´§ä»“'
                                    
                                    # Filter data for selected dist
                                    bc_cur = d_cur[d_cur['ç»é”€å•†åç§°'] == sel_dist_drill]
                                    bc_last = d_last[d_last['ç»é”€å•†åç§°'] == sel_dist_drill]
                                    
                                    bc_cur_g = bc_cur.groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                                    bc_last_g = bc_last.groupby(cat_col_S)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                    
                                    bc_final = pd.merge(bc_cur_g, bc_last_g, on=cat_col_S, how='outer').fillna(0)
                                    bc_final['åŒæ¯”å¢é•¿'] = bc_final.apply(lambda x: ((x['æœ¬æœˆ'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                                    bc_final = bc_final.sort_values('æœ¬æœˆ', ascending=False)
                                    
                                    bc_final['æœ¬æœˆ(ä¸‡)'] = bc_final['æœ¬æœˆ'] / 10000
                                    bc_final['åŒæœŸ(ä¸‡)'] = bc_final['åŒæœŸ'] / 10000
                                    
                                    ag_bc = show_aggrid_table(
                                        bc_final[[cat_col_S, 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”å¢é•¿']],
                                        key="perf_bc_table_dist_ag",
                                        on_row_selected=True
                                    )
                                    
                                    selected_rows_bc = ag_bc.get('selected_rows') if ag_bc else None
                                    
                                    if selected_rows_bc is not None and len(selected_rows_bc) > 0:
                                        if isinstance(selected_rows_bc, pd.DataFrame):
                                            first_row_bc = selected_rows_bc.iloc[0]
                                        else:
                                            first_row_bc = selected_rows_bc[0]
                                            
                                        sel_bc_drill = first_row_bc.get(cat_col_S) if isinstance(first_row_bc, dict) else first_row_bc[cat_col_S]
                                        st.info(f"ğŸ“ æ­£åœ¨æŸ¥çœ‹ {sel_prov_drill} > {sel_dist_drill} > {sel_bc_drill} çš„å°åˆ†ç±»(å½’ç±»)æ˜ç»†")
                                        
                                        # Level 4: Small Category (Group) for Selected Big Cat
                                        sc_cur = bc_cur[bc_cur[cat_col_S] == sel_bc_drill]
                                        sc_last = bc_last[bc_last[cat_col_S] == sel_bc_drill]
                                        
                                        sc_cur_g = sc_cur.groupby('å½’ç±»')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                                        sc_last_g = sc_last.groupby('å½’ç±»')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                        
                                        sc_final = pd.merge(sc_cur_g, sc_last_g, on='å½’ç±»', how='outer').fillna(0)
                                        sc_final['åŒæ¯”å¢é•¿'] = sc_final.apply(lambda x: ((x['æœ¬æœˆ'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                                        sc_final = sc_final.sort_values('æœ¬æœˆ', ascending=False)
                                        
                                        sc_final['æœ¬æœˆ(ä¸‡)'] = sc_final['æœ¬æœˆ'] / 10000
                                        sc_final['åŒæœŸ(ä¸‡)'] = sc_final['åŒæœŸ'] / 10000
                                        
                                        show_aggrid_table(
                                            sc_final[['å½’ç±»', 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”å¢é•¿']],
                                            key="perf_sc_table_dist_ag"
                                        )

                            with tab_cat:
                                st.caption(f"æ­£åœ¨æŸ¥çœ‹ï¼š{sel_prov_drill} > å“ç±»æ˜ç»† (æŒ‰å¤§åˆ†ç±»èšåˆ)")
                                if 'å¤§åˆ†ç±»' in d_cur.columns:
                                    agg_col = 'å¤§åˆ†ç±»'
                                elif 'æœˆåˆ†æ' in d_cur.columns:
                                    agg_col = 'æœˆåˆ†æ'
                                else:
                                    agg_col = 'å‘è´§ä»“'
                                
                                c_cur_g = d_cur.groupby(agg_col)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                                c_last_g = d_last.groupby(agg_col)['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                
                                c_final = pd.merge(c_cur_g, c_last_g, on=agg_col, how='outer').fillna(0)
                                c_final['åŒæ¯”å¢é•¿'] = c_final.apply(lambda x: ((x['æœ¬æœˆ'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                                c_final = c_final.sort_values('æœ¬æœˆ', ascending=False)
                                
                                c_final['æœ¬æœˆ(ä¸‡)'] = c_final['æœ¬æœˆ'] / 10000
                                c_final['åŒæœŸ(ä¸‡)'] = c_final['åŒæœŸ'] / 10000
                                
                                ag_cat = show_aggrid_table(
                                    c_final[[agg_col, 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”å¢é•¿']],
                                    key="perf_cat_table_ag",
                                    on_row_selected=True
                                )
                                
                                selected_rows_cat = ag_cat.get('selected_rows') if ag_cat else None
                                
                                if selected_rows_cat is not None and len(selected_rows_cat) > 0:
                                    if isinstance(selected_rows_cat, pd.DataFrame):
                                        first_row_cat = selected_rows_cat.iloc[0]
                                    else:
                                        first_row_cat = selected_rows_cat[0]
                                        
                                    sel_cat_drill = first_row_cat.get(agg_col) if isinstance(first_row_cat, dict) else first_row_cat[agg_col]
                                    st.info(f"ğŸ“ æ­£åœ¨æŸ¥çœ‹ {sel_prov_drill} > {sel_cat_drill} çš„å°åˆ†ç±»(å½’ç±»)æ˜ç»†")
                                    
                                    # Level 3: Small Category (Group) for Selected Big Cat (Province Level)
                                    sc_cur = d_cur[d_cur[agg_col] == sel_cat_drill]
                                    sc_last = d_last[d_last[agg_col] == sel_cat_drill]
                                    
                                    sc_cur_g = sc_cur.groupby('å½’ç±»')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'æœ¬æœˆ'})
                                    sc_last_g = sc_last.groupby('å½’ç±»')['å‘è´§é‡‘é¢'].sum().reset_index().rename(columns={'å‘è´§é‡‘é¢': 'åŒæœŸ'})
                                    
                                    sc_final = pd.merge(sc_cur_g, sc_last_g, on='å½’ç±»', how='outer').fillna(0)
                                    sc_final['åŒæ¯”å¢é•¿'] = sc_final.apply(lambda x: ((x['æœ¬æœˆ'] - x['åŒæœŸ']) / x['åŒæœŸ']) if x['åŒæœŸ'] > 0 else 0, axis=1)
                                    sc_final = sc_final.sort_values('æœ¬æœˆ', ascending=False)
                                    
                                    sc_final['æœ¬æœˆ(ä¸‡)'] = sc_final['æœ¬æœˆ'] / 10000
                                    sc_final['åŒæœŸ(ä¸‡)'] = sc_final['åŒæœŸ'] / 10000
                                    
                                    # Dynamic height
                                    n_rows_sc2 = len(sc_final)
                                    calc_height_sc2 = (n_rows_sc2 + 1) * 35 + 10
                                    final_height_sc2 = max(150, min(calc_height_sc2, 2000))
                                    
                                    show_aggrid_table(
                                        sc_final[['å½’ç±»', 'æœ¬æœˆ(ä¸‡)', 'åŒæœŸ(ä¸‡)', 'åŒæ¯”å¢é•¿']],
                                        height=final_height_sc2,
                                        key="perf_sc_table_cat_ag"
                                    )

else:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
