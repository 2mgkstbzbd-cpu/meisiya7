import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io
import time
import os
import socket
import hashlib
import re
from datetime import datetime
import html as _html
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
def _is_nan(x):
    try:
        return x != x
    except Exception:
        return False

def fmt_num(x, na="‚Äî"):
    if x is None or _is_nan(x):
        return na
    try:
        s = f"{float(x):,.2f}"
    except Exception:
        return str(x)
    s = s.rstrip("0").rstrip(".")
    return s

def fmt_pct_ratio(r, na="‚Äî", decimals=1):
    if r is None or _is_nan(r):
        return na
    v = float(r) * 100.0
    s = f"{v:.{decimals}f}".rstrip("0").rstrip(".")
    return f"{s}%"

def fmt_pct_value(p, na="‚Äî", decimals=1):
    if p is None or _is_nan(p):
        return na
    v = float(p)
    sign = "+" if v > 0 else ("-" if v < 0 else "")
    s = f"{abs(v):.{decimals}f}".rstrip("0").rstrip(".")
    return f"{sign}{s}%"

_COORD_NUM_RE = re.compile(r"[-+]?\d+(?:\.\d+)?")

def _parse_lon_lat(v):
    if v is None:
        return None, None
    s = str(v).strip()
    if not s or s.lower() in {"nan", "none"}:
        return None, None
    nums = _COORD_NUM_RE.findall(s)
    if len(nums) < 2:
        return None, None
    a = float(nums[0])
    b = float(nums[1])

    def _is_lon(x): return 70 <= x <= 140
    def _is_lat(x): return 0 <= x <= 60

    if _is_lon(a) and _is_lat(b):
        lon, lat = a, b
    elif _is_lon(b) and _is_lat(a):
        lon, lat = b, a
    else:
        lon, lat = (a, b) if abs(a) >= abs(b) else (b, a)
    if not _is_lon(lon) or not _is_lat(lat):
        return None, None
    return lon, lat

def get_host_ip():
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
    except Exception:
        ip = '127.0.0.1'
    finally:
        s.close()
    return ip

# -----------------------------------------------------------------------------
# 1. Page Config
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ÁæéÊÄùÈõÖÊï∞ÊçÆÂàÜÊûêÁ≥ªÁªü",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="collapsed"
)
st.markdown('<meta name="google" content="notranslate" />', unsafe_allow_html=True)
st.markdown("""
<script>
  document.documentElement.setAttribute("translate", "no");
  document.querySelector('html').setAttribute("translate", "no");
</script>
""", unsafe_allow_html=True)

_required_password = os.getenv("DASHBOARD_PASSWORD", "").strip()
if _required_password:
    if not st.session_state.get("_authed", False):
        st.markdown("### üîí ËÆøÈóÆÈ™åËØÅ")
        _pwd = st.text_input("ËØ∑ËæìÂÖ•ËÆøÈóÆÂØÜÁ†Å", type="password")
        if st.button("È™åËØÅ", type="primary"):
            if _pwd == _required_password:
                st.session_state["_authed"] = True
                st.rerun()
            else:
                st.error("ÂØÜÁ†ÅÈîôËØØ")
        st.stop()

if 'drill_level' not in st.session_state:
    st.session_state.drill_level = 1
if 'selected_prov' not in st.session_state:
    st.session_state.selected_prov = None
if 'selected_dist' not in st.session_state:
    st.session_state.selected_dist = None
if 'perf_time_mode' not in st.session_state:
    st.session_state.perf_time_mode = 'Ëøë12‰∏™Êúà'
if 'perf_provs' not in st.session_state:
    st.session_state.perf_provs = []
if 'perf_cats' not in st.session_state:
    st.session_state.perf_cats = []

# -----------------------------------------------------------------------------
# 2. Custom CSS
# -----------------------------------------------------------------------------
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap');
    :root {
        --bg-1: #F5F5F7;
        --bg-2: #ECECEC;
        --bg-3: #E0E0E0;
        --panel: #FFFFFF;
        --panel-2: rgba(255, 255, 255, 0.85);
        --stroke: #E0E0E0;
        --stroke-strong: #D1D1D1;
        --text: #1B1530;
        --text-muted: rgba(27, 21, 48, 0.7);
        --primary: #5B2EA6;
        --primary-2: #6A3AD0;
        --accent: #FFC400;
        --accent-2: #FFB000;
        --danger: #E5484D;
        --success: #2FBF71;
        --shadow: 0 10px 26px rgba(0, 0, 0, 0.08);
        --shadow-soft: 0 4px 12px rgba(0, 0, 0, 0.05);
        --radius: 12px;
        --radius-sm: 10px;
        --transition: 240ms cubic-bezier(.2,.8,.2,1);
        --focus: 0 0 0 3px rgba(91, 46, 166, 0.2);
        --tbl-header-bg: #4285F4;
        --tbl-header-bg-hover: #2F76E4;
        --tbl-header-border: #2B63C4;
        --tbl-header-fg: #FFFFFF;
        --tbl-header-icon: rgba(255, 255, 255, 0.92);
        --tbl-header-shadow: 0 6px 16px rgba(0, 0, 0, 0.16);
        --tbl-header-font-size: 15px;
        --tbl-header-font-weight: 800;
        --tbl-cell-font-size: 13px;
    }
    
    @media (prefers-color-scheme: dark) {
        :root {
            --tbl-header-bg: #2B66D9;
            --tbl-header-bg-hover: #2358C2;
            --tbl-header-border: #1B46A0;
            --tbl-header-fg: #FFFFFF;
            --tbl-header-icon: rgba(255, 255, 255, 0.95);
            --tbl-header-shadow: 0 10px 22px rgba(0, 0, 0, 0.32);
        }
    }

    html, body, [class*="css"] {
        font-family: 'Inter', 'Microsoft YaHei', sans-serif;
        color: var(--text);
    }

    .stApp {
        background: #F5F5F7;
    }

    [data-testid="stSidebar"], [data-testid="collapsedControl"] {
        display: none !important;
    }

    div[data-testid="stDataFrame"] thead tr th,
    div[data-testid="stTable"] thead tr th {
        background: var(--tbl-header-bg) !important;
        color: var(--tbl-header-fg) !important;
        font-weight: var(--tbl-header-font-weight) !important;
        font-size: var(--tbl-header-font-size) !important;
        border-bottom: 1px solid var(--tbl-header-border) !important;
    }

    div[data-testid="stDataFrame"] thead tr th:hover,
    div[data-testid="stTable"] thead tr th:hover {
        background: var(--tbl-header-bg-hover) !important;
    }

    div[data-testid="stDataFrame"] thead tr th:active,
    div[data-testid="stTable"] thead tr th:active {
        box-shadow: var(--tbl-header-shadow) !important;
    }

    .out-kpi-card {
        background: linear-gradient(180deg, rgba(66,133,244,0.08) 0%, rgba(255,255,255,0.92) 60%, #FFFFFF 100%);
        border-radius: 14px;
        padding: 16px 16px 14px;
        border: 1px solid rgba(66,133,244,0.22);
        box-shadow: 0 10px 26px rgba(0,0,0,0.06);
        margin-bottom: 10px;
        position: relative;
        overflow: hidden;
    }
    .out-kpi-bar {
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 3px;
        background: linear-gradient(90deg, var(--tbl-header-bg) 0%, var(--success) 60%, var(--accent) 100%);
        opacity: 0.9;
    }
    .out-kpi-head { display:flex; align-items:center; gap:10px; margin-bottom: 10px; }
    .out-kpi-ico {
        width: 34px;
        height: 34px;
        border-radius: 10px;
        display:flex;
        justify-content:center;
        align-items:center;
        background: rgba(66,133,244,0.16);
        border: 1px solid rgba(66,133,244,0.28);
        color: var(--tbl-header-bg);
        font-weight: 900;
        font-size: 18px;
    }
    .out-kpi-title { font-size: 15px; color: rgba(27,21,48,0.78); font-weight: 800; letter-spacing: 0.2px; }
    .out-kpi-val { font-size: 26px; font-weight: 900; color: #1B1530; margin-bottom: 4px; }
    .out-kpi-sub { font-size: 13px; display:flex; justify-content:space-between; align-items:center; color: rgba(27,21,48,0.72); }
    .out-kpi-sub2 { font-size: 12px; display:flex; justify-content:space-between; align-items:center; color: rgba(27,21,48,0.62); margin-top: 4px; }
    .out-kpi-progress { background: rgba(27,21,48,0.10); border-radius: 999px; height: 6px; width: 100%; overflow: hidden; }
    .out-kpi-progress-bar { height: 100%; border-radius: 999px; }
    .trend-up { color: var(--success); font-weight: 800; }
    .trend-down { color: var(--danger); font-weight: 800; }
    .trend-neutral { color: rgba(27,21,48,0.72); font-weight: 800; }
    @media (max-width: 768px) {
        .out-kpi-card { padding: 14px 14px 12px; }
        .out-kpi-val { font-size: 22px; }
        .out-kpi-title { font-size: 14px; }
    }

    h1, h2, h3, h4, h5, h6 {
        color: var(--text);
        letter-spacing: 0.2px;
        text-shadow: none;
    }

    [data-testid="stAppViewContainer"] {
        color: var(--text);
    }

    /* Reset global text visibility */
    .stMarkdown, .stText, p, li, span, label {
        color: var(--text) !important;
        text-shadow: none;
    }
    
    /* Caption specific */
    .stCaption {
        color: var(--text-muted) !important;
    }

    /* --- SIDEBAR STYLING REMOVED TO RESTORE VISIBILITY --- */
    
    /* Only keep global metric styling that doesn't affect visibility */
    div[data-testid="stMetric"] {
        background: var(--panel);
        border: 1px solid var(--stroke);
        border-radius: var(--radius);
        box-shadow: var(--shadow-soft);
        padding: 18px;
    }

    div[data-testid="stMetric"] * {
        color: var(--text) !important;
    }
    
    div[data-testid="stMetric"] label {
        color: var(--text-muted) !important;
    }

    div[data-testid="stMetric"] div[data-testid="stMetricValue"] {
        color: var(--primary) !important;
    }

    div[data-testid="stMetric"] div[data-testid="stMetricDelta"] {
        color: var(--accent-2) !important;
    }
    
    /* Buttons */
    div.stButton > button {
        border-radius: var(--radius-sm);
    }
    
    /* Analysis Button Customization */
    div.stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #FFC400 0%, #FFB000 100%) !important;
        border: 1px solid rgba(255, 176, 0, 0.4) !important;
        color: #5B2EA6 !important;
        font-weight: 700 !important;
        text-shadow: none !important;
        box-shadow: 0 4px 12px rgba(255, 196, 0, 0.25) !important;
        transition: all 0.2s ease !important;
    }

    div.stButton > button[kind="primary"]:hover {
        background: linear-gradient(135deg, #FFD54F 0%, #FFC107 100%) !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 6px 16px rgba(255, 196, 0, 0.35) !important;
        border-color: rgba(255, 176, 0, 0.6) !important;
    }
    
    div.stButton > button[kind="primary"]:active {
        transform: translateY(1px) !important;
        box-shadow: 0 2px 8px rgba(255, 196, 0, 0.2) !important;
    }
    
    /* Tabs styling kept simple */
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }

    /* Outbound subtabs (radio styled as tabs) */
    div[data-testid="stRadio"] .out-subtab-hint {display:none;}
    div[data-testid="stRadio"] [data-baseweb="radio"] > div {
        background: transparent !important;
        border: none !important;
        box-shadow: none !important;
        padding: 0 !important;
        margin: 0 !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input {
        position: absolute !important;
        opacity: 0 !important;
        pointer-events: none !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] div[role="radio"] {
        display: none !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] span {
        font-weight: 600 !important;
        color: rgba(27, 21, 48, 0.75) !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input:checked ~ div span {
        color: rgba(27, 21, 48, 0.95) !important;
    }
    div[data-testid="stRadio"] [data-testid="stRadio"] > div[role="radiogroup"] {
        border-bottom: 1px solid rgba(0, 0, 0, 0.08) !important;
        padding-bottom: 6px !important;
        gap: 10px !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] {
        position: relative !important;
        padding: 8px 0 10px 0 !important;
        margin-right: 14px !important;
    }
    div[data-testid="stRadio"] [data-baseweb="radio"] input:checked ~ div::after {
        content: "" !important;
        position: absolute !important;
        left: 0 !important;
        right: 0 !important;
        bottom: -7px !important;
        height: 2px !important;
        background: #E5484D !important;
        border-radius: 2px !important;
        transition: all 0.2s ease !important;
    }

    .out-subtab-content {
        animation: outFadeUp 240ms cubic-bezier(.2,.8,.2,1);
    }
    @keyframes outFadeUp {
        from { opacity: 0; transform: translateY(8px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* Ensure DataFrame styling is applied even if internal structure varies */
    [data-testid="stDataFrame"] {
        background: var(--panel);
        border: 1px solid var(--stroke);
        border-radius: var(--radius);
        box-shadow: var(--shadow-soft);
        overflow: hidden;
    }
    
    /* Target all possible table cells within the dataframe container */
    [data-testid="stDataFrame"] td, 
    [data-testid="stDataFrame"] th,
    [data-testid="stDataFrame"] [role="gridcell"],
    [data-testid="stDataFrame"] [role="columnheader"],
    [data-testid="stDataFrame"] div[data-testid="stDataFrameResizable"] {
        text-align: center !important;
        vertical-align: middle !important;
        color: var(--text) !important;
        display: flex;
        justify-content: center;
        align-items: center;
    }
    
    /* Force header content center */
    [data-testid="stDataFrame"] [role="columnheader"] > div {
        justify-content: center !important;
        text-align: center !important;
        width: 100%;
        display: flex;
    }
    
    /* Force cell content center */
    [data-testid="stDataFrame"] [role="gridcell"] > div {
        justify-content: center !important;
        text-align: center !important;
        width: 100%;
        display: flex;
    }

    /* Essential Visibility Controls */
    button[kind="header"], [data-testid="collapsedControl"] {
        visibility: visible !important;
        z-index: 999999 !important;
    }

    header {visibility: visible !important;}
    [data-testid="stSidebarNav"] {display: block !important;}
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
    [data-testid="stStatusWidget"] {visibility: hidden;}
    [data-testid="stToolbar"] {display: none !important;}
    [data-testid="stHeader"] {background: transparent !important;}
    [data-testid="stHeader"] a {display:none !important;}
    [data-testid="stViewerBadge"] {display:none !important;}
    [data-testid="stGitHubLink"] {display:none !important;}

    /* Sidebar explicit frosted light scheme to ensure readability */
    [data-testid="stSidebar"] {
        background: rgba(255, 255, 255, 0.88) !important;
        backdrop-filter: blur(10px) !important;
        border-right: 1px solid rgba(0, 0, 0, 0.08) !important;
    }
    [data-testid="stSidebar"] * {
        color: #333333 !important;
    }
    [data-testid="stSidebar"] summary svg,
    [data-testid="stSidebar"] svg {
        fill: #333333 !important;
    }
    [data-testid="stSidebar"] details[data-testid="stExpander"] > summary:hover {
        background: rgba(0,0,0,0.05) !important;
    }

    /* Sidebar inputs and selects */
    [data-testid="stSidebar"] input,
    [data-testid="stSidebar"] div[data-baseweb="select"] > div {
        background: rgba(255,255,255,0.95) !important;
        border: 1px solid rgba(0,0,0,0.15) !important;
        color: #333333 !important;
    }
    [data-testid="stSidebar"] input::placeholder {
        color: rgba(0,0,0,0.55) !important;
    }
    [data-testid="stSidebar"] div[data-baseweb="select"] > div:hover,
    [data-testid="stSidebar"] input:hover {
        border-color: rgba(91,46,166,0.6) !important;
    }

    /* File uploader dropzone */
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] {
        background: rgba(255,255,255,0.92) !important;
        border: 1px dashed rgba(0,0,0,0.18) !important;
        color: #333333 !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] span {
        color: #333333 !important;
    }
    [data-testid="stSidebar"] [data-testid="stBaseButton-secondary"] {
        background: rgba(91,46,166,0.10) !important;
        color: #333333 !important;
        border: 1px solid rgba(91,46,166,0.35) !important;
    }

    /* Collapsed control arrow visibility and contrast */
    [data-testid="collapsedControl"] {
        color: #333333 !important;
        background: rgba(255,255,255,0.55) !important;
        border: 1px solid rgba(0,0,0,0.12) !important;
        border-radius: 6px !important;
        top: 56px !important;
    }

    @media (max-width: 768px) {
        div[data-testid="stMetric"] {
            padding: 14px;
        }
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
    div[data-testid="stDataFrame"] div[role="gridcell"] { display: flex; align-items: center; }
    div[data-testid="stDataFrame"] div[role="columnheader"] { display: flex; align-items: center; justify-content: center; }
    .msy-table-wrap {
        width: 100%;
        overflow-x: auto;
        border-radius: 12px;
        border: 1px solid rgba(0,0,0,0.08);
        background: rgba(255,255,255,0.9);
        box-shadow: 0 6px 18px rgba(0,0,0,0.06);
    }
    table.msy-table {
        width: 100%;
        border-collapse: collapse;
        table-layout: auto;
        font-size: 14px;
        line-height: 1.45;
    }
    table.msy-table thead th {
        position: sticky;
        top: 0;
        background: #1F2937;
        color: #F9FAFB;
        font-weight: 700;
        padding: 10px 12px;
        border: 1px solid rgba(255,255,255,0.12);
        text-align: center;
        vertical-align: middle;
        white-space: nowrap;
    }
    table.msy-table tbody td {
        padding: 10px 12px;
        border: 1px solid rgba(0,0,0,0.08);
        text-align: center;
        vertical-align: middle;
        font-variant-numeric: tabular-nums;
        white-space: nowrap;
    }
    table.msy-table tbody tr:nth-child(even) td {
        background: #F8FAFC;
    }
    table.msy-table tbody tr:hover td {
        background: #EEF2FF;
    }
</style>
""", unsafe_allow_html=True)

def _format_cell(v):
    if v is None or pd.isna(v):
        return ""
    if isinstance(v, (int, float, np.integer, np.floating)):
        return fmt_num(v, na="")
    return str(v)


# -----------------------------------------------------------------------------
# AgGrid Helper
# -----------------------------------------------------------------------------
JS_COLOR_CONDITIONAL = JsCode("""
function(params) {
    if (params.value > 0) {
        return {'color': '#28A745', 'textAlign': 'center', 'fontWeight': 'bold'};
    } else if (params.value < 0) {
        return {'color': '#DC3545', 'textAlign': 'center', 'fontWeight': 'bold'};
    }
    return {'textAlign': 'center'};
}
""")

JS_CENTER = JsCode("""
function(params) {
    return {'textAlign': 'center'};
}
""")

JS_FMT_NUM = JsCode("""
function(params) {
    const v = params.value;
    if (v === null || v === undefined) return '';
    const n = Number(v);
    if (!isFinite(n)) return '';
    return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
}
""")

JS_FMT_PCT_RATIO = JsCode("""
function(params) {
    const v = params.value;
    if (v === null || v === undefined) return '';
    const n = Number(v);
    if (!isFinite(n)) return '';
    const p = n * 100;
    return p.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1}) + '%';
}
""")

# Custom Cell Renderer for Progress Bar (Mockup using HTML)
JS_PROGRESS_BAR = JsCode("""
class ProgressBarRenderer {
    init(params) {
        this.eGui = document.createElement('div');
        this.eGui.style.width = '100%';
        this.eGui.style.height = '100%';
        this.eGui.style.display = 'flex';
        this.eGui.style.alignItems = 'center';
        
        const fmt1 = (v) => {
            if (v === null || v === undefined) return '';
            const n = Number(v);
            if (!isFinite(n)) return '';
            if (Math.abs(n - Math.round(n)) < 1e-9) return Math.round(n).toLocaleString('zh-CN');
            return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
        };

        let value = params.value;
        if (value === null || value === undefined) value = 0;

        let maxValue = 0;
        if (params.colDef && params.colDef.cellRendererParams && params.colDef.cellRendererParams.maxValue !== undefined) {
            maxValue = Number(params.colDef.cellRendererParams.maxValue) || 0;
        }

        const percent = maxValue > 0 ? Math.min(Math.max((Number(value) / maxValue) * 100, 0), 100) : 0;

        let color = '#007bff';
        if (percent >= 100) color = '#28a745';
        else if (percent < 60) color = '#dc3545';
        else color = '#ffc107';
        
        this.eGui.innerHTML = `
            <div style="width: 100%; height: 20px; background-color: #e9ecef; border-radius: 3px; position: relative;">
                <div style="width: ${percent}%; height: 100%; background-color: ${color}; border-radius: 3px; transition: width 0.5s;"></div>
                <span style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; text-align: center; line-height: 20px; font-size: 12px; color: #000;">${fmt1(value)}</span>
            </div>
        `;
    }
    getGui() {
        return this.eGui;
    }
}
""")

# Custom Cell Renderer for Count (No %)
JS_PROGRESS_BAR_COUNT = JsCode("""
class ProgressBarCountRenderer {
    init(params) {
        this.eGui = document.createElement('div');
        this.eGui.style.width = '100%';
        this.eGui.style.height = '100%';
        this.eGui.style.display = 'flex';
        this.eGui.style.alignItems = 'center';
        
        const fmt1 = (v) => {
            if (v === null || v === undefined) return '';
            const n = Number(v);
            if (!isFinite(n)) return '';
            if (Math.abs(n - Math.round(n)) < 1e-9) return Math.round(n).toLocaleString('zh-CN');
            return n.toLocaleString('zh-CN', {minimumFractionDigits: 1, maximumFractionDigits: 1});
        };

        let value = params.value;
        if (value === null || value === undefined) value = 0;

        let maxValue = 0;
        if (params.colDef && params.colDef.cellRendererParams && params.colDef.cellRendererParams.maxValue !== undefined) {
            maxValue = Number(params.colDef.cellRendererParams.maxValue) || 0;
        }

        const percent = maxValue > 0 ? Math.min(Math.max((Number(value) / maxValue) * 100, 0), 100) : 0;

        let color = '#28a745';
        if (percent > 0) color = '#ffc107';
        if (percent >= 60) color = '#dc3545';
        
        this.eGui.innerHTML = `
            <div style="width: 100%; height: 20px; background-color: #e9ecef; border-radius: 3px; position: relative;">
                <div style="width: ${percent}%; height: 100%; background-color: ${color}; border-radius: 3px; transition: width 0.5s;"></div>
                <span style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; text-align: center; line-height: 20px; font-size: 12px; color: #000;">${fmt1(value)}</span>
            </div>
        `;
    }
    getGui() {
        return this.eGui;
    }
}
""")

def show_aggrid_table(df, height=None, key=None, on_row_selected=None, 
                      columns_props=None, 
                      column_defs=None,
                      grid_options_overrides=None,
                      auto_height_limit=2000):
    """
    Standardized AgGrid Table
    :param df: DataFrame to display
    :param height: Fixed height (optional)
    :param key: Unique key
    :param on_row_selected: 'single' or 'multiple' or None
    :param columns_props: Dict of col_name -> {type: 'percent'|'money'|'growth'|'bar', ...}
    :param auto_height_limit: Max height for auto calculation
    """
    if df is None or df.empty:
        # Custom Empty State
        st.markdown("""
            <div style="text-align: center; padding: 40px; background: #f8f9fa; border-radius: 8px; border: 1px dashed #d9d9d9;">
                <div style="font-size: 24px; margin-bottom: 10px;">üì≠</div>
                <div style="color: #666; font-size: 14px;">ÊöÇÊó†Êï∞ÊçÆ</div>
            </div>
        """, unsafe_allow_html=True)
        return None

    # Inject CSS for Custom AgGrid Styling
    st.markdown("""
        <style>
        /* --- 1. Header Styling --- */
        .ag-header {
            background-color: var(--tbl-header-bg) !important;
            border-bottom: 1px solid var(--tbl-header-border) !important;
        }
        .ag-header-row,
        .ag-header-group-cell,
        .ag-header-cell {
            background-color: var(--tbl-header-bg) !important;
        }
        .ag-header-group-cell:hover,
        .ag-header-cell:hover {
            background-color: var(--tbl-header-bg-hover) !important;
        }
        .ag-header-group-cell:active,
        .ag-header-cell:active {
            box-shadow: var(--tbl-header-shadow) !important;
        }
        .ag-header-cell {
            color: var(--tbl-header-fg) !important;
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-header-font-size) !important;
            font-weight: var(--tbl-header-font-weight) !important;
            padding: 0 12px !important;
        }
        .ag-header-group-cell {
            color: var(--tbl-header-fg) !important;
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-header-font-size) !important;
            font-weight: var(--tbl-header-font-weight) !important;
        }
        .ag-header-cell .ag-icon,
        .ag-header-group-cell .ag-icon,
        .ag-sort-indicator-icon,
        .ag-icon-asc,
        .ag-icon-desc,
        .ag-icon-menu {
            color: var(--tbl-header-icon) !important;
            fill: var(--tbl-header-icon) !important;
            opacity: 1 !important;
        }
        /* Strict Centering for Header */
        .ag-header-cell-label {
            display: flex !important;
            justify-content: center !important;
            align-items: center !important;
            text-align: center !important;
            width: 100% !important;
        }
        .ag-header-cell-label, .ag-header-cell-text {
            white-space: normal !important;
            overflow: visible !important;
            text-overflow: clip !important;
            line-height: 1.2 !important;
        }

        /* Strict Centering for Cells */
        .ag-cell, .ag-cell-value {
            display: flex !important;
            justify-content: center !important;
            align-items: center !important;
            text-align: center !important;
        }
        
        /* Remove default separator bars in header */
        .ag-header-cell::after, .ag-header-group-cell::after {
            display: none !important;
        }

        /* --- 2. Row & Cell Styling --- */
        .ag-row {
            font-family: 'Inter', 'Microsoft YaHei', sans-serif !important;
            font-size: var(--tbl-cell-font-size) !important;
            color: #333333 !important;
            border-bottom-color: #f0f0f0 !important;
        }
        .ag-row-odd {
            background-color: #f8f9fa !important;
        }
        .ag-row-even {
            background-color: #ffffff !important;
        }
        .ag-row-hover {
            background-color: #f0f7ff !important;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;
            z-index: 5;
        }
        .ag-row-selected {
            background-color: #e6f7ff !important;
            border-left: 2px solid #4096ff !important; /* Left highlight */
        }
        
        /* Removed duplicate .ag-cell rule, handled above */

        /* Selected Row Text */
        .ag-row-selected .ag-cell {
            font-weight: 500 !important;
        }

        .ag-row.ag-row-pinned,
        .ag-row.ag-row-pinned-bottom {
            background-color: var(--tbl-header-bg) !important;
        }
        .ag-row-pinned .ag-cell,
        .ag-row-pinned-bottom .ag-cell {
            color: var(--tbl-header-fg) !important;
            font-weight: 900 !important;
            border-top: 1px solid var(--tbl-header-border) !important;
        }
        .ag-row-pinned .ag-cell .ag-cell-value,
        .ag-row-pinned-bottom .ag-cell .ag-cell-value {
            color: var(--tbl-header-fg) !important;
            font-weight: 900 !important;
        }
        .ag-row-pinned .ag-cell .ag-icon,
        .ag-row-pinned-bottom .ag-cell .ag-icon {
            color: var(--tbl-header-icon) !important;
            fill: var(--tbl-header-icon) !important;
        }
        
        /* --- 3. Container & Borders --- */
        .ag-root-wrapper {
            border: 1px solid #e5e6eb !important;
            border-radius: 4px !important;
            overflow: hidden !important; /* For radius */
        }
        
        /* --- 4. Scrollbars (Optional, for better look) --- */
        .ag-body-viewport::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        .ag-body-viewport::-webkit-scrollbar-thumb {
            background: #ccc;
            border-radius: 4px;
        }
        .ag-body-viewport::-webkit-scrollbar-track {
            background: #f1f1f1;
        }

        /* --- 5. Mobile Optimization --- */
        @media (max-width: 768px) {
            .ag-header-cell {
                font-size: 13px !important;
                padding: 0 4px !important;
            }
            .ag-header-group-cell {
                font-size: 13px !important;
            }
            .ag-cell {
                font-size: 12px !important;
                padding: 0 4px !important;
            }
            .ag-header-group-cell:active,
            .ag-header-cell:active {
                box-shadow: none !important;
            }
        }
        </style>
    """, unsafe_allow_html=True)

    gb = GridOptionsBuilder.from_dataframe(df)

    percent_cols = set()
    if columns_props:
        for col, props in columns_props.items():
            c_type = (props or {}).get('type')
            if c_type in ['percent', 'growth']:
                percent_cols.add(col)
    for col in df.columns:
        if ('ÂêåÊØî' in str(col)) or ('Â¢ûÈïø' in str(col)) or ('ËææÊàêÁéá' in str(col)) or (str(col).endswith('Áéá')):
            percent_cols.add(col)
    
    total_row = {c: None for c in df.columns}
    if len(df.columns) > 0:
        total_row[df.columns[0]] = 'ÂêàËÆ°'
    yoy_cols = [c for c in df.columns if ('ÂêåÊØî' in str(c)) or (str(c) == 'ÂêåÊØîÂ¢ûÈïø')]

    for c in df.columns:
        if c == df.columns[0]:
            continue
        if c in percent_cols:
            continue
        s = pd.to_numeric(df[c], errors='coerce')
        if s.notna().sum() == 0:
            continue
        total_row[c] = float(s.fillna(0).sum())

    def _infer_yoy_pair(yoy_col: str):
        if yoy_col not in df.columns:
            return None

        for old, new in [
            ('ÂêåÊØî(ÁÆ±)', 'ÁÆ±Êï∞'),
            ('ÂêåÊØîÔºàÁÆ±Ôºâ', 'ÁÆ±Êï∞'),
            ('ÂêåÊØî(Èó®Â∫ó)', 'Èó®Â∫óÊï∞'),
            ('ÂêåÊØîÔºàÈó®Â∫óÔºâ', 'Èó®Â∫óÊï∞'),
        ]:
            if old in str(yoy_col):
                cur = str(yoy_col).replace(old, new)
                last = str(yoy_col).replace(old, 'ÂêåÊúü(ÁÆ±Êï∞)' if 'ÁÆ±' in old else 'ÂêåÊúü(Èó®Â∫óÊï∞)')
                if cur in df.columns and last in df.columns:
                    return cur, last

        if str(yoy_col) == 'ÂêåÊØîÂ¢ûÈïø':
            for cur, last in [
                ('Êú¨Êúà', 'ÂêåÊúü'),
                ('Êú¨Êúà‰∏öÁª©', 'ÂêåÊúü‰∏öÁª©'),
                ('Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)'),
                ('Êú¨Êúà‰∏öÁª©(‰∏á)', 'ÂêåÊúü‰∏öÁª©(‰∏á)'),
                ('ÂÆûÈôÖ', 'ÂêåÊúü'),
            ]:
                if cur in df.columns and last in df.columns:
                    return cur, last

        base = (
            str(yoy_col)
            .replace('ÂêåÊØîÂ¢ûÈïø', '')
            .replace('ÂêåÊØî', '')
            .replace('Â¢ûÈïø', '')
            .strip()
        )
        if not base:
            return None
        last_candidates = [c for c in df.columns if ('ÂêåÊúü' in str(c) or 'ÂéªÂπ¥' in str(c)) and base in str(c)]
        cur_candidates = [c for c in df.columns if ('ÂêåÊúü' not in str(c) and 'ÂéªÂπ¥' not in str(c) and 'ÂêåÊØî' not in str(c) and 'Â¢ûÈïø' not in str(c)) and base in str(c)]
        if len(cur_candidates) == 1 and len(last_candidates) == 1:
            return cur_candidates[0], last_candidates[0]
        return None

    for c in yoy_cols:
        pair = _infer_yoy_pair(c)
        if not pair:
            continue
        cur_col, last_col = pair
        try:
            cur_sum = float(pd.to_numeric(df[cur_col], errors='coerce').fillna(0).sum())
            last_sum = float(pd.to_numeric(df[last_col], errors='coerce').fillna(0).sum())
            total_row[c] = (cur_sum - last_sum) / last_sum if last_sum > 0 else None
        except Exception:
            total_row[c] = None
    
    # Configure General Options
    gb.configure_grid_options(
        rowHeight=40, # increased for padding
        headerHeight=60,
        animateRows=True,
        suppressCellFocus=True, # remove blue outline on click
        enableCellTextSelection=True,
        suppressDragLeaveHidesColumns=True,
        sideBar={
            "toolPanels": [
                {
                    "id": "columns",
                    "labelDefault": "Âàó",
                    "iconKey": "columns",
                    "toolPanel": "agColumnsToolPanel",
                    "toolPanelParams": {
                        "suppressRowGroups": True,
                        "suppressValues": True,
                        "suppressPivots": True,
                        "suppressPivotMode": True
                    }
                }
            ],
            "defaultToolPanel": None
        }
    )
    
    # Default Config: Centered, Resizable, Sortable, Filterable
    gb.configure_default_column(
        resizable=True,
        filterable=True,
        sortable=True,
        cellStyle=JS_CENTER,
        headerClass='ag-header-center',
        headerStyle={'textAlign': 'center', 'justifyContent': 'center'},
        wrapHeaderText=True,
        autoHeaderHeight=True,
        minWidth=70,
        flex=1
    )
    
    configured_cols = set()

    # Apply Column Specific Props
    if columns_props:
        for col, props in columns_props.items():
            if col not in df.columns:
                continue
            
            c_type = props.get('type')
            max_value = None
            if c_type in ("bar", "bar_count"):
                s = pd.to_numeric(df[col], errors='coerce')
                max_value = float(s.max()) if len(s) and pd.notna(s.max()) else 0.0
            
            if c_type == 'growth':
                gb.configure_column(col, 
                                    cellStyle=JS_COLOR_CONDITIONAL, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_PCT_RATIO,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'percent':
                 gb.configure_column(col, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_PCT_RATIO,
                                    minWidth=70,
                                    flex=1)
                 configured_cols.add(col)
            elif c_type == 'money':
                gb.configure_column(col, 
                                    type=["numericColumn", "numberColumnFilter"], 
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'bar':
                # Use custom renderer
                gb.configure_column(col, 
                                    cellRenderer=JS_PROGRESS_BAR,
                                    cellRendererParams={'maxValue': max_value},
                                    type=["numericColumn", "numberColumnFilter"],
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
            elif c_type == 'bar_count':
                # Use custom renderer for count
                gb.configure_column(col, 
                                    cellRenderer=JS_PROGRESS_BAR_COUNT,
                                    cellRendererParams={'maxValue': max_value},
                                    type=["numericColumn", "numberColumnFilter"],
                                    valueFormatter=JS_FMT_NUM,
                                    minWidth=70,
                                    flex=1)
                configured_cols.add(col)
                
    # Generic Auto-Type Logic (Fallbacks)
    for col in df.columns:
        if col in configured_cols:
            continue
        
        # Check if column has 'growth' or 'ÂêåÊØî' -> Growth Color
        if 'ÂêåÊØî' in col or 'Â¢ûÈïø' in col:
            gb.configure_column(col, 
                                cellStyle=JS_COLOR_CONDITIONAL, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_PCT_RATIO,
                                minWidth=70,
                                flex=1)
        
        # Check if 'ËææÊàêÁéá' or 'Áéá' -> Percent
        elif 'ËææÊàêÁéá' in col or 'Âç†ÊØî' in col or str(col).endswith('Áéá'):
            gb.configure_column(col, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_PCT_RATIO,
                                minWidth=70,
                                flex=1)
            
            # Optional: Add Data Bar style for 'ËææÊàêÁéá' if requested
            if 'ËææÊàêÁéá' in col:
                 gb.configure_column(col,
                    cellStyle=JsCode("""
                        function(params) {
                            let ratio = params.value;
                            if (ratio === null || isNaN(ratio)) return {'textAlign': 'center'};
                            let percent = ratio * 100;
                             let color = '#28a745'; // Green
                             if (percent < 100) color = '#ffc107'; // Yellow
                             if (percent < 60) color = '#dc3545'; // Red
                             return {
                                 'textAlign': 'center', 
                                 'background': `linear-gradient(90deg, ${color} ${Math.min(percent, 100)}%, transparent ${Math.min(percent, 100)}%)`
                             };
                        }
                    """),
                    valueFormatter=JS_FMT_PCT_RATIO,
                    minWidth=70,
                    flex=1
                 )

        # Money/Number
        elif pd.api.types.is_numeric_dtype(df[col]):
            gb.configure_column(col, 
                                type=["numericColumn", "numberColumnFilter"], 
                                valueFormatter=JS_FMT_NUM,
                                minWidth=70,
                                flex=1)
        else:
            if col == df.columns[0]:
                gb.configure_column(col, minWidth=95, flex=1.2, tooltipField=col)
            else:
                gb.configure_column(col, minWidth=100, flex=1.2, tooltipField=col)

    # Selection
    if on_row_selected:
        gb.configure_selection('single', use_checkbox=False)
        
    gridOptions = gb.build()
    gridOptions['pinnedBottomRowData'] = [total_row]
    if column_defs:
        gridOptions['columnDefs'] = column_defs
        gridOptions['groupHeaderHeight'] = 40
        gridOptions['headerHeight'] = 46
    if grid_options_overrides:
        gridOptions.update(grid_options_overrides)
    
    # --- Auto Height & Pagination Logic ---
    # 1. Calculate ideal height for all rows
    n_rows = len(df)
    row_h = 40  # consistent with configure_grid_options rowHeight
    header_h = 60 # consistent with configure_grid_options headerHeight
    padding = 20
    
    calc_full_height = header_h + (n_rows * row_h) + padding + 40 # +40 buffer for potential horizontal scrollbar/total row
    
    # 2. Thresholds
    MAX_HEIGHT_NO_SCROLL = 600  # If content < 600px, show full height (no scroll/pagination)
    PAGE_SIZE = 20              # If content > 600px, use pagination with 20 rows/page
    
    # 3. Determine Mode
    # If explicit height provided, use it (and scroll if needed)
    # Else, apply auto-logic
    if height:
        final_height = height
        # If explicitly short height, maybe enable pagination? No, trust caller or AgGrid default scroll.
    else:
        if calc_full_height <= MAX_HEIGHT_NO_SCROLL:
            final_height = max(150, calc_full_height) # At least 150px
            # No pagination needed
            gridOptions['pagination'] = False
        else:
            # Content too long -> Use Pagination
            gridOptions['pagination'] = True
            gridOptions['paginationPageSize'] = PAGE_SIZE
            # Height fits PageSize rows + Header + PaginationPanel
            # PageSize * RowHeight + Header + PagerPanel(~50px)
            final_height = (PAGE_SIZE * row_h) + header_h + 50 + padding
    
    # Enable SideBar for Columns Tool Panel (Optional, user asked for "Drop down menu for each column")
    # AgGrid default filter menu is on column header. 
    
    # --- Responsive & Horizontal Scroll Logic ---
    # If too many columns, disable 'fit_columns_on_grid_load' to allow horizontal scroll
    # Heuristic: > 8-10 columns or if we suspect wide content
    should_fit_columns = True
    if len(df.columns) > 10:
        should_fit_columns = False
    
    return AgGrid(
        df,
        gridOptions=gridOptions,
        height=final_height,
        width='100%',
        data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
        update_mode=GridUpdateMode.SELECTION_CHANGED | GridUpdateMode.VALUE_CHANGED,
        fit_columns_on_grid_load=should_fit_columns,
        allow_unsafe_jscode=True, 
        theme='streamlit', 
        key=key
    )

# -----------------------------------------------------------------------------
# 3. Data Logic
# -----------------------------------------------------------------------------

@st.cache_data(show_spinner=False)
def load_data_v2(file_bytes: bytes, file_name: str):
    debug_logs = []
    try:
        file_name_lower = (file_name or "").lower()
        bio = io.BytesIO(file_bytes)
        if file_name_lower.endswith('.csv'):
            df = pd.read_csv(bio, encoding='gb18030')
            df_stock = None
            df_q4_raw = None
            df_perf_raw = None
        else:
            xl = pd.ExcelFile(bio)
            df = xl.parse(0)
            df_stock = xl.parse(1) if len(xl.sheet_names) > 1 else None
            df_q4_raw = xl.parse(2) if len(xl.sheet_names) > 2 else None
            df_perf_raw = None
            
            debug_logs.append(f"Total Sheets: {len(xl.sheet_names)} | Names: {xl.sheet_names}")

            # Sheet 4 Detection Logic (Robust)
            if len(xl.sheet_names) > 3:
                preferred = next((s for s in xl.sheet_names if 'sheet4' in str(s).strip().lower()), None)
                candidate_names = [preferred] if preferred else []
                candidate_names += [s for s in xl.sheet_names if s not in candidate_names]
                
                for sname in candidate_names:
                    try:
                        # Optimization: Read only header first (0 rows) to check columns
                        tmp_header = xl.parse(sname, nrows=0)
                        cols = [str(c).strip() for c in tmp_header.columns]
                    except Exception as e:
                        debug_logs.append(f"Error parsing header of {sname}: {str(e)}")
                        continue
                    
                    # Fuzzy match for keys
                    key_hits = sum(1 for k in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ', 'ÁúÅÂå∫'] if any(k in c for c in cols))
                    signal_hits = sum(1 for k in ['ÂèëË¥ß‰ªì', 'Âéü‰ª∑ÈáëÈ¢ù', 'Âü∫Êú¨Êï∞Èáè', 'Â§ßÂàÜÁ±ª', 'ÊúàÂàÜÊûê', 'ÂÆ¢Êà∑ÁÆÄÁß∞'] if any(k in c for c in cols))
                    
                    debug_logs.append(f"Checking '{sname}': keys={key_hits}, signals={signal_hits}")
                    
                    if key_hits >= 2 and signal_hits >= 1:
                        # Found it! Now read the full sheet
                        try:
                            df_perf_raw = xl.parse(sname)
                            debug_logs.append(f"-> MATCHED Sheet4: {sname}")
                            break
                        except Exception as e:
                            debug_logs.append(f"Error reading body of {sname}: {e}")
            else:
                 debug_logs.append("Warning: Less than 4 sheets found.")
            
        # --- Process Sheet 1 (Sales) ---
        # Ensure column names are clean
        df.columns = [str(c).strip() for c in df.columns]
        
        # --- Handle Long Format (Rows) -> Wide Format (Columns) ---
        # User indicates Time (Month) is in Column F (index 5)
        # Potential Columns: F=Time, I=Prov, J=Dist, K=Qty (based on user info)
        is_long_format = False
        time_col = None
        
        # Check if Column F exists and looks like Month
        if len(df.columns) > 5:
            col_f = df.columns[5]
            # Check a sample of values in Col F for "Êúà" or date-like
            sample_vals = df[col_f].dropna().head(10).astype(str).tolist()
            if any('Êúà' in v for v in sample_vals):
                is_long_format = True
                time_col = col_f
        
        if is_long_format:
            # Identify Key Columns for Pivot
            # Try to map by name or index
            # User hints: Prov(I=8), Dist(J=9), Qty(K=10)
            
            col_prov = df.columns[8] if len(df.columns) > 8 else None
            col_dist = df.columns[9] if len(df.columns) > 9 else None
            col_qty = df.columns[10] if len(df.columns) > 10 else None
            
            # Fallback: Search by name
            if col_prov is None: col_prov = next((c for c in df.columns if 'ÁúÅ' in c), None)
            if col_dist is None: col_dist = next((c for c in df.columns if 'ÁªèÈîÄ' in c or 'ÂÆ¢Êà∑' in c), None)
            if col_qty is None: col_qty = next((c for c in df.columns if 'Êï∞' in c or 'Qty' in c or 'ÁÆ±' in c), None)
            
            # Store Column? If not found, default to Dist or blank
            col_store = next((c for c in df.columns if 'Èó®Â∫ó' in c), None)
            
            if col_prov and col_dist and col_qty and time_col:
                # Prepare for Pivot
                pivot_index = [col_prov, col_dist]
                if col_store:
                    pivot_index.append(col_store)
                
                # Pivot
                # Ensure Qty is numeric
                df[col_qty] = pd.to_numeric(df[col_qty], errors='coerce').fillna(0)
                
                df_wide = df.pivot_table(
                    index=pivot_index,
                    columns=time_col,
                    values=col_qty,
                    aggfunc='sum'
                ).reset_index()
                
                # Handle Missing Store Column if needed
                if not col_store:
                    df_wide['Èó®Â∫óÂêçÁß∞'] = df_wide[col_dist] # Use Dist as Store if missing
                    
                df = df_wide
                # Reset clean columns
                df.columns = [str(c).strip() for c in df.columns]
                
        # Identify Month Columns (Assume '1Êúà', '2Êúà', etc. or columns 4 onwards if strict structure)
        # Based on user requirement: Col 1-3 are dimensions, 4+ are months.
        # Let's try to detect "XÊúà" pattern first, fallback to index.
        month_cols = [c for c in df.columns if 'Êúà' in c and c not in ['ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'Èó®Â∫óÂêçÁß∞']]
        
        # If headers are standard: ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞, ÁªèÈîÄÂïÜÂêçÁß∞, Èó®Â∫óÂêçÁß∞
        # Normalize dimension columns
        rename_map = {}
        if 'ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞' in df.columns: rename_map['ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞'] = 'ÁúÅÂå∫'
        if 'ÁªèÈîÄÂïÜÂêçÁß∞' not in df.columns and len(df.columns) > 1: rename_map[df.columns[1]] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
        if 'Èó®Â∫óÂêçÁß∞' not in df.columns and len(df.columns) > 2: rename_map[df.columns[2]] = 'Èó®Â∫óÂêçÁß∞'
        
        df = df.rename(columns=rename_map)
        
        # Validate critical columns
        required = ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'Èó®Â∫óÂêçÁß∞']
        for req in required:
            if req not in df.columns:
                # Fallback: Assume positional 0, 1, 2
                if len(df.columns) >= 3:
                    df.columns.values[0] = 'ÁúÅÂå∫'
                    df.columns.values[1] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
                    df.columns.values[2] = 'Èó®Â∫óÂêçÁß∞'
                else:
                    st.error(f"Êï∞ÊçÆÊ†ºÂºèÈîôËØØÔºöÁº∫Â§±Âàó {req}")
                    return None, None, None, None

        # Re-identify month cols after rename
        month_cols = [c for c in df.columns if c not in required]
        
        # Ensure numeric
        for col in month_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        # --- Core Metric Calculation ---
        # 1. Total Shipment
        df['ÊÄªÂá∫Â∫ìÊï∞'] = df[month_cols].sum(axis=1)
        
        # 2. Effective Months (Count where Shipment > 0)
        df['ÊúâÊïàÊúà‰ªΩÊï∞'] = df[month_cols].gt(0).sum(axis=1).astype(int)
        
        # 3. Avg Monthly Shipment
        # Optimized: Vectorized calculation instead of apply
        df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] = np.where(df['ÊúâÊïàÊúà‰ªΩÊï∞'] > 0, df['ÊÄªÂá∫Â∫ìÊï∞'] / df['ÊúâÊïàÊúà‰ªΩÊï∞'], 0.0)
        
        # Classification
        # Optimized: Vectorized select
        conditions = [
            df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 4,
            (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 2) & (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] < 4),
            (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 1) & (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] < 2)
        ]
        choices = ['AÁ±ªÈó®Â∫ó (>=4)', 'BÁ±ªÈó®Â∫ó (2-4)', 'CÁ±ªÈó®Â∫ó (1-2)']
        df['Èó®Â∫óÂàÜÁ±ª'] = np.select(conditions, choices, default='DÁ±ªÈó®Â∫ó (<1)')
        
        # --- Process Sheet 2 (Stock) ---
        if df_stock is not None:
            # Clean columns
            df_stock.columns = [str(c).strip() for c in df_stock.columns]
            
            # Validate Stock Columns (A-L strict structure check or Name check)
            # User defined: ÁªèÈîÄÂïÜÁºñÁ†Å(A), ÁªèÈîÄÂïÜÂêçÁß∞(B), ‰∫ßÂìÅÁºñÁ†Å(C), ‰∫ßÂìÅÂêçÁß∞(D), Â∫ìÂ≠òÊï∞Èáè(E), ÁÆ±Êï∞(F), ÁúÅÂå∫(G), ÂÆ¢Êà∑ÁÆÄÁß∞(H), Â§ßÁ±ª(I), Â∞èÁ±ª(J), ÈáçÈáè(K), ËßÑÊ†º(L)
            # We map by index to be safe if names vary slightly, or by expected names.
            # Let's use expected names map based on index to standardize.
            # UPDATE: Use 'ÂÆ¢Êà∑ÁÆÄÁß∞' (HÂàó, index 7) as the primary 'ÁªèÈîÄÂïÜÂêçÁß∞' for analysis.
            # Rename original 'ÁªèÈîÄÂïÜÂêçÁß∞' (BÂàó, index 1) to 'ÁªèÈîÄÂïÜÂÖ®Áß∞' for reference.
            stock_cols_map = {
                0: 'ÁªèÈîÄÂïÜÁºñÁ†Å', 1: 'ÁªèÈîÄÂïÜÂÖ®Áß∞', 2: '‰∫ßÂìÅÁºñÁ†Å', 3: '‰∫ßÂìÅÂêçÁß∞', 
                4: 'Â∫ìÂ≠òÊï∞Èáè(Âê¨/Áõí)', 5: 'ÁÆ±Êï∞', 6: 'ÁúÅÂå∫ÂêçÁß∞', 7: 'ÁªèÈîÄÂïÜÂêçÁß∞', # Map 'ÂÆ¢Êà∑ÁÆÄÁß∞' to 'ÁªèÈîÄÂïÜÂêçÁß∞'
                8: '‰∫ßÂìÅÂ§ßÁ±ª', 9: '‰∫ßÂìÅÂ∞èÁ±ª', 10: 'ÈáçÈáè', 11: 'ËßÑÊ†º'
            }
            
            if len(df_stock.columns) >= 12:
                # Rename columns by index to ensure standard access
                new_cols = list(df_stock.columns)
                for idx, name in stock_cols_map.items():
                    new_cols[idx] = name
                df_stock.columns = new_cols
                
                # Ensure numeric 'ÁÆ±Êï∞'
                df_stock['ÁÆ±Êï∞'] = pd.to_numeric(df_stock['ÁÆ±Êï∞'], errors='coerce').fillna(0)
                
                # Clean Distributor Name (ÂÆ¢Êà∑ÁÆÄÁß∞)
                df_stock['ÁªèÈîÄÂïÜÂêçÁß∞'] = df_stock['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.strip()
                
                # Fix PyArrow mixed type error for mixed columns
                df_stock['ÈáçÈáè'] = df_stock['ÈáçÈáè'].astype(str)
                df_stock['ËßÑÊ†º'] = df_stock['ËßÑÊ†º'].astype(str)
                
                # --- Smart Classification Logic (Specific Category) ---
                # Rules:
                # - ÈõÖÁ≥ªÂàóÔºö‰ªÖÂΩì‰∫ßÂìÅÂêçÁß∞ÂåÖÂê´„ÄåÈõÖËµã/ÈõÖËÄÄ/ÈõÖËàí/ÈõÖÊä§„Äç‰πã‰∏ÄÊó∂ÂëΩ‰∏≠
                # - ÂàÜÊÆµÔºö‰ªÖÂú®„Äå‰∫ßÂìÅÂ§ßÁ±ª=ÁæéÊÄùÈõÖÊÆµÁ≤â„ÄçËåÉÂõ¥ÂÜÖÔºå‰∏î‰∫ßÂìÅÂêçÁß∞ÂåÖÂê´„Äå1ÊÆµ/2ÊÆµ/3ÊÆµ„Äç‰πã‰∏ÄÊó∂ÂëΩ‰∏≠
                
                # Optimized: Vectorized Logic using np.select and str.contains
                # Pre-calculate boolean masks
                name_series = df_stock['‰∫ßÂìÅÂêçÁß∞'].astype(str)
                cat_series = df_stock['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str)
                
                mask_ya = name_series.str.contains('ÈõÖËµã|ÈõÖËÄÄ|ÈõÖËàí|ÈõÖÊä§', regex=True)
                mask_seg_cat = cat_series == 'ÁæéÊÄùÈõÖÊÆµÁ≤â'
                
                # For segments, we need to extract which segment it is. 
                # Since we need the specific string ('1ÊÆµ' etc), np.select is good but we need to know WHICH one.
                # Let's use extraction for segments.
                seg_extract = name_series.str.extract(r'(1ÊÆµ|2ÊÆµ|3ÊÆµ)')[0]
                
                # Logic:
                # 1. If 'ÈõÖÁ≥ªÂàó' keyword -> return keyword. (Need to extract which one? Old logic returned the keyword itself e.g. 'ÈõÖËµã')
                # 2. If 'ÁæéÊÄùÈõÖÊÆµÁ≤â' and has segment -> return segment.
                # 3. Else 'ÂÖ∂‰ªñ'
                
                # Extract Ya keyword
                ya_extract = name_series.str.extract(r'(ÈõÖËµã|ÈõÖËÄÄ|ÈõÖËàí|ÈõÖÊä§)')[0]
                
                # Construct final series
                # Priority: Ya > Segment (if logic follows original sequence, Ya was checked first)
                
                df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'] = np.where(
                    mask_ya, ya_extract,
                    np.where(
                        mask_seg_cat & seg_extract.notna(), seg_extract,
                        'ÂÖ∂‰ªñ'
                    )
                )
                df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'] = df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'].fillna('ÂÖ∂‰ªñ').astype(str)
                 
                # --- Filter Stock Data (Hardcoded Rules) ---
                # Rule 1: Weight (ÈáçÈáè) must be '700', '800', '800-Êñ∞ÂåÖË£Ö'
                if 'ÈáçÈáè' in df_stock.columns:
                    valid_weights = ['700', '800', '800-Êñ∞ÂåÖË£Ö']
                    # Ensure weight column is string for comparison (already done above)
                    # Handle potential float/int like 700.0 or 700
                    # We converted to string, so 700 might become '700' or '700.0' depending on source.
                    # Let's normalize: check if string contains the valid weight or exact match.
                    # Exact match is safer if data is clean. Let's try exact match first, assuming '700' in Excel is '700' or 700.
                    # If it was 700 (int), astype(str) makes it '700'.
                    df_stock = df_stock[df_stock['ÈáçÈáè'].isin(valid_weights)]
            else:
                st.warning("Â∫ìÂ≠òË°® (Sheet2) ÂàóÊï∞‰∏çË∂≥ 12 ÂàóÔºåÊó†Ê≥ïËøõË°åÂ∫ìÂ≠òÂàÜÊûê„ÄÇ")
                df_stock = None

        # --- Process Sheet 3 (Outbound Base Table) ---
        if df_q4_raw is not None:
            df_q4_raw.columns = [str(c).strip() for c in df_q4_raw.columns]

            df_out = df_q4_raw.copy()

            month_src = df_out.columns[5] if len(df_out.columns) > 5 else None
            prov_src = df_out.columns[8] if len(df_out.columns) > 8 else None
            dist_src = df_out.columns[9] if len(df_out.columns) > 9 else None
            qty_src = df_out.columns[10] if len(df_out.columns) > 10 else None

            rename_map = {}
            if month_src: rename_map[month_src] = 'Êúà‰ªΩ'
            if prov_src: rename_map[prov_src] = 'ÁúÅÂå∫'
            if dist_src: rename_map[dist_src] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
            if qty_src: rename_map[qty_src] = 'Êï∞Èáè(ÁÆ±)'

            cat_src = next((c for c in df_out.columns if '‰∫ßÂìÅÂ§ßÁ±ª' in str(c)), None)
            if cat_src is None:
                cat_src = next((c for c in df_out.columns if ('Â§ßÁ±ª' in str(c)) and ('ÁúÅÂå∫' not in str(c))), None)
            sub_src = next((c for c in df_out.columns if '‰∫ßÂìÅÂ∞èÁ±ª' in str(c)), None)
            if sub_src is None:
                sub_src = next((c for c in df_out.columns if ('Â∞èÁ±ª' in str(c)) and ('‰∫ßÂìÅ' in str(c))), None)
            if cat_src is None and len(df_out.columns) > 11:
                cat_src = df_out.columns[11]
            if sub_src is None and len(df_out.columns) > 12:
                sub_src = df_out.columns[12]

            if cat_src: rename_map[cat_src] = '‰∫ßÂìÅÂ§ßÁ±ª'
            if sub_src: rename_map[sub_src] = '‰∫ßÂìÅÂ∞èÁ±ª'

            df_out = df_out.rename(columns=rename_map)
            df_out = df_out.loc[:, ~df_out.columns.duplicated()]

            if 'ÁªèÈîÄÂïÜÂêçÁß∞' in df_out.columns:
                df_out['ÁªèÈîÄÂïÜÂêçÁß∞'] = df_out['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.strip()
            if 'Êï∞Èáè(ÁÆ±)' in df_out.columns:
                df_out['Êï∞Èáè(ÁÆ±)'] = pd.to_numeric(df_out['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0)
            if '‰∫ßÂìÅÂ§ßÁ±ª' in df_out.columns:
                df_out['‰∫ßÂìÅÂ§ßÁ±ª'] = df_out['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str).str.strip()
            if '‰∫ßÂìÅÂ∞èÁ±ª' in df_out.columns:
                df_out['‰∫ßÂìÅÂ∞èÁ±ª'] = df_out['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str).str.strip()

            df_q4_raw = df_out

        # --- Process Sheet 4 (Performance / Shipment) ---
        if df_perf_raw is not None:
            df_perf_raw.columns = [str(c).strip() for c in df_perf_raw.columns]
            df_perf = df_perf_raw.copy()

            col_year = next((c for c in df_perf.columns if c == 'Âπ¥‰ªΩ' or 'Âπ¥' in c), None)
            col_month = next((c for c in df_perf.columns if c == 'Êúà‰ªΩ' or 'Êúà' in c), None)
            col_prov = next((c for c in df_perf.columns if c == 'ÁúÅÂå∫' or 'ÁúÅÂå∫' in c), None)
            col_dist = next((c for c in df_perf.columns if c == 'ÁªèÈîÄÂïÜÂêçÁß∞' or c == 'ÂÆ¢Êà∑ÁÆÄÁß∞' or 'ÂÆ¢Êà∑ÁÆÄÁß∞' in c), None)
            col_qty = next((c for c in df_perf.columns if c == 'ÁÆ±Êï∞' or c == 'Âü∫Êú¨Êï∞Èáè' or 'Êï∞Èáè' in c), None)
            col_amt = next((c for c in df_perf.columns if c == 'ÂèëË¥ßÈáëÈ¢ù' or c == 'Âéü‰ª∑ÈáëÈ¢ù' or 'ÈáëÈ¢ù' in c), None)
            col_wh = next((c for c in df_perf.columns if c == 'ÂèëË¥ß‰ªì' or 'ÂèëË¥ß‰ªì' in c), None)
            col_mid = next((c for c in df_perf.columns if c == '‰∏≠Á±ª' or '‰∏≠Á±ª' in c), None)
            col_grp = next((c for c in df_perf.columns if c == 'ÂΩíÁ±ª' or 'ÂΩíÁ±ª' in c), None)
            col_bigcat = next((c for c in df_perf.columns if c == 'Â§ßÂàÜÁ±ª' or 'Â§ßÂàÜÁ±ª' in c), None)
            col_big = next((c for c in df_perf.columns if c == 'Â§ßÁ±ª' or 'Â§ßÁ±ª' in c), None)
            col_small = next((c for c in df_perf.columns if c == 'Â∞èÁ±ª' or 'Â∞èÁ±ª' in c), None)
            col_cat = next((c for c in df_perf.columns if c == 'ÊúàÂàÜÊûê' or 'ÊúàÂàÜÊûê' in c), None)

            rename_perf = {}
            if col_year: rename_perf[col_year] = 'Âπ¥‰ªΩ'
            if col_month: rename_perf[col_month] = 'Êúà‰ªΩ'
            if col_prov: rename_perf[col_prov] = 'ÁúÅÂå∫'
            if col_dist: rename_perf[col_dist] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
            if col_qty: rename_perf[col_qty] = 'ÂèëË¥ßÁÆ±Êï∞'
            if col_amt: rename_perf[col_amt] = 'ÂèëË¥ßÈáëÈ¢ù'
            if col_wh: rename_perf[col_wh] = 'ÂèëË¥ß‰ªì'
            if col_mid: rename_perf[col_mid] = '‰∏≠Á±ª'
            if col_grp: rename_perf[col_grp] = 'ÂΩíÁ±ª'
            if col_bigcat:
                rename_perf[col_bigcat] = 'Â§ßÂàÜÁ±ª'
            elif col_cat:
                rename_perf[col_cat] = 'Â§ßÂàÜÁ±ª'
            if col_big: rename_perf[col_big] = 'Â§ßÁ±ª'
            if col_small: rename_perf[col_small] = 'Â∞èÁ±ª'

            df_perf = df_perf.rename(columns=rename_perf)

            for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'ÂèëË¥ß‰ªì', '‰∏≠Á±ª', 'ÂΩíÁ±ª', 'Â§ßÂàÜÁ±ª', 'Â§ßÁ±ª', 'Â∞èÁ±ª']:
                if c in df_perf.columns:
                    df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()
            
            # --- FIX: Ensure 'ÁªèÈîÄÂïÜÂêçÁß∞' exists ---
            if 'ÁªèÈîÄÂïÜÂêçÁß∞' not in df_perf.columns:
                # Try to find alias
                alt_dist = next((c for c in df_perf.columns if 'ÂÆ¢Êà∑' in c or 'ÁªèÈîÄ' in c), None)
                if alt_dist:
                    df_perf = df_perf.rename(columns={alt_dist: 'ÁªèÈîÄÂïÜÂêçÁß∞'})
                else:
                    # Fallback: Create empty if absolutely necessary (but better to warn)
                    df_perf['ÁªèÈîÄÂïÜÂêçÁß∞'] = 'Êú™Áü•ÁªèÈîÄÂïÜ'
            # --------------------------------------

            if 'Â§ßÂàÜÁ±ª' in df_perf.columns and 'Á±ªÁõÆ' not in df_perf.columns:
                df_perf['Á±ªÁõÆ'] = df_perf['Â§ßÂàÜÁ±ª']

            if 'Âπ¥‰ªΩ' in df_perf.columns:
                # Handle "25Âπ¥" or "2025" strings by extracting digits
                # NOTE: Use regex extraction to handle "25Âπ¥" -> "25"
                df_perf['Âπ¥‰ªΩ'] = df_perf['Âπ¥‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                # Normalize 2-digit years to 4-digit (e.g. 25 -> 2025)
                df_perf['Âπ¥‰ªΩ'] = df_perf['Âπ¥‰ªΩ'].apply(lambda y: y + 2000 if 0 < y < 100 else y)

            if 'Êúà‰ªΩ' in df_perf.columns:
                 # Handle "1Êúà" or "01" strings
                df_perf['Êúà‰ªΩ'] = df_perf['Êúà‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if 'ÂèëË¥ßÁÆ±Êï∞' in df_perf.columns:
                df_perf['ÂèëË¥ßÁÆ±Êï∞'] = pd.to_numeric(df_perf['ÂèëË¥ßÁÆ±Êï∞'], errors='coerce').fillna(0)
            if 'ÂèëË¥ßÈáëÈ¢ù' in df_perf.columns:
                df_perf['ÂèëË¥ßÈáëÈ¢ù'] = pd.to_numeric(df_perf['ÂèëË¥ßÈáëÈ¢ù'], errors='coerce').fillna(0)

            if 'Âπ¥‰ªΩ' in df_perf.columns and 'Êúà‰ªΩ' in df_perf.columns:
                df_perf = df_perf[(df_perf['Âπ¥‰ªΩ'] > 0) & (df_perf['Êúà‰ªΩ'].between(1, 12))]
                df_perf['Âπ¥Êúà'] = pd.to_datetime(df_perf['Âπ¥‰ªΩ'].astype(str) + '-' + df_perf['Êúà‰ªΩ'].astype(str).str.zfill(2) + '-01')
            else:
                df_perf['Âπ¥Êúà'] = pd.NaT

            df_perf_raw = df_perf

        # --- Process Sheet 5 (Target) ---
        df_target_raw = None
        try:
            if len(xl.sheet_names) > 4:
                df_target_raw = xl.parse(4)
                df_target_raw.columns = [str(c).strip() for c in df_target_raw.columns]
                
                # Expected Cols: D(ÂìÅÁ±ª), E(Êúà‰ªΩ), F(‰ªªÂä°Èáè) -> Index 3, 4, 5
                # Rename by index to be safe
                rename_target = {}
                if len(df_target_raw.columns) > 3: rename_target[df_target_raw.columns[3]] = 'ÂìÅÁ±ª'
                if len(df_target_raw.columns) > 4: rename_target[df_target_raw.columns[4]] = 'Êúà‰ªΩ'
                if len(df_target_raw.columns) > 5: rename_target[df_target_raw.columns[5]] = '‰ªªÂä°Èáè'
                
                df_target_raw = df_target_raw.rename(columns=rename_target)
                
                # Basic Cleaning
                if 'Êúà‰ªΩ' in df_target_raw.columns:
                     # Handle "1Êúà" or "01" strings
                    df_target_raw['Êúà‰ªΩ'] = df_target_raw['Êúà‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                if '‰ªªÂä°Èáè' in df_target_raw.columns:
                    df_target_raw['‰ªªÂä°Èáè'] = pd.to_numeric(df_target_raw['‰ªªÂä°Èáè'], errors='coerce').fillna(0)
            else:
                 debug_logs.append("Warning: Sheet5 (Target) not found.")
        except Exception as e:
            debug_logs.append(f"Error parsing Sheet5: {e}")
            df_target_raw = None

        return df, month_cols, df_stock, df_q4_raw, df_perf_raw, df_target_raw, debug_logs
        
    except Exception as e:
        st.error(f"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•: {str(e)}")
        return None, None, None, None, None, None, [str(e)]

@st.cache_data(ttl=3600)
def load_data_v3(file_bytes: bytes, file_name: str):
    debug_logs = []
    try:
        file_name_lower = (file_name or "").lower()
        bio = io.BytesIO(file_bytes)
        
        # Init Returns
        df = None
        month_cols = []
        df_stock = None
        df_q4_raw = None
        df_perf_raw = None
        df_target_raw = None
        df_scan_raw = None

        if file_name_lower.endswith('.csv'):
            df = pd.read_csv(bio, encoding='gb18030')
        else:
            xl = pd.ExcelFile(bio)
            debug_logs.append(f"Sheet Names: {xl.sheet_names}")
            
            # Sheet 1: Sales
            if len(xl.sheet_names) > 0: df = xl.parse(0)
            
            # Sheet 2: Stock
            if len(xl.sheet_names) > 1: df_stock = xl.parse(1)
            
            # Sheet 3: Outbound (Q4)
            if len(xl.sheet_names) > 2: df_q4_raw = xl.parse(2)
            
            # Sheet 4: Performance
            if len(xl.sheet_names) > 3:
                preferred = next((s for s in xl.sheet_names if 'sheet4' in str(s).strip().lower()), None)
                candidate_names = [preferred] if preferred else []
                candidate_names += [s for s in xl.sheet_names if s not in candidate_names]
                for sname in candidate_names:
                    try:
                        tmp_header = xl.parse(sname, nrows=0)
                        cols = [str(c).strip() for c in tmp_header.columns]
                        key_hits = sum(1 for k in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ', 'ÁúÅÂå∫'] if any(k in c for c in cols))
                        signal_hits = sum(1 for k in ['ÂèëË¥ß‰ªì', 'Âéü‰ª∑ÈáëÈ¢ù', 'Âü∫Êú¨Êï∞Èáè', 'Â§ßÂàÜÁ±ª', 'ÊúàÂàÜÊûê', 'ÂÆ¢Êà∑ÁÆÄÁß∞'] if any(k in c for c in cols))
                        if key_hits >= 2 and signal_hits >= 1:
                            df_perf_raw = xl.parse(sname)
                            debug_logs.append(f"-> MATCHED Sheet4: {sname}")
                            break
                    except: continue
            
            # Sheet 5: Target
            if len(xl.sheet_names) > 4: df_target_raw = xl.parse(4)

            # Sheet 6: Scan Data
            if len(xl.sheet_names) > 5: df_scan_raw = xl.parse(5)

        # --- Process Sheet 1 (Sales) ---
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            
            # Identify Month Columns
            is_long_format = False
            time_col = None
            if len(df.columns) > 5:
                col_f = df.columns[5]
                sample_vals = df[col_f].dropna().head(10).astype(str).tolist()
                if any('Êúà' in v for v in sample_vals):
                    is_long_format = True
                    time_col = col_f
            
            if is_long_format:
                col_prov = df.columns[8] if len(df.columns) > 8 else None
                col_dist = df.columns[9] if len(df.columns) > 9 else None
                col_qty = df.columns[10] if len(df.columns) > 10 else None
                
                if col_prov is None: col_prov = next((c for c in df.columns if 'ÁúÅ' in c), None)
                if col_dist is None: col_dist = next((c for c in df.columns if 'ÁªèÈîÄ' in c or 'ÂÆ¢Êà∑' in c), None)
                if col_qty is None: col_qty = next((c for c in df.columns if 'Êï∞' in c or 'Qty' in c or 'ÁÆ±' in c), None)
                col_store = next((c for c in df.columns if 'Èó®Â∫ó' in c), None)
                
                if col_prov and col_dist and col_qty and time_col:
                    df[col_qty] = pd.to_numeric(df[col_qty], errors='coerce').fillna(0)
                    pivot_index = [col_prov, col_dist]
                    if col_store: pivot_index.append(col_store)
                    df_wide = df.pivot_table(index=pivot_index, columns=time_col, values=col_qty, aggfunc='sum').reset_index()
                    if not col_store: df_wide['Èó®Â∫óÂêçÁß∞'] = df_wide[col_dist]
                    df = df_wide
                    df.columns = [str(c).strip() for c in df.columns]
            
            rename_map = {}
            if 'ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞' in df.columns: rename_map['ÂìÅÁâåÁúÅÂå∫ÂêçÁß∞'] = 'ÁúÅÂå∫'
            if 'ÁªèÈîÄÂïÜÂêçÁß∞' not in df.columns and len(df.columns) > 1: rename_map[df.columns[1]] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
            if 'Èó®Â∫óÂêçÁß∞' not in df.columns and len(df.columns) > 2: rename_map[df.columns[2]] = 'Èó®Â∫óÂêçÁß∞'
            df = df.rename(columns=rename_map)
            
            required = ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'Èó®Â∫óÂêçÁß∞']
            for req in required:
                if req not in df.columns:
                    if len(df.columns) >= 3:
                        df.columns.values[0] = 'ÁúÅÂå∫'
                        df.columns.values[1] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
                        df.columns.values[2] = 'Èó®Â∫óÂêçÁß∞'
            
            month_cols = [c for c in df.columns if 'Êúà' in c and c not in required]
            for col in month_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
            df['ÊÄªÂá∫Â∫ìÊï∞'] = df[month_cols].sum(axis=1)
            df['ÊúâÊïàÊúà‰ªΩÊï∞'] = df[month_cols].gt(0).sum(axis=1).astype(int)
            df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] = np.where(df['ÊúâÊïàÊúà‰ªΩÊï∞'] > 0, df['ÊÄªÂá∫Â∫ìÊï∞'] / df['ÊúâÊïàÊúà‰ªΩÊï∞'], 0.0)
            
            conditions = [df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 4, (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 2) & (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] < 4), (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] >= 1) & (df['Âπ≥ÂùáÊØèÊúàÂá∫Â∫ìÊï∞'] < 2)]
            choices = ['AÁ±ªÈó®Â∫ó (>=4)', 'BÁ±ªÈó®Â∫ó (2-4)', 'CÁ±ªÈó®Â∫ó (1-2)']
            df['Èó®Â∫óÂàÜÁ±ª'] = np.select(conditions, choices, default='DÁ±ªÈó®Â∫ó (<1)')

        # --- Process Sheet 2 (Stock) ---
        if df_stock is not None:
            df_stock.columns = [str(c).strip() for c in df_stock.columns]
            stock_cols_map = {
                0: 'ÁªèÈîÄÂïÜÁºñÁ†Å', 1: 'ÁªèÈîÄÂïÜÂÖ®Áß∞', 2: '‰∫ßÂìÅÁºñÁ†Å', 3: '‰∫ßÂìÅÂêçÁß∞', 
                4: 'Â∫ìÂ≠òÊï∞Èáè(Âê¨/Áõí)', 5: 'ÁÆ±Êï∞', 6: 'ÁúÅÂå∫ÂêçÁß∞', 7: 'ÁªèÈîÄÂïÜÂêçÁß∞', # 7=ÂÆ¢Êà∑ÁÆÄÁß∞
                8: '‰∫ßÂìÅÂ§ßÁ±ª', 9: '‰∫ßÂìÅÂ∞èÁ±ª', 10: 'ÈáçÈáè', 11: 'ËßÑÊ†º'
            }
            if len(df_stock.columns) >= 12:
                new_cols = list(df_stock.columns)
                for idx, name in stock_cols_map.items():
                    if idx < len(new_cols): new_cols[idx] = name
                df_stock.columns = new_cols
                df_stock['ÁÆ±Êï∞'] = pd.to_numeric(df_stock['ÁÆ±Êï∞'], errors='coerce').fillna(0)
                
                # CLEAN DISTRIBUTOR NAME STRICTLY
                if 'ÁªèÈîÄÂïÜÂêçÁß∞' in df_stock.columns:
                    df_stock['ÁªèÈîÄÂïÜÂêçÁß∞'] = df_stock['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.replace(r'\s+', '', regex=True)
                
                df_stock['ÈáçÈáè'] = df_stock['ÈáçÈáè'].astype(str)
                df_stock['ËßÑÊ†º'] = df_stock['ËßÑÊ†º'].astype(str)
                
                name_series = df_stock['‰∫ßÂìÅÂêçÁß∞'].astype(str)
                mask_ya = name_series.str.contains('ÈõÖËµã|ÈõÖËÄÄ|ÈõÖËàí|ÈõÖÊä§', regex=True)
                mask_seg_cat = df_stock['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == 'ÁæéÊÄùÈõÖÊÆµÁ≤â'
                seg_extract = name_series.str.extract(r'(1ÊÆµ|2ÊÆµ|3ÊÆµ)')[0]
                ya_extract = name_series.str.extract(r'(ÈõÖËµã|ÈõÖËÄÄ|ÈõÖËàí|ÈõÖÊä§)')[0]
                
                df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'] = np.where(mask_ya, ya_extract, np.where(mask_seg_cat & seg_extract.notna(), seg_extract, 'ÂÖ∂‰ªñ'))
                df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'] = df_stock['ÂÖ∑‰ΩìÂàÜÁ±ª'].fillna('ÂÖ∂‰ªñ').astype(str)
                 
                if 'ÈáçÈáè' in df_stock.columns:
                    valid_weights = ['700', '800', '800-Êñ∞ÂåÖË£Ö']
                    df_stock = df_stock[df_stock['ÈáçÈáè'].isin(valid_weights)]
            else:
                df_stock = None

        # --- Process Sheet 3 (Outbound) FIX ---
        if df_q4_raw is not None:
            # Deduplicate
            cols = pd.Series(df_q4_raw.columns)
            for dup in cols[cols.duplicated()].unique(): 
                cols[cols[cols == dup].index.values.tolist()] = [dup + '.' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]
            df_q4_raw.columns = cols
            
            df_out = df_q4_raw.copy()
            
            # Map Indices (User Requirement: +8 shift)
            # M(12)=Year, N(13)=Month, Q(16)=Prov, R(17)=Dist(CustomerAbbr), S(18)=Qty, U(20)=SubCat
            idx_map = {
                12: 'Âπ¥‰ªΩ',
                13: 'Êúà‰ªΩ',
                16: 'ÁúÅÂå∫',
                17: 'ÁªèÈîÄÂïÜÂêçÁß∞',
                18: 'Êï∞Èáè(ÁÆ±)',
                20: '‰∫ßÂìÅÂ∞èÁ±ª',
                19: '‰∫ßÂìÅÂ§ßÁ±ª'
            }
            curr_cols = list(df_out.columns)
            
            # Avoid Name Collision: Rename existing columns that clash with target names
            target_names = list(idx_map.values())
            for i, c in enumerate(curr_cols):
                if c in target_names and i not in idx_map:
                    new_n = f"{c}_old_{i}"
                    df_out.rename(columns={c: new_n}, inplace=True)
                    debug_logs.append(f"Renamed collision '{c}' -> '{new_n}'")
            
            # Refresh columns after collision avoidance
            curr_cols = list(df_out.columns)
            
            for idx, name in idx_map.items():
                if idx < len(curr_cols):
                    df_out.rename(columns={curr_cols[idx]: name}, inplace=True)
            
            # Clean Dist Name
            if 'ÁªèÈîÄÂïÜÂêçÁß∞' in df_out.columns:
                 df_out['ÁªèÈîÄÂïÜÂêçÁß∞'] = df_out['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.replace(r'\s+', '', regex=True)
                 debug_logs.append(f"Sheet3 Dist Sample: {df_out['ÁªèÈîÄÂïÜÂêçÁß∞'].head(3).tolist()}")

            if 'Êï∞Èáè(ÁÆ±)' in df_out.columns:
                df_out['Êï∞Èáè(ÁÆ±)'] = pd.to_numeric(df_out['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0)
            
            if '‰∫ßÂìÅÂ§ßÁ±ª' in df_out.columns: df_out['‰∫ßÂìÅÂ§ßÁ±ª'] = df_out['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str).str.strip()
            if '‰∫ßÂìÅÂ∞èÁ±ª' in df_out.columns: df_out['‰∫ßÂìÅÂ∞èÁ±ª'] = df_out['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str).str.strip()
            
            # Clean Year
            if 'Âπ¥‰ªΩ' in df_out.columns:
                # Extract digits and normalize
                df_out['Âπ¥‰ªΩ'] = df_out['Âπ¥‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                # Normalize 25 -> 2025
                df_out['Âπ¥‰ªΩ'] = df_out['Âπ¥‰ªΩ'].apply(lambda y: y + 2000 if 20 <= y < 100 else y)

            df_q4_raw = df_out

        # --- Process Sheet 4 (Perf) ---
        if df_perf_raw is not None:
            df_perf_raw.columns = [str(c).strip() for c in df_perf_raw.columns]
            df_perf = df_perf_raw.copy()
            col_year = next((c for c in df_perf.columns if str(c).strip() == 'Âπ¥‰ªΩ' or ('Âπ¥' in str(c))), None)
            col_month = next((c for c in df_perf.columns if str(c).strip() == 'Êúà‰ªΩ' or ('Êúà' in str(c))), None)
            col_prov = next((c for c in df_perf.columns if str(c).strip() == 'ÁúÅÂå∫' or ('ÁúÅÂå∫' in str(c)) or (str(c).strip() == 'ÁúÅ')), None)
            col_dist = next((c for c in df_perf.columns if str(c).strip() == 'ÁªèÈîÄÂïÜÂêçÁß∞' or str(c).strip() == 'ÂÆ¢Êà∑ÁÆÄÁß∞' or ('ÂÆ¢Êà∑ÁÆÄÁß∞' in str(c)) or ('ÁªèÈîÄÂïÜ' in str(c))), None)
            col_qty = next((c for c in df_perf.columns if str(c).strip() == 'ÂèëË¥ßÁÆ±Êï∞' or str(c).strip() == 'ÁÆ±Êï∞' or str(c).strip() == 'Âü∫Êú¨Êï∞Èáè' or ('Êï∞Èáè' in str(c)) or ('ÁÆ±' in str(c))), None)
            col_amt = next((c for c in df_perf.columns if str(c).strip() == 'ÂèëË¥ßÈáëÈ¢ù' or str(c).strip() == 'Âéü‰ª∑ÈáëÈ¢ù' or ('ÈáëÈ¢ù' in str(c))), None)
            col_wh = next((c for c in df_perf.columns if str(c).strip() == 'ÂèëË¥ß‰ªì' or ('ÂèëË¥ß‰ªì' in str(c))), None)
            col_mid = next((c for c in df_perf.columns if str(c).strip() == '‰∏≠Á±ª' or ('‰∏≠Á±ª' in str(c))), None)
            col_grp = next((c for c in df_perf.columns if str(c).strip() == 'ÂΩíÁ±ª' or ('ÂΩíÁ±ª' in str(c))), None)
            col_bigcat = next((c for c in df_perf.columns if str(c).strip() == 'Â§ßÂàÜÁ±ª' or ('Â§ßÂàÜÁ±ª' in str(c))), None)
            col_big = next((c for c in df_perf.columns if str(c).strip() == 'Â§ßÁ±ª' or ('Â§ßÁ±ª' in str(c))), None)
            col_small = next((c for c in df_perf.columns if str(c).strip() == 'Â∞èÁ±ª' or ('Â∞èÁ±ª' in str(c))), None)
            col_cat = next((c for c in df_perf.columns if str(c).strip() == 'ÊúàÂàÜÊûê' or ('ÊúàÂàÜÊûê' in str(c))), None)

            rename_perf = {}
            if col_year: rename_perf[col_year] = 'Âπ¥‰ªΩ'
            if col_month: rename_perf[col_month] = 'Êúà‰ªΩ'
            if col_prov: rename_perf[col_prov] = 'ÁúÅÂå∫'
            if col_dist: rename_perf[col_dist] = 'ÁªèÈîÄÂïÜÂêçÁß∞'
            if col_qty: rename_perf[col_qty] = 'ÂèëË¥ßÁÆ±Êï∞'
            if col_amt: rename_perf[col_amt] = 'ÂèëË¥ßÈáëÈ¢ù'
            if col_wh: rename_perf[col_wh] = 'ÂèëË¥ß‰ªì'
            if col_mid: rename_perf[col_mid] = '‰∏≠Á±ª'
            if col_grp: rename_perf[col_grp] = 'ÂΩíÁ±ª'
            if col_bigcat:
                rename_perf[col_bigcat] = 'Â§ßÂàÜÁ±ª'
            elif col_cat:
                rename_perf[col_cat] = 'Â§ßÂàÜÁ±ª'
            if col_big: rename_perf[col_big] = 'Â§ßÁ±ª'
            if col_small: rename_perf[col_small] = 'Â∞èÁ±ª'

            df_perf = df_perf.rename(columns=rename_perf)

            if 'ÁªèÈîÄÂïÜÂêçÁß∞' not in df_perf.columns:
                alt_dist = next((c for c in df_perf.columns if ('ÂÆ¢Êà∑' in str(c)) or ('ÁªèÈîÄ' in str(c))), None)
                if alt_dist:
                    df_perf = df_perf.rename(columns={alt_dist: 'ÁªèÈîÄÂïÜÂêçÁß∞'})
                else:
                    df_perf['ÁªèÈîÄÂïÜÂêçÁß∞'] = ''
                    debug_logs.append("Warning: Sheet4 missing distributor column; set 'ÁªèÈîÄÂïÜÂêçÁß∞' to empty.")

            for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'ÂèëË¥ß‰ªì', '‰∏≠Á±ª', 'ÂΩíÁ±ª', 'Â§ßÂàÜÁ±ª', 'Â§ßÁ±ª', 'Â∞èÁ±ª']:
                if c in df_perf.columns:
                    df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()

            if 'Âπ¥‰ªΩ' in df_perf.columns:
                df_perf['Âπ¥‰ªΩ'] = df_perf['Âπ¥‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
                df_perf['Âπ¥‰ªΩ'] = df_perf['Âπ¥‰ªΩ'].apply(lambda y: y + 2000 if 0 < y < 100 else y)
            if 'Êúà‰ªΩ' in df_perf.columns:
                df_perf['Êúà‰ªΩ'] = df_perf['Êúà‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if 'ÂèëË¥ßÁÆ±Êï∞' in df_perf.columns:
                df_perf['ÂèëË¥ßÁÆ±Êï∞'] = pd.to_numeric(df_perf['ÂèëË¥ßÁÆ±Êï∞'], errors='coerce').fillna(0)
            if 'ÂèëË¥ßÈáëÈ¢ù' in df_perf.columns:
                df_perf['ÂèëË¥ßÈáëÈ¢ù'] = pd.to_numeric(df_perf['ÂèëË¥ßÈáëÈ¢ù'], errors='coerce').fillna(0)

            if 'Âπ¥‰ªΩ' in df_perf.columns and 'Êúà‰ªΩ' in df_perf.columns:
                df_perf = df_perf[(df_perf['Âπ¥‰ªΩ'] > 0) & (df_perf['Êúà‰ªΩ'].between(1, 12))]
                df_perf['Âπ¥Êúà'] = pd.to_datetime(
                    df_perf['Âπ¥‰ªΩ'].astype(str) + '-' + df_perf['Êúà‰ªΩ'].astype(str).str.zfill(2) + '-01',
                    errors='coerce'
                )
            else:
                df_perf['Âπ¥Êúà'] = pd.NaT
            df_perf_raw = df_perf

        # --- Process Sheet 5 (Target) ---
        if df_target_raw is not None:
            df_target_raw.columns = [str(c).strip() for c in df_target_raw.columns]
            rename_target = {}
            if len(df_target_raw.columns) > 3: rename_target[df_target_raw.columns[3]] = 'ÂìÅÁ±ª'
            if len(df_target_raw.columns) > 4: rename_target[df_target_raw.columns[4]] = 'Êúà‰ªΩ'
            if len(df_target_raw.columns) > 5: rename_target[df_target_raw.columns[5]] = '‰ªªÂä°Èáè'
            df_target_raw = df_target_raw.rename(columns=rename_target)
            if 'Êúà‰ªΩ' in df_target_raw.columns:
                df_target_raw['Êúà‰ªΩ'] = df_target_raw['Êúà‰ªΩ'].astype(str).str.extract(r'(\d+)')[0].astype(float).fillna(0).astype(int)
            if '‰ªªÂä°Èáè' in df_target_raw.columns:
                df_target_raw['‰ªªÂä°Èáè'] = pd.to_numeric(df_target_raw['‰ªªÂä°Èáè'], errors='coerce').fillna(0)

        # --- Process Sheet 6 (Scan Data) ---
        if df_scan_raw is not None:
            df0 = df_scan_raw

            def _col(idx: int):
                if idx < df0.shape[1]:
                    return df0.iloc[:, idx]
                return pd.Series([None] * len(df0))

            df_scan_raw = pd.DataFrame({
                "Èó®Â∫óÂêçÁß∞": _col(1),
                "ÁªèÈîÄÂïÜÂêçÁß∞": _col(18),
                "ÁúÅÂå∫": _col(17),
                "‰∫ßÂìÅÂ§ßÁ±ª": _col(19),
                "‰∫ßÂìÅÂ∞èÁ±ª": _col(20),
                "ÁªèÁ∫¨Â∫¶": _col(12),
                "Âπ¥‰ªΩ": _col(13),
                "Êúà‰ªΩ": _col(14),
                "Êó•": _col(15),
            })

            df_scan_raw["Âπ¥‰ªΩ"] = df_scan_raw["Âπ¥‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
            df_scan_raw["Âπ¥‰ªΩ"] = df_scan_raw["Âπ¥‰ªΩ"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
            df_scan_raw["Êúà‰ªΩ"] = df_scan_raw["Êúà‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
            df_scan_raw["Êó•"] = df_scan_raw["Êó•"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)

            for c in ["Èó®Â∫óÂêçÁß∞", "ÁúÅÂå∫", "ÁªèÈîÄÂïÜÂêçÁß∞", "‰∫ßÂìÅÂ§ßÁ±ª", "‰∫ßÂìÅÂ∞èÁ±ª"]:
                df_scan_raw[c] = df_scan_raw[c].fillna("").astype(str).str.strip()

            coords = df_scan_raw["ÁªèÁ∫¨Â∫¶"].apply(_parse_lon_lat)
            df_scan_raw["ÁªèÂ∫¶"] = coords.apply(lambda x: x[0])
            df_scan_raw["Á∫¨Â∫¶"] = coords.apply(lambda x: x[1])

        return df, month_cols, df_stock, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs
        
    except Exception as e:
        import traceback
        return None, None, None, None, None, None, None, [f"Error: {str(e)}", traceback.format_exc()]

@st.cache_data(ttl=3600)
def load_builtin_perf_2025():
    base_dir = os.path.dirname(__file__) if "__file__" in globals() else os.getcwd()
    path = os.path.join(base_dir, "ÂàÜÊûêÂ∫ïË°®0115.xlsx")
    if not os.path.exists(path):
        return pd.DataFrame()
    xl = pd.ExcelFile(path)
    sheet_name = next((s for s in xl.sheet_names if "ÂèëË¥ß" in str(s)), None)
    if sheet_name is None and len(xl.sheet_names) > 3:
        sheet_name = xl.sheet_names[3]
    if sheet_name is None:
        return pd.DataFrame()
    df0 = xl.parse(sheet_name)
    df0.columns = [str(c).strip() for c in df0.columns]
    col_year = next((c for c in df0.columns if str(c).strip() == "Âπ¥‰ªΩ" or "Âπ¥" in str(c)), None)
    col_month = next((c for c in df0.columns if str(c).strip() == "Êúà‰ªΩ" or "Êúà" in str(c)), None)
    col_prov = next((c for c in df0.columns if "ÁúÅÂå∫" in str(c)), None)
    col_dist = next((c for c in df0.columns if "ÂÆ¢Êà∑ÁÆÄÁß∞" in str(c)), None) or next((c for c in df0.columns if "Ë¥≠Ë¥ßÂçï‰Ωç" in str(c)), None)
    col_qty = next((c for c in df0.columns if "Âü∫Êú¨Êï∞Èáè" in str(c)), None) or next((c for c in df0.columns if "ÁÆ±" in str(c) or "Êï∞Èáè" in str(c)), None)
    col_amt = next((c for c in df0.columns if "Âéü‰ª∑ÈáëÈ¢ù" in str(c)), None) or next((c for c in df0.columns if "ÈáëÈ¢ù" in str(c)), None)
    col_wh = next((c for c in df0.columns if "ÂèëË¥ß‰ªì" in str(c)), None)
    col_grp = next((c for c in df0.columns if "ÂΩíÁ±ª" in str(c)), None)
    col_bigcat = next((c for c in df0.columns if str(c).strip() == "Â§ßÂàÜÁ±ª"), None) or next((c for c in df0.columns if "ÊúàÂàÜÊûê" in str(c)), None)
    col_big = next((c for c in df0.columns if str(c).strip() == "Â§ßÁ±ª"), None)
    col_mid = next((c for c in df0.columns if str(c).strip() == "‰∏≠Á±ª"), None)
    col_small = next((c for c in df0.columns if str(c).strip() == "Â∞èÁ±ª"), None)

    df = pd.DataFrame()
    if col_year is not None: df["Âπ¥‰ªΩ"] = df0[col_year]
    if col_month is not None: df["Êúà‰ªΩ"] = df0[col_month]
    if col_prov is not None: df["ÁúÅÂå∫"] = df0[col_prov]
    if col_dist is not None: df["ÁªèÈîÄÂïÜÂêçÁß∞"] = df0[col_dist]
    if col_qty is not None: df["ÂèëË¥ßÁÆ±Êï∞"] = df0[col_qty]
    if col_amt is not None: df["ÂèëË¥ßÈáëÈ¢ù"] = df0[col_amt]
    if col_wh is not None: df["ÂèëË¥ß‰ªì"] = df0[col_wh]
    if col_mid is not None: df["‰∏≠Á±ª"] = df0[col_mid]
    if col_grp is not None: df["ÂΩíÁ±ª"] = df0[col_grp]
    if col_bigcat is not None: df["Â§ßÂàÜÁ±ª"] = df0[col_bigcat]
    if col_big is not None: df["Â§ßÁ±ª"] = df0[col_big]
    if col_small is not None: df["Â∞èÁ±ª"] = df0[col_small]

    for c in ["ÁúÅÂå∫", "ÁªèÈîÄÂïÜÂêçÁß∞", "ÂèëË¥ß‰ªì", "‰∏≠Á±ª", "ÂΩíÁ±ª", "Â§ßÂàÜÁ±ª", "Â§ßÁ±ª", "Â∞èÁ±ª"]:
        if c in df.columns:
            df[c] = df[c].fillna("").astype(str).str.strip()
    if "Âπ¥‰ªΩ" in df.columns:
        df["Âπ¥‰ªΩ"] = df["Âπ¥‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["Âπ¥‰ªΩ"] = df["Âπ¥‰ªΩ"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
    if "Êúà‰ªΩ" in df.columns:
        df["Êúà‰ªΩ"] = df["Êúà‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
    if "ÂèëË¥ßÁÆ±Êï∞" in df.columns:
        df["ÂèëË¥ßÁÆ±Êï∞"] = pd.to_numeric(df["ÂèëË¥ßÁÆ±Êï∞"], errors="coerce").fillna(0)
    if "ÂèëË¥ßÈáëÈ¢ù" in df.columns:
        df["ÂèëË¥ßÈáëÈ¢ù"] = pd.to_numeric(df["ÂèëË¥ßÈáëÈ¢ù"], errors="coerce").fillna(0)
    if "Âπ¥‰ªΩ" in df.columns and "Êúà‰ªΩ" in df.columns:
        df = df[(df["Âπ¥‰ªΩ"] == 2025) & (df["Êúà‰ªΩ"].between(1, 12))]
        df["Âπ¥Êúà"] = pd.to_datetime(df["Âπ¥‰ªΩ"].astype(str) + "-" + df["Êúà‰ªΩ"].astype(str).str.zfill(2) + "-01", errors="coerce")
    else:
        return pd.DataFrame()
    return df

@st.cache_data(ttl=3600)
def load_builtin_scan_2025():
    # Attempt to load built-in file if it exists, otherwise return empty
    base_dir = os.path.dirname(__file__) if "__file__" in globals() else os.getcwd()
    path = os.path.join(base_dir, "ÂàÜÊûêÂ∫ïË°®0115.xlsx")
    if not os.path.exists(path):
        return pd.DataFrame()
    
    try:
        xl = pd.ExcelFile(path)
        if len(xl.sheet_names) <= 5:
            return pd.DataFrame()

        df0 = xl.parse(5)
        if df0 is None or df0.empty:
            return pd.DataFrame()

        def _col(idx: int):
            if idx < df0.shape[1]:
                return df0.iloc[:, idx]
            return pd.Series([None] * len(df0))

        df = pd.DataFrame({
            "Èó®Â∫óÂêçÁß∞": _col(1),
            "ÁªèÈîÄÂïÜÂêçÁß∞": _col(18),
            "ÁúÅÂå∫": _col(17),
            "‰∫ßÂìÅÂ§ßÁ±ª": _col(19),
            "‰∫ßÂìÅÂ∞èÁ±ª": _col(20),
            "ÁªèÁ∫¨Â∫¶": _col(12),
            "Âπ¥‰ªΩ": _col(13),
            "Êúà‰ªΩ": _col(14),
            "Êó•": _col(15),
        })

        df["Âπ¥‰ªΩ"] = df["Âπ¥‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["Âπ¥‰ªΩ"] = df["Âπ¥‰ªΩ"].apply(lambda y: y + 2000 if 0 < y < 100 else y)
        df["Êúà‰ªΩ"] = df["Êúà‰ªΩ"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)
        df["Êó•"] = df["Êó•"].astype(str).str.extract(r"(\d+)")[0].astype(float).fillna(0).astype(int)

        for c in ["Èó®Â∫óÂêçÁß∞", "ÁúÅÂå∫", "ÁªèÈîÄÂïÜÂêçÁß∞", "‰∫ßÂìÅÂ§ßÁ±ª", "‰∫ßÂìÅÂ∞èÁ±ª"]:
            df[c] = df[c].fillna("").astype(str).str.strip()

        coords = df["ÁªèÁ∫¨Â∫¶"].apply(_parse_lon_lat)
        df["ÁªèÂ∫¶"] = coords.apply(lambda x: x[0])
        df["Á∫¨Â∫¶"] = coords.apply(lambda x: x[1])

        df = df[df["Âπ¥‰ªΩ"] == 2025]
        return df
    except Exception:
        return pd.DataFrame()

# -----------------------------------------------------------------------------
# 4. Layout
# -----------------------------------------------------------------------------

st.markdown("## üõ†Ô∏è Êï∞ÊçÆÊéßÂà∂Âè∞")

if 'hc_mode' not in st.session_state:
    st.session_state.hc_mode = False

st.toggle("È´òÂØπÊØîÊ®°Âºè", key="hc_mode")

if st.session_state.get("hc_mode"):
    st.markdown("""
    <style>
      :root {
        --tbl-header-bg: #0B57D0;
        --tbl-header-bg-hover: #0846AB;
        --tbl-header-border: #06357F;
        --tbl-header-fg: #FFFFFF;
        --tbl-header-icon: #FFFFFF;
        --tbl-header-shadow: 0 10px 22px rgba(0, 0, 0, 0.38);
      }
    </style>
    """, unsafe_allow_html=True)

if 'exp_upload' not in st.session_state:
    st.session_state.exp_upload = True
if 'exp_filter' not in st.session_state:
    st.session_state.exp_filter = True

with st.expander("üì• Êï∞ÊçÆÂØºÂÖ•", expanded=st.session_state.exp_upload):
    uploaded_file = st.file_uploader("ÂØºÂÖ•Êï∞ÊçÆË°® (Excel/CSV)", type=['xlsx', 'xls', 'csv'], key="main_uploader")

if uploaded_file is None:
    st.markdown(
        """
        <div style='text-align: center; padding: 60px 20px; background-color: white; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 40px;'>
            <h1 style='color: #4096ff; margin-bottom: 16px;'>üëã Ê¨¢Ëøé‰ΩøÁî®ÁæéÊÄùÈõÖÊï∞ÊçÆÂàÜÊûêÁ≥ªÁªü</h1>
            <p style='color: #666; font-size: 16px; margin-bottom: 0;'>ËØ∑‰∏ä‰º† Excel Êï∞ÊçÆÊñá‰ª∂‰ª•Ëß£ÈîÅÂÆåÊï¥ÂàÜÊûêÈù¢Êùø</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    # st.stop()  # Streamlit Cloud Health Check Fix: Avoid blocking the app here

# Main Logic
if uploaded_file:
    uploaded_name = uploaded_file.name
    cached_bytes = st.session_state.get("_uploaded_bytes")
    cached_sig = st.session_state.get("_uploaded_sig")
    cached_name = st.session_state.get("_uploaded_name")

    if cached_bytes is None or cached_sig is None or cached_name != uploaded_name:
        cached_bytes = uploaded_file.getvalue()
        cached_sig = hashlib.md5(cached_bytes).hexdigest()
        st.session_state["_uploaded_bytes"] = cached_bytes
        st.session_state["_uploaded_sig"] = cached_sig
        st.session_state["_uploaded_name"] = uploaded_name

    if st.session_state.get("_active_file_sig") != cached_sig:
        st.session_state["_active_file_sig"] = cached_sig
        st.session_state["run_analysis"] = False

    parsed_cache = st.session_state.get("_parsed_cache", {})
    if cached_sig in parsed_cache:
        # Check if cache is old version (7 elements) or new version (8 elements)
        cache_val = parsed_cache[cached_sig]
        if len(cache_val) == 8:
            df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = cache_val
        else:
            # Re-parse if cache format mismatch (Old cache had 7 items)
            df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = load_data_v3(cached_bytes, uploaded_name)
            parsed_cache[cached_sig] = (df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs)
            st.session_state["_parsed_cache"] = parsed_cache
    else:
        df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs = load_data_v3(cached_bytes, uploaded_name)
        parsed_cache[cached_sig] = (df_raw, month_cols, df_stock_raw, df_q4_raw, df_perf_raw, df_target_raw, df_scan_raw, debug_logs)
        if len(parsed_cache) > 2:
            for k in list(parsed_cache.keys())[:-2]:
                parsed_cache.pop(k, None)
        st.session_state["_parsed_cache"] = parsed_cache

    df_perf_2025 = load_builtin_perf_2025()
    if df_perf_2025 is not None and not df_perf_2025.empty:
        if df_perf_raw is None or getattr(df_perf_raw, "empty", True):
            df_perf_raw = df_perf_2025.copy()
        else:
            years = pd.to_numeric(df_perf_raw.get("Âπ¥‰ªΩ", pd.Series(dtype=float)), errors="coerce")
            if not bool((years == 2025).any()):
                df_perf_raw = pd.concat([df_perf_2025, df_perf_raw], ignore_index=True, sort=False)
                
    df_scan_2025 = load_builtin_scan_2025()
    if df_scan_2025 is not None and not df_scan_2025.empty:
        if df_scan_raw is None or getattr(df_scan_raw, "empty", True):
            df_scan_raw = df_scan_2025.copy()
        else:
            years_s = pd.to_numeric(df_scan_raw.get("Âπ¥‰ªΩ", pd.Series(dtype=float)), errors="coerce")
            if not bool((years_s == 2025).any()):
                df_scan_raw = pd.concat([df_scan_2025, df_scan_raw], ignore_index=True, sort=False)

    if df_raw is None and debug_logs:
        st.error("Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•„ÄÇËØ¶ÁªÜÊó•ÂøóÂ¶Ç‰∏ãÔºö")
        st.text("\n".join(debug_logs))

    if df_raw is not None:
        # --- Filters Area ---
        with st.expander("üîé Á≠õÈÄâÊêúÁ¥¢", expanded=st.session_state.exp_filter):
            # Province Filter
            provinces = ['ÂÖ®ÈÉ®'] + sorted(list(df_raw['ÁúÅÂå∫'].unique()))
            sel_prov = st.selectbox("ÈÄâÊã©ÁúÅÂå∫ (Province)", provinces)
            
            # Distributor Filter
            if sel_prov != 'ÂÖ®ÈÉ®':
                dist_options = ['ÂÖ®ÈÉ®'] + sorted(list(df_raw[df_raw['ÁúÅÂå∫']==sel_prov]['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
            else:
                dist_options = ['ÂÖ®ÈÉ®'] + sorted(list(df_raw['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
            sel_dist = st.selectbox("ÈÄâÊã©ÁªèÈîÄÂïÜ (Distributor)", dist_options)

            cat_set = set()
            for _df, _col in [
                (df_perf_raw, 'Â§ßÂàÜÁ±ª'),
                (df_perf_raw, '‰∫ßÂìÅÂ§ßÁ±ª'),
                (df_q4_raw, '‰∫ßÂìÅÂ§ßÁ±ª'),
                (df_stock_raw, '‰∫ßÂìÅÂ§ßÁ±ª'),
                (df_scan_raw, '‰∫ßÂìÅÂ§ßÁ±ª'),
            ]:
                if _df is not None and not getattr(_df, "empty", True) and _col in _df.columns:
                    cat_set |= set(_df[_col].fillna('').astype(str).str.strip().tolist())
            cat_options = ['ÂÖ®ÈÉ®'] + sorted([x for x in cat_set if x])
            sel_cat = st.selectbox("ÈÄâÊã©‰∫ßÂìÅÂ§ßÁ±ª (Category)", cat_options, key="main_sel_cat")
        
        # Apply Filters
        df = df_raw.copy()
        if sel_prov != 'ÂÖ®ÈÉ®':
            df = df[df['ÁúÅÂå∫'] == sel_prov]
        if sel_dist != 'ÂÖ®ÈÉ®':
            df = df[df['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist]
            
        if not st.session_state.get('run_analysis', False):
            st.markdown("### ‚úÖ Êï∞ÊçÆÂ∑≤Âä†ËΩΩ")
            st.caption("ÁÇπÂáª„ÄåÂºÄÂßãÂàÜÊûê üöÄ„ÄçËøõÂÖ•ÂàÜÊûêÈ°µÈù¢„ÄÇ")
            if st.button("ÂºÄÂßãÂàÜÊûê üöÄ", type="primary", key="main_start_analysis"):
                st.session_state['run_analysis'] = True

        # Share / external-access UI intentionally removed
            
        if st.session_state.get('run_analysis', False):
            
            # --- Header ---
            st.title("üìà ÁæéÊÄùÈõÖÊï∞ÊçÆÂàÜÊûêÁ≥ªÁªü")
            st.markdown(f"ÂΩìÂâçÊï∞ÊçÆËåÉÂõ¥: **{sel_prov}** / **{sel_dist}** | ÂåÖÂê´ **{len(df)}** ÂÆ∂Èó®Â∫ó")
            
            # --- Tabs ---
            tab1, tab7, tab6, tab_out, tab_scan, tab3, tab_other = st.tabs(["üìä Ê†∏ÂøÉÊ¶ÇËßà", "üöÄ ‰∏öÁª©ÂàÜÊûê", "üì¶ Â∫ìÂ≠òÂàÜÊûê", "üöö Âá∫Â∫ìÂàÜÊûê", "üì± Êâ´Á†ÅÂàÜÊûê", "üìà ABCDÊïàËÉΩÂàÜÊûê", "ÂÖ∂‰ªñÂàÜÊûê"])
            
            # === TAB 1: OVERVIEW ===
            with tab1:
                st.caption(f"Á≠õÈÄâÂè£ÂæÑÔºöÁúÅÂå∫={sel_prov}ÔΩúÁªèÈîÄÂïÜ={sel_dist}ÔΩú‰∫ßÂìÅÂ§ßÁ±ª={st.session_state.get('main_sel_cat', 'ÂÖ®ÈÉ®')}")

                # --- Common Helpers for Tab 1 ---
                def _fmt_wan(x): return fmt_num((x or 0) / 10000)
                def _fmt_pct(x): return fmt_pct_ratio(x) if x is not None else "‚Äî"
                def _arrow(x): return "‚Üë" if x and x>0 else ("‚Üì" if x and x<0 else "")
                def _trend_cls(x): return "trend-up" if x and x > 0 else ("trend-down" if x and x < 0 else "trend-neutral")

                # Card Renderer for Performance (Tab 7 Style)
                def _render_perf_card(title, icon, val_wan, target_wan, rate, yoy_val_wan, yoy_pct):
                    trend_cls = _trend_cls(yoy_pct)
                    arrow = _arrow(yoy_pct)
                    rate_txt = _fmt_pct(rate)
                    yoy_txt = _fmt_pct(yoy_pct)
                    pct_val = min(max(rate * 100 if rate else 0, 0), 100)
                    prog_color = "#28A745" if rate and rate >= 1.0 else ("#FFC107" if rate and rate >= 0.8 else "#DC3545")

                    st.markdown(f"""
                    <div class="out-kpi-card">
                        <div class="out-kpi-bar"></div>
                        <div class="out-kpi-head">
                            <div class="out-kpi-ico">{icon}</div>
                            <div class="out-kpi-title">{title}</div>
                        </div>
                        <div class="out-kpi-val">¬• {val_wan}‰∏á</div>
                        <div class="out-kpi-sub2" style="margin-top:8px;">
                            <span>ËææÊàêÁéá</span>
                            <span style="font-weight:800; color:{prog_color}">{rate_txt}</span>
                        </div>
                        <div class="out-kpi-progress" style="margin-top:6px;">
                            <div class="out-kpi-progress-bar" style="background:{prog_color}; width:{pct_val}%;"></div>
                        </div>
                        <div class="out-kpi-sub2" style="margin-top:10px;">
                            <span>ÁõÆÊ†á</span>
                            <span>{target_wan}‰∏á</span>
                        </div>
                        <div class="out-kpi-sub2">
                            <span>ÂêåÊúü</span>
                            <span>{yoy_val_wan}‰∏á</span>
                        </div>
                        <div class="out-kpi-sub2">
                            <span>ÂêåÊØî</span>
                            <span class="{trend_cls}">{arrow} {yoy_txt}</span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

                # Card Renderer for Outbound/Scan (General Style)
                def _render_general_card(title, icon, main_val, sub_items):
                    # sub_items: list of (label, value_html)
                    rows_html = ""
                    for label, val_html in sub_items:
                        rows_html += f'<div class="out-kpi-sub2"><span>{label}</span><span>{val_html}</span></div>'
                    
                    st.markdown(f"""
                    <div class="out-kpi-card">
                        <div class="out-kpi-bar"></div>
                        <div class="out-kpi-head">
                            <div class="out-kpi-ico">{icon}</div>
                            <div class="out-kpi-title">{title}</div>
                        </div>
                        <div class="out-kpi-val">{main_val}</div>
                        <div style="margin-top:10px;">{rows_html}</div>
                    </div>
                    """, unsafe_allow_html=True)

                sel_bigcat = st.session_state.get("main_sel_cat", "ÂÖ®ÈÉ®")

                def _filter_common(_df):
                    if _df is None or getattr(_df, "empty", True):
                        return pd.DataFrame()
                    d = _df.copy()
                    for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', '‰∫ßÂìÅÂ§ßÁ±ª', 'Â§ßÂàÜÁ±ª']:
                        if c in d.columns:
                            d[c] = d[c].fillna('').astype(str).str.strip()
                    if sel_prov != 'ÂÖ®ÈÉ®' and 'ÁúÅÂå∫' in d.columns:
                        d = d[d['ÁúÅÂå∫'] == sel_prov]
                    if sel_dist != 'ÂÖ®ÈÉ®' and 'ÁªèÈîÄÂïÜÂêçÁß∞' in d.columns:
                        d = d[d['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist]
                    if sel_bigcat != 'ÂÖ®ÈÉ®':
                        if '‰∫ßÂìÅÂ§ßÁ±ª' in d.columns:
                            d = d[d['‰∫ßÂìÅÂ§ßÁ±ª'] == sel_bigcat]
                        elif 'Â§ßÂàÜÁ±ª' in d.columns:
                            d = d[d['Â§ßÂàÜÁ±ª'] == sel_bigcat]
                    return d

                # ---------------------------------------------------------
                # 1. Ê†∏ÂøÉ‰∏öÁª©ÊåáÊ†á (From Tab 7)
                # ---------------------------------------------------------
                st.markdown("### üöÄ Ê†∏ÂøÉ‰∏öÁª©ÊåáÊ†á")
                df_perf = _filter_common(df_perf_raw)
                if not df_perf.empty:
                    # Data Prep
                    if 'Âπ¥‰ªΩ' in df_perf.columns:
                        df_perf['Âπ¥‰ªΩ'] = pd.to_numeric(df_perf['Âπ¥‰ªΩ'], errors='coerce').fillna(0).astype(int)
                    if 'Êúà‰ªΩ' in df_perf.columns:
                        df_perf['Êúà‰ªΩ'] = pd.to_numeric(df_perf['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                    amt_col = 'ÂèëË¥ßÈáëÈ¢ù' if 'ÂèëË¥ßÈáëÈ¢ù' in df_perf.columns else None
                    if amt_col:
                        df_perf[amt_col] = pd.to_numeric(df_perf[amt_col], errors='coerce').fillna(0)
                    
                    years_avail = sorted([y for y in df_perf['Âπ¥‰ªΩ'].unique().tolist() if y > 2000])
                    perf_y = max(years_avail) if years_avail else 2025
                    months_avail = sorted([m for m in df_perf[df_perf['Âπ¥‰ªΩ'] == perf_y]['Êúà‰ªΩ'].unique().tolist() if 1 <= m <= 12])
                    perf_m = max(months_avail) if months_avail else 1
                    last_y = perf_y - 1

                    # Actuals
                    cur_m_amt = df_perf[(df_perf['Âπ¥‰ªΩ'] == perf_y) & (df_perf['Êúà‰ªΩ'] == perf_m)][amt_col].sum() if amt_col else 0
                    last_m_amt = df_perf[(df_perf['Âπ¥‰ªΩ'] == last_y) & (df_perf['Êúà‰ªΩ'] == perf_m)][amt_col].sum() if amt_col else 0
                    cur_y_amt = df_perf[df_perf['Âπ¥‰ªΩ'] == perf_y][amt_col].sum() if amt_col else 0
                    last_y_amt = df_perf[df_perf['Âπ¥‰ªΩ'] == last_y][amt_col].sum() if amt_col else 0

                    yoy_m = (cur_m_amt - last_m_amt) / last_m_amt if last_m_amt > 0 else 0
                    yoy_y = (cur_y_amt - last_y_amt) / last_y_amt if last_y_amt > 0 else 0

                    # Targets
                    t_cur_m = 0.0
                    t_cur_y = 0.0
                    if df_target_raw is not None and not getattr(df_target_raw, "empty", True):
                        df_t = df_target_raw.copy()
                        for c in ['ÁúÅÂå∫', 'ÂìÅÁ±ª']:
                            if c in df_t.columns: df_t[c] = df_t[c].fillna('').astype(str).str.strip()
                        if 'Êúà‰ªΩ' in df_t.columns: df_t['Êúà‰ªΩ'] = pd.to_numeric(df_t['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                        if '‰ªªÂä°Èáè' in df_t.columns: df_t['‰ªªÂä°Èáè'] = pd.to_numeric(df_t['‰ªªÂä°Èáè'], errors='coerce').fillna(0)
                        
                        if sel_prov != 'ÂÖ®ÈÉ®' and 'ÁúÅÂå∫' in df_t.columns:
                            df_t = df_t[df_t['ÁúÅÂå∫'] == sel_prov]
                        # Target usually doesn't filter by Distributor, but filters by Category
                        if sel_bigcat != 'ÂÖ®ÈÉ®' and 'ÂìÅÁ±ª' in df_t.columns:
                            df_t = df_t[df_t['ÂìÅÁ±ª'] == sel_bigcat]
                        
                        t_cur_m = df_t[df_t['Êúà‰ªΩ'] == perf_m]['‰ªªÂä°Èáè'].sum()
                        t_cur_y = df_t['‰ªªÂä°Èáè'].sum() # Total Year Target

                    rate_m = (cur_m_amt / t_cur_m) if t_cur_m > 0 else None
                    rate_y = (cur_y_amt / t_cur_y) if t_cur_y > 0 else None

                    c1, c2 = st.columns(2)
                    with c1:
                        _render_perf_card(f"Êú¨Êúà‰∏öÁª©Ôºà{perf_m}ÊúàÔºâ", "üìÖ", _fmt_wan(cur_m_amt), _fmt_wan(t_cur_m), rate_m, _fmt_wan(last_m_amt), yoy_m)
                    with c2:
                        _render_perf_card(f"Âπ¥Â∫¶Á¥ØËÆ°‰∏öÁª©Ôºà{perf_y}Âπ¥Ôºâ", "üèÜ", _fmt_wan(cur_y_amt), _fmt_wan(t_cur_y), rate_y, _fmt_wan(last_y_amt), yoy_y)
                else:
                    st.info("‰∏öÁª©Êï∞ÊçÆ‰∏∫Á©∫Êàñ‰∏çÂê´ÂåπÈÖçÂ≠óÊÆµ")

                st.markdown("---")

                # ---------------------------------------------------------
                # 2. Â∫ìÂ≠òÂÖ≥ÈîÆÊåáÊ†á (From Tab 6)
                # ---------------------------------------------------------
                st.markdown("### üì¶ Â∫ìÂ≠òÂÖ≥ÈîÆÊåáÊ†á")
                df_stock = _filter_common(df_stock_raw)
                if not df_stock.empty:
                    # Prepare Data for Metrics
                    stock_box_col = 'ÁÆ±Êï∞' if 'ÁÆ±Êï∞' in df_stock.columns else next((c for c in df_stock.columns if 'ÁÆ±' in str(c)), None)
                    stock_boxes = float(pd.to_numeric(df_stock[stock_box_col], errors='coerce').fillna(0).sum()) if stock_box_col else 0.0
                    
                    # Q4 Avg Sales (Need logic from Tab 6)
                    total_q4_avg = 0.0
                    if df_q4_raw is not None and not getattr(df_q4_raw, "empty", True):
                        # Simple estimation: Filter Q4 raw by current filters -> Sum Q4 months -> Divide by 3
                        # Tab 6 logic is more complex (Distributor based), but for Overview Total, simple sum is close enough.
                        # However, let's try to match Tab 6 logic: Sum 'Q4_Avg' of relevant distributors.
                        
                        # 1. Get filtered distributors
                        valid_dists = df_stock['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()
                        
                        # 2. Calculate Q4 Sales for these distributors
                        df_q4_f = df_q4_raw.copy()
                        if 'Âπ¥‰ªΩ' in df_q4_f.columns: df_q4_f = df_q4_f[df_q4_f['Âπ¥‰ªΩ'] == 2025] # Q4 assumption
                        if 'ÁªèÈîÄÂïÜÂêçÁß∞' in df_q4_f.columns:
                            df_q4_f = df_q4_f[df_q4_f['ÁªèÈîÄÂïÜÂêçÁß∞'].isin(valid_dists)]
                        
                        # Filter for Oct, Nov, Dec
                        if 'Êúà‰ªΩ' in df_q4_f.columns:
                            df_q4_f['Êúà‰ªΩ'] = pd.to_numeric(df_q4_f['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                            df_q4_f = df_q4_f[df_q4_f['Êúà‰ªΩ'].isin([10, 11, 12])]
                        
                        qty_col = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in df_q4_f.columns else next((c for c in df_q4_f.columns if 'Êï∞Èáè' in str(c)), None)
                        if qty_col:
                            total_q4_sales = pd.to_numeric(df_q4_f[qty_col], errors='coerce').sum()
                            total_q4_avg = total_q4_sales / 3.0

                    dos = stock_boxes / total_q4_avg if total_q4_avg > 0 else 0.0
                    
                    # Abnormal Count (Simplify for Overview)
                    # Tab 6 calculates per distributor. Here we just show global metrics.
                    
                    m1, m2, m3 = st.columns(3)
                    m1.metric("üì¶ ÊÄªÂ∫ìÂ≠ò (ÁÆ±)", fmt_num(stock_boxes))
                    m2.metric("üìâ Q4ÊúàÂùáÈîÄ", fmt_num(total_q4_avg))
                    m3.metric("üìÖ Êï¥‰ΩìÂèØÈîÄÊúà (DOS)", fmt_num(dos))
                else:
                    st.info("Â∫ìÂ≠òÊï∞ÊçÆ‰∏∫Á©∫")

                st.markdown("---")

                # ---------------------------------------------------------
                # 3. Âá∫Â∫ìÂÖ≥ÈîÆÊåáÊ†á (From Tab Out)
                # ---------------------------------------------------------
                st.markdown("### üöö Âá∫Â∫ìÂÖ≥ÈîÆÊåáÊ†á")
                df_out = _filter_common(df_q4_raw)
                if not df_out.empty:
                    # Date Prep
                    tmp = df_out.copy()
                    for c in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ']: 
                        if c in tmp.columns: tmp[c] = pd.to_numeric(tmp[c], errors='coerce').fillna(0).astype(int)
                    if 'Êó•' in tmp.columns: tmp['Êó•'] = pd.to_numeric(tmp['Êó•'], errors='coerce').fillna(0).astype(int)
                    qty_col = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in tmp.columns else next((c for c in tmp.columns if 'Êï∞Èáè' in str(c) or 'ÁÆ±' in str(c)), None)
                    if qty_col:
                        tmp['Êï∞Èáè(ÁÆ±)'] = pd.to_numeric(tmp[qty_col], errors='coerce').fillna(0)
                        tmp = tmp[tmp['Âπ¥‰ªΩ'] > 0]
                        
                        oy = int(tmp['Âπ¥‰ªΩ'].max())
                        om = int(tmp[tmp['Âπ¥‰ªΩ'] == oy]['Êúà‰ªΩ'].max())
                        od = int(tmp[(tmp['Âπ¥‰ªΩ'] == oy) & (tmp['Êúà‰ªΩ'] == om)]['Êó•'].max())
                        
                        # Current
                        today_boxes = tmp[(tmp['Âπ¥‰ªΩ'] == oy) & (tmp['Êúà‰ªΩ'] == om) & (tmp['Êó•'] == od)]['Êï∞Èáè(ÁÆ±)'].sum()
                        month_boxes = tmp[(tmp['Âπ¥‰ªΩ'] == oy) & (tmp['Êúà‰ªΩ'] == om)]['Êï∞Èáè(ÁÆ±)'].sum()
                        year_boxes = tmp[tmp['Âπ¥‰ªΩ'] == oy]['Êï∞Èáè(ÁÆ±)'].sum()
                        
                        # Last Year
                        ly = oy - 1
                        l_today_boxes = tmp[(tmp['Âπ¥‰ªΩ'] == ly) & (tmp['Êúà‰ªΩ'] == om) & (tmp['Êó•'] == od)]['Êï∞Èáè(ÁÆ±)'].sum()
                        l_month_boxes = tmp[(tmp['Âπ¥‰ªΩ'] == ly) & (tmp['Êúà‰ªΩ'] == om)]['Êï∞Èáè(ÁÆ±)'].sum()
                        l_year_boxes = tmp[tmp['Âπ¥‰ªΩ'] == ly]['Êï∞Èáè(ÁÆ±)'].sum()
                        
                        # YoY
                        yoy_d = (today_boxes - l_today_boxes) / l_today_boxes if l_today_boxes > 0 else 0
                        yoy_m = (month_boxes - l_month_boxes) / l_month_boxes if l_month_boxes > 0 else 0
                        yoy_y = (year_boxes - l_year_boxes) / l_year_boxes if l_year_boxes > 0 else 0
                        
                        k1, k2, k3 = st.columns(3)
                        with k1:
                            trend = _trend_cls(yoy_d)
                            arr = _arrow(yoy_d)
                            _render_general_card("Êú¨Êó•Âá∫Â∫ì", "üöö", f"{fmt_num(today_boxes)} ÁÆ±", [
                                ("ÂêåÊúü", f"{fmt_num(l_today_boxes)} ÁÆ±"),
                                ("ÂêåÊØî", f'<span class="{trend}">{arr} {_fmt_pct(yoy_d)}</span>')
                            ])
                        with k2:
                            trend = _trend_cls(yoy_m)
                            arr = _arrow(yoy_m)
                            _render_general_card(f"Êú¨ÊúàÁ¥ØËÆ°Âá∫Â∫ìÔºà{om}ÊúàÔºâ", "üì¶", f"{fmt_num(month_boxes)} ÁÆ±", [
                                ("ÂêåÊúü", f"{fmt_num(l_month_boxes)} ÁÆ±"),
                                ("ÂêåÊØî", f'<span class="{trend}">{arr} {_fmt_pct(yoy_m)}</span>')
                            ])
                        with k3:
                            trend = _trend_cls(yoy_y)
                            arr = _arrow(yoy_y)
                            _render_general_card(f"Êú¨Âπ¥Á¥ØËÆ°Âá∫Â∫ìÔºà{oy}Âπ¥Ôºâ", "üßæ", f"{fmt_num(year_boxes)} ÁÆ±", [
                                ("ÂêåÊúü", f"{fmt_num(l_year_boxes)} ÁÆ±"),
                                ("ÂêåÊØî", f'<span class="{trend}">{arr} {_fmt_pct(yoy_y)}</span>')
                            ])
                else:
                    st.info("Âá∫Â∫ìÊï∞ÊçÆ‰∏∫Á©∫")

                st.markdown("---")

                # ---------------------------------------------------------
                # 4. Êâ´Á†ÅÁéáÊ¶ÇËßà (From Tab Scan)
                # ---------------------------------------------------------
                st.markdown("### üì± Êâ´Á†ÅÁéáÊ¶ÇËßà")
                df_scan = _filter_common(df_scan_raw)
                # Re-use out_base from above or re-calc
                if not df_scan.empty and not df_out.empty:
                    # Ensure Date Cols
                    for c in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ', 'Êó•']:
                        if c in df_scan.columns: df_scan[c] = pd.to_numeric(df_scan[c], errors='coerce').fillna(0).astype(int)
                    
                    # Use same oy, om, od from Outbound
                    scan_today = len(df_scan[(df_scan['Âπ¥‰ªΩ'] == oy) & (df_scan['Êúà‰ªΩ'] == om) & (df_scan['Êó•'] == od)]) / 6.0
                    scan_month = len(df_scan[(df_scan['Âπ¥‰ªΩ'] == oy) & (df_scan['Êúà‰ªΩ'] == om)]) / 6.0
                    scan_year = len(df_scan[df_scan['Âπ¥‰ªΩ'] == oy]) / 6.0
                    
                    l_scan_today = len(df_scan[(df_scan['Âπ¥‰ªΩ'] == ly) & (df_scan['Êúà‰ªΩ'] == om) & (df_scan['Êó•'] == od)]) / 6.0
                    l_scan_month = len(df_scan[(df_scan['Âπ¥‰ªΩ'] == ly) & (df_scan['Êúà‰ªΩ'] == om)]) / 6.0
                    l_scan_year = len(df_scan[df_scan['Âπ¥‰ªΩ'] == ly]) / 6.0

                    rate_today = scan_today / today_boxes if today_boxes > 0 else 0
                    rate_month = scan_month / month_boxes if month_boxes > 0 else 0
                    rate_year = scan_year / year_boxes if year_boxes > 0 else 0
                    
                    yoy_rate_d = rate_today - (l_scan_today / l_today_boxes if l_today_boxes > 0 else 0)
                    yoy_rate_m = rate_month - (l_scan_month / l_month_boxes if l_month_boxes > 0 else 0)
                    yoy_rate_y = rate_year - (l_scan_year / l_year_boxes if l_year_boxes > 0 else 0)

                    s1, s2, s3 = st.columns(3)
                    with s1:
                        trend = _trend_cls(yoy_rate_d)
                        arr = _arrow(yoy_rate_d)
                        _render_general_card("Êú¨Êó•Êâ´Á†ÅÁéá", "üì±", fmt_pct_ratio(rate_today), [
                            ("Êâ´Á†Å / Âá∫Â∫ì", f"{fmt_num(scan_today)} / {fmt_num(today_boxes)}"),
                            ("ÂêåÊØîÂ¢ûÂáè", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_d*100)}</span>')
                        ])
                    with s2:
                        trend = _trend_cls(yoy_rate_m)
                        arr = _arrow(yoy_rate_m)
                        _render_general_card("Êú¨ÊúàÊâ´Á†ÅÁéá", "üóìÔ∏è", fmt_pct_ratio(rate_month), [
                            ("Êâ´Á†Å / Âá∫Â∫ì", f"{fmt_num(scan_month)} / {fmt_num(month_boxes)}"),
                            ("ÂêåÊØîÂ¢ûÂáè", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_m*100)}</span>')
                        ])
                    with s3:
                        trend = _trend_cls(yoy_rate_y)
                        arr = _arrow(yoy_rate_y)
                        _render_general_card("Êú¨Âπ¥Êâ´Á†ÅÁéá", "üìà", fmt_pct_ratio(rate_year), [
                            ("Êâ´Á†Å / Âá∫Â∫ì", f"{fmt_num(scan_year)} / {fmt_num(year_boxes)}"),
                            ("ÂêåÊØîÂ¢ûÂáè", f'<span class="{trend}">{arr} {fmt_pct_value(yoy_rate_y*100)}</span>')
                        ])
                else:
                    st.info("Êâ´Á†ÅÊï∞ÊçÆ‰∏∫Á©∫")

            # === TAB SCAN: SCAN ANALYSIS ===
            with tab_scan:
                if df_scan_raw is not None and not df_scan_raw.empty:
                    st.subheader("üì± Êâ´Á†ÅÂàÜÊûê")
                    
                    # 1. Date Calculation
                    # Today: Max date in max month of 2026
                    max_scan_date = None
                    df_scan_2026 = df_scan_raw[df_scan_raw['Âπ¥‰ªΩ'] == 2026]
                    if not df_scan_2026.empty:
                        max_month = df_scan_2026['Êúà‰ªΩ'].max()
                        max_day = df_scan_2026[df_scan_2026['Êúà‰ªΩ'] == max_month]['Êó•'].max()
                        max_scan_date = pd.Timestamp(year=2026, month=max_month, day=max_day)
                    
                    if max_scan_date:
                        cur_year = max_scan_date.year
                        cur_month = max_scan_date.month
                        cur_day = max_scan_date.day
                        st.info(f"üìÖ ÂΩìÂâçÁªüËÆ°Êó•ÊúüÔºö{cur_year}Âπ¥{cur_month}Êúà{cur_day}Êó•")
                    else:
                        st.warning("‚ö†Ô∏è Êú™ÊâæÂà∞2026Âπ¥Êâ´Á†ÅÊï∞ÊçÆÔºåÊó†Ê≥ïËÆ°ÁÆóÂΩìÊó•/ÂΩìÊúàÊåáÊ†á")
                        cur_year, cur_month, cur_day = 2026, 1, 1

                    # 2. Filter Area
                    with st.expander("üîé Êâ´Á†ÅÁ≠õÈÄâ", expanded=True):
                        c_s1, c_s2, c_s3 = st.columns(3)
                        # Province
                        prov_opts_s = ['ÂÖ®ÈÉ®'] + sorted(df_scan_raw['ÁúÅÂå∫'].unique().tolist())
                        sel_prov_s = c_s1.selectbox("ÁúÅÂå∫", prov_opts_s, key="scan_prov")
                        
                        # Distributor
                        if sel_prov_s != 'ÂÖ®ÈÉ®':
                            dist_opts_s = ['ÂÖ®ÈÉ®'] + sorted(df_scan_raw[df_scan_raw['ÁúÅÂå∫'] == sel_prov_s]['ÁªèÈîÄÂïÜÂêçÁß∞'].unique().tolist())
                        else:
                            dist_opts_s = ['ÂÖ®ÈÉ®'] + sorted(df_scan_raw['ÁªèÈîÄÂïÜÂêçÁß∞'].unique().tolist())
                        sel_dist_s = c_s2.selectbox("ÁªèÈîÄÂïÜ", dist_opts_s, key="scan_dist")
                        
                        # Category
                        cat_opts_s = ['ÂÖ®ÈÉ®'] + sorted(df_scan_raw['‰∫ßÂìÅÂ§ßÁ±ª'].unique().tolist())
                        sel_cat_s = c_s3.selectbox("‰∫ßÂìÅÂ§ßÁ±ª", cat_opts_s, key="scan_cat")

                    # Apply Filters
                    df_s_flt = df_scan_raw.copy()
                    last_year = cur_year - 1
                    out_base_df = None
                    out_day_df = None
                    out_day_last_df = None
                    if df_q4_raw is not None and not getattr(df_q4_raw, "empty", True):
                        tmp = df_q4_raw.copy()
                        for c in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ']:
                            if c in tmp.columns:
                                tmp[c] = pd.to_numeric(tmp[c], errors='coerce').fillna(0).astype(int)
                        day_col_out = None
                        if 'Êó•' in tmp.columns:
                            day_col_out = 'Êó•'
                            tmp['Êó•'] = pd.to_numeric(tmp['Êó•'], errors='coerce').fillna(0).astype(int)
                        else:
                            cand = next((c for c in tmp.columns if 'Êó•Êúü' in str(c)), None)
                            if cand:
                                dt = pd.to_datetime(tmp[cand], errors='coerce')
                                tmp['Âπ¥‰ªΩ'] = dt.dt.year
                                tmp['Êúà‰ªΩ'] = dt.dt.month
                                tmp['Êó•'] = dt.dt.day
                                day_col_out = 'Êó•'
                        qty_col_out = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in tmp.columns else next((c for c in tmp.columns if 'Êï∞Èáè' in str(c) or 'ÁÆ±' in str(c)), None)
                        if qty_col_out:
                            tmp['Êï∞Èáè(ÁÆ±)'] = pd.to_numeric(tmp[qty_col_out], errors='coerce').fillna(0)
                            if all(k in tmp.columns for k in ['Âπ¥‰ªΩ', 'Êúà‰ªΩ', 'Êó•']):
                                out_base_df = tmp.copy()
                                for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', '‰∫ßÂìÅÂ§ßÁ±ª', 'Â§ßÂàÜÁ±ª']:
                                    if c in out_base_df.columns:
                                        out_base_df[c] = out_base_df[c].fillna('').astype(str).str.strip()

                    if sel_prov_s != 'ÂÖ®ÈÉ®':
                        df_s_flt = df_s_flt[df_s_flt['ÁúÅÂå∫'] == sel_prov_s]
                        if out_base_df is not None and 'ÁúÅÂå∫' in out_base_df.columns:
                            out_base_df = out_base_df[out_base_df['ÁúÅÂå∫'] == sel_prov_s]
                    if sel_dist_s != 'ÂÖ®ÈÉ®':
                        df_s_flt = df_s_flt[df_s_flt['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist_s]
                        if out_base_df is not None and 'ÁªèÈîÄÂïÜÂêçÁß∞' in out_base_df.columns:
                            out_base_df = out_base_df[out_base_df['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist_s]
                    if sel_cat_s != 'ÂÖ®ÈÉ®':
                        df_s_flt = df_s_flt[df_s_flt['‰∫ßÂìÅÂ§ßÁ±ª'] == sel_cat_s]
                        if out_base_df is not None:
                            if '‰∫ßÂìÅÂ§ßÁ±ª' in out_base_df.columns:
                                out_base_df = out_base_df[out_base_df['‰∫ßÂìÅÂ§ßÁ±ª'] == sel_cat_s]
                            elif 'Â§ßÂàÜÁ±ª' in out_base_df.columns:
                                out_base_df = out_base_df[out_base_df['Â§ßÂàÜÁ±ª'] == sel_cat_s]

                    if out_base_df is not None:
                        out_day_df = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == cur_year) & (out_base_df['Êúà‰ªΩ'] == cur_month) & (out_base_df['Êó•'] == cur_day)].copy()
                        out_day_last_df = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == last_year) & (out_base_df['Êúà‰ªΩ'] == cur_month) & (out_base_df['Êó•'] == cur_day)].copy()

                    # 3. Calculate Metrics (Scan vs Outbound)
                    # Unit: Box (6 tins = 1 box)
                    # Scan Count (Rows) / 6
                    
                    # --- Current Period (2026) ---
                    # Day
                    scan_day = len(df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month) & (df_s_flt['Êó•'] == cur_day)]) / 6.0
                    out_day = 0
                    if out_day_df is not None:
                        qty_col_out = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in out_day_df.columns else next((c for c in out_day_df.columns if 'Êï∞Èáè' in str(c) or 'ÁÆ±' in str(c)), None)
                        if qty_col_out:
                            out_day = float(pd.to_numeric(out_day_df[qty_col_out], errors='coerce').fillna(0).sum())
                    out_day_last = 0
                    if out_day_last_df is not None:
                        qty_col_out = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in out_day_last_df.columns else next((c for c in out_day_last_df.columns if 'Êï∞Èáè' in str(c) or 'ÁÆ±' in str(c)), None)
                        if qty_col_out:
                            out_day_last = float(pd.to_numeric(out_day_last_df[qty_col_out], errors='coerce').fillna(0).sum())
                    
                    # Month
                    scan_month = len(df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month)]) / 6.0
                    out_month = float(pd.to_numeric(out_base_df[(out_base_df['Âπ¥‰ªΩ'] == cur_year) & (out_base_df['Êúà‰ªΩ'] == cur_month)]['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0
                    
                    # Year
                    scan_year = len(df_s_flt[df_s_flt['Âπ¥‰ªΩ'] == cur_year]) / 6.0
                    out_year = float(pd.to_numeric(out_base_df[out_base_df['Âπ¥‰ªΩ'] == cur_year]['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0

                    # --- Same Period Last Year (2025) ---
                    scan_day_last = len(df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == last_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month) & (df_s_flt['Êó•'] == cur_day)]) / 6.0
                    
                    # Month
                    scan_month_last = len(df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == last_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month)]) / 6.0
                    out_month_last = float(pd.to_numeric(out_base_df[(out_base_df['Âπ¥‰ªΩ'] == last_year) & (out_base_df['Êúà‰ªΩ'] == cur_month)]['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0
                    
                    # Year (YTD? or Full Year? Usually YTD for comparison or Full Year 2025)
                    # "ÂêåÊúü" usually means same period. For Year, it means 2025 Full Year or YTD.
                    # Let's use Full Year 2025 for now as 2026 is incomplete.
                    scan_year_last = len(df_s_flt[df_s_flt['Âπ¥‰ªΩ'] == last_year]) / 6.0
                    out_year_last = float(pd.to_numeric(out_base_df[out_base_df['Âπ¥‰ªΩ'] == last_year]['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0).sum()) if out_base_df is not None else 0.0

                    # Rates
                    rate_month = (scan_month / out_month) if out_month > 0 else 0
                    rate_month_last = (scan_month_last / out_month_last) if out_month_last > 0 else 0
                    rate_year = (scan_year / out_year) if out_year > 0 else 0
                    rate_year_last = (scan_year_last / out_year_last) if out_year_last > 0 else 0
                    rate_day = (scan_day / out_day) if out_day > 0 else 0
                    rate_day_last = (scan_day_last / out_day_last) if out_day_last > 0 else 0

                    tab_overview, tab_s_cat, tab_s_prov, tab_s_map = st.tabs(["üìä Êâ´Á†ÅÁéáÊ¶ÇËßà", "üß© ÂàÜÂìÅÁ±ªÊâ´Á†ÅÁéá", "üó∫Ô∏è ÁúÅÂå∫Êâ´Á†ÅÁéá", "üß≠ Âú∞ÂõæÁÉ≠Âäõ"])

                    with tab_overview:
                        st.caption(f"Âè£ÂæÑÔºö‰ªäÊó• {cur_year}Âπ¥{cur_month}Êúà{cur_day}Êó•ÔΩúÊú¨Êúà {cur_month}ÊúàÔΩúÊú¨Âπ¥ {cur_year}Âπ¥")

                        def _trend_cls(x):
                            if x is None or (isinstance(x, float) and pd.isna(x)):
                                return "trend-neutral"
                            return "trend-up" if x > 0 else ("trend-down" if x < 0 else "trend-neutral")

                        def _arrow(x):
                            if x is None or (isinstance(x, float) and pd.isna(x)):
                                return ""
                            return "‚Üë" if x > 0 else ("‚Üì" if x < 0 else "")

                        yoy_rate_day = (rate_day - rate_day_last) if out_day_last > 0 else None
                        yoy_rate_month = (rate_month - rate_month_last) if out_month_last > 0 else None
                        yoy_rate_year = (rate_year - rate_year_last) if out_year_last > 0 else None
                        yoy_rate_day_pct = (yoy_rate_day * 100.0) if yoy_rate_day is not None else None
                        yoy_rate_month_pct = (yoy_rate_month * 100.0) if yoy_rate_month is not None else None
                        yoy_rate_year_pct = (yoy_rate_year * 100.0) if yoy_rate_year is not None else None

                        c1, c2, c3 = st.columns(3)
                        with c1:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üì±</div>
                                    <div class="out-kpi-title">Êú¨Êó•Êâ´Á†ÅÁéá</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_day)}</div>
                                <div class="out-kpi-sub"><span>Âá∫Â∫ì(ÁÆ±)</span><span>{fmt_num(out_day)}</span></div>
                                <div class="out-kpi-sub"><span>Êâ´Á†Å(ÁÆ±)</span><span>{fmt_num(scan_day)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({last_year})</span><span>{fmt_num(out_day_last)} ÁÆ± / {fmt_num(scan_day_last)} ÁÆ±</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÊâ´Á†ÅÁéáÔºâ</span><span class="{_trend_cls(yoy_rate_day)}">{_arrow(yoy_rate_day)} {fmt_pct_value(yoy_rate_day_pct) if yoy_rate_day_pct is not None else "‚Äî"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c2:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üóìÔ∏è</div>
                                    <div class="out-kpi-title">Êú¨ÊúàÊâ´Á†ÅÁéá</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_month)}</div>
                                <div class="out-kpi-sub"><span>Âá∫Â∫ì(ÁÆ±)</span><span>{fmt_num(out_month)}</span></div>
                                <div class="out-kpi-sub"><span>Êâ´Á†Å(ÁÆ±)</span><span>{fmt_num(scan_month)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({last_year})</span><span>{fmt_num(out_month_last)} ÁÆ± / {fmt_num(scan_month_last)} ÁÆ±</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÊâ´Á†ÅÁéáÔºâ</span><span class="{_trend_cls(yoy_rate_month)}">{_arrow(yoy_rate_month)} {fmt_pct_value(yoy_rate_month_pct) if yoy_rate_month_pct is not None else "‚Äî"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c3:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üìà</div>
                                    <div class="out-kpi-title">Êú¨Âπ¥Êâ´Á†ÅÁéá</div>
                                </div>
                                <div class="out-kpi-val">{fmt_pct_ratio(rate_year)}</div>
                                <div class="out-kpi-sub"><span>Âá∫Â∫ì(ÁÆ±)</span><span>{fmt_num(out_year)}</span></div>
                                <div class="out-kpi-sub"><span>Êâ´Á†Å(ÁÆ±)</span><span>{fmt_num(scan_year)}</span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({last_year})</span><span>{fmt_num(out_year_last)} ÁÆ± / {fmt_num(scan_year_last)} ÁÆ±</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÊâ´Á†ÅÁéáÔºâ</span><span class="{_trend_cls(yoy_rate_year)}">{_arrow(yoy_rate_year)} {fmt_pct_value(yoy_rate_year_pct) if yoy_rate_year_pct is not None else "‚Äî"}</span></div>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    # --- Sub-Tab 1: Category ---
                    with tab_s_cat:
                        # Group by Big Category
                        
                        # --- Day Level (Sync) ---
                        s_cat_day = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month) & (df_s_flt['Êó•'] == cur_day)].groupby('‰∫ßÂìÅÂ§ßÁ±ª').size().reset_index(name='Êú¨Êó•Êâ´Á†ÅÂê¨Êï∞')
                        s_cat_day['Êú¨Êó•Êâ´Á†Å(ÁÆ±)'] = s_cat_day['Êú¨Êó•Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        o_cat_day = None
                        if out_day_df is not None:
                            if '‰∫ßÂìÅÂ§ßÁ±ª' in out_day_df.columns:
                                group_col = '‰∫ßÂìÅÂ§ßÁ±ª'
                            elif 'Â§ßÂàÜÁ±ª' in out_day_df.columns:
                                group_col = 'Â§ßÂàÜÁ±ª'
                            else:
                                group_col = None
                            qty_col_out = 'Êï∞Èáè(ÁÆ±)' if 'Êï∞Èáè(ÁÆ±)' in (out_day_df.columns if out_day_df is not None else []) else next((c for c in out_day_df.columns if 'Êï∞Èáè' in str(c) or 'ÁÆ±' in str(c)), None) if out_day_df is not None else None
                            if group_col and qty_col_out:
                                o_cat_day = out_day_df.groupby(group_col)[qty_col_out].sum().reset_index().rename(columns={group_col: '‰∫ßÂìÅÂ§ßÁ±ª', qty_col_out: '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'})
                        
                        # --- Month Level (Sync) ---
                        s_cat_month = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month)].groupby('‰∫ßÂìÅÂ§ßÁ±ª').size().reset_index(name='Êú¨ÊúàÊâ´Á†ÅÂê¨Êï∞')
                        s_cat_month['Êú¨ÊúàÊâ´Á†Å(ÁÆ±)'] = s_cat_month['Êú¨ÊúàÊâ´Á†ÅÂê¨Êï∞'] / 6.0
                        
                        o_cat_month = pd.DataFrame(columns=['‰∫ßÂìÅÂ§ßÁ±ª', 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'])
                        if out_base_df is not None:
                            group_col_m = '‰∫ßÂìÅÂ§ßÁ±ª' if '‰∫ßÂìÅÂ§ßÁ±ª' in out_base_df.columns else ('Â§ßÂàÜÁ±ª' if 'Â§ßÂàÜÁ±ª' in out_base_df.columns else None)
                            if group_col_m:
                                o_cat_month = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == cur_year) & (out_base_df['Êúà‰ªΩ'] == cur_month)].groupby(group_col_m)['Êï∞Èáè(ÁÆ±)'].sum().reset_index()
                                o_cat_month = o_cat_month.rename(columns={group_col_m: '‰∫ßÂìÅÂ§ßÁ±ª', 'Êï∞Èáè(ÁÆ±)': 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'})

                        # --- Year Level (Sync) ---
                        s_cat_year = df_s_flt[df_s_flt['Âπ¥‰ªΩ'] == cur_year].groupby('‰∫ßÂìÅÂ§ßÁ±ª').size().reset_index(name='Êú¨Âπ¥Êâ´Á†ÅÂê¨Êï∞')
                        s_cat_year['Êú¨Âπ¥Êâ´Á†Å(ÁÆ±)'] = s_cat_year['Êú¨Âπ¥Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        
                        o_cat_year = pd.DataFrame(columns=['‰∫ßÂìÅÂ§ßÁ±ª', 'Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)'])
                        if out_base_df is not None:
                            group_col_y = '‰∫ßÂìÅÂ§ßÁ±ª' if '‰∫ßÂìÅÂ§ßÁ±ª' in out_base_df.columns else ('Â§ßÂàÜÁ±ª' if 'Â§ßÂàÜÁ±ª' in out_base_df.columns else None)
                            if group_col_y:
                                o_cat_year = out_base_df[out_base_df['Âπ¥‰ªΩ'] == cur_year].groupby(group_col_y)['Êï∞Èáè(ÁÆ±)'].sum().reset_index()
                                o_cat_year = o_cat_year.rename(columns={group_col_y: '‰∫ßÂìÅÂ§ßÁ±ª', 'Êï∞Èáè(ÁÆ±)': 'Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)'})
                            
                        # Merge All
                        cat_final = pd.merge(s_cat_day[['‰∫ßÂìÅÂ§ßÁ±ª', 'Êú¨Êó•Êâ´Á†Å(ÁÆ±)']], s_cat_month[['‰∫ßÂìÅÂ§ßÁ±ª', 'Êú¨ÊúàÊâ´Á†Å(ÁÆ±)']], on='‰∫ßÂìÅÂ§ßÁ±ª', how='outer')
                        if o_cat_day is not None:
                            cat_final = pd.merge(cat_final, o_cat_day, on='‰∫ßÂìÅÂ§ßÁ±ª', how='outer')
                        cat_final = pd.merge(cat_final, o_cat_month, on='‰∫ßÂìÅÂ§ßÁ±ª', how='outer')
                        cat_final = pd.merge(cat_final, s_cat_year[['‰∫ßÂìÅÂ§ßÁ±ª', 'Êú¨Âπ¥Êâ´Á†Å(ÁÆ±)']], on='‰∫ßÂìÅÂ§ßÁ±ª', how='outer')
                        cat_final = pd.merge(cat_final, o_cat_year, on='‰∫ßÂìÅÂ§ßÁ±ª', how='outer').fillna(0)
                        
                        # Calculate Rates
                        # Day Rate: Outbound usually monthly, so Day Rate might not be accurate unless assumed uniform or N/A
                        # User requirement: "Êú¨Êó•„ÄÅÊú¨ÊúàÁöÑÁª¥Â∫¶Ôºå‰πüÈúÄË¶ÅÂä†Âà∞ÂàÜÂìÅÁ±ªÂíåÂàÜÁúÅÂå∫". 
                        # Let's show Day Scan Qty. Day Rate is tricky without Day Outbound. We will show Day Scan Qty only or N/A for Rate.
                        # Month Rate
                        cat_final['Êú¨ÊúàÊâ´Á†ÅÁéá'] = cat_final.apply(lambda x: x['Êú¨ÊúàÊâ´Á†Å(ÁÆ±)'] / x['Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'] if x['Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        # Year Rate
                        cat_final['Êú¨Âπ¥Êâ´Á†ÅÁéá'] = cat_final.apply(lambda x: x['Êú¨Âπ¥Êâ´Á†Å(ÁÆ±)'] / x['Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)'] if x['Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        # Day Rate
                        if '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)' in cat_final.columns:
                            cat_final['Êú¨Êó•Êâ´Á†ÅÁéá'] = cat_final.apply(lambda x: x['Êú¨Êó•Êâ´Á†Å(ÁÆ±)'] / x['‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'] if x['‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        else:
                            cat_final['‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'] = 0.0
                            cat_final['Êú¨Êó•Êâ´Á†ÅÁéá'] = 0.0
                        
                        cat_final = cat_final.sort_values('Êú¨ÊúàÊâ´Á†Å(ÁÆ±)', ascending=False)
                        
                        # Format for display
                        # Display
                        cat_disp = cat_final[['‰∫ßÂìÅÂ§ßÁ±ª', '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)', 'Êú¨Êó•Êâ´Á†Å(ÁÆ±)', 'Êú¨Êó•Êâ´Á†ÅÁéá', 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†Å(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†ÅÁéá', 'Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)', 'Êú¨Âπ¥Êâ´Á†Å(ÁÆ±)', 'Êú¨Âπ¥Êâ´Á†ÅÁéá']].copy()
                        cat_disp = cat_disp.rename(columns={'Êú¨Êó•Êâ´Á†Å(ÁÆ±)': '‰ªäÊó•Êâ´Á†Å(ÁÆ±)'})
                        cat_column_defs = [
                            {"headerName": "‰∫ßÂìÅÂ§ßÁ±ª", "field": "‰∫ßÂìÅÂ§ßÁ±ª", "pinned": "left", "minWidth": 120},
                            {"headerName": f"‰ªäÊó•Ôºà{cur_month}Êúà{cur_day}Êó•Ôºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "‰ªäÊó•Âá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "‰ªäÊó•Êâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "Êú¨Êó•Êâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"Êú¨ÊúàÔºà{cur_month}ÊúàÔºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "Êú¨ÊúàÊâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "Êú¨ÊúàÊâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"Êú¨Âπ¥Ôºà{cur_year}Âπ¥Ôºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "Êú¨Âπ¥Âá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "Êú¨Âπ¥Êâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "Êú¨Âπ¥Êâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                        ]

                        show_aggrid_table(cat_disp, key="scan_cat_ag", column_defs=cat_column_defs)

                    # --- Sub-Tab 2: Province ---
                    with tab_s_prov:
                        # --- Day Level ---
                        s_prov_day = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month) & (df_s_flt['Êó•'] == cur_day)].groupby('ÁúÅÂå∫').size().reset_index(name='Êú¨Êó•Êâ´Á†ÅÂê¨Êï∞')
                        s_prov_day['Êú¨Êó•Êâ´Á†Å(ÁÆ±)'] = s_prov_day['Êú¨Êó•Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        o_prov_day = None
                        if out_day_df is not None:
                            o_prov_day = out_day_df.groupby('ÁúÅÂå∫')['Êï∞Èáè(ÁÆ±)'].sum().reset_index().rename(columns={'Êï∞Èáè(ÁÆ±)': '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'})

                        # --- Month Level (Current) ---
                        s_prov_cur = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == cur_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month)].groupby('ÁúÅÂå∫').size().reset_index(name='Êâ´Á†ÅÂê¨Êï∞')
                        s_prov_cur['Êâ´Á†ÅÁÆ±Êï∞'] = s_prov_cur['Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        o_prov_cur = pd.DataFrame(columns=['ÁúÅÂå∫', 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'])
                        if out_base_df is not None:
                            o_prov_cur = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == cur_year) & (out_base_df['Êúà‰ªΩ'] == cur_month)].groupby('ÁúÅÂå∫')['Êï∞Èáè(ÁÆ±)'].sum().reset_index().rename(columns={'Êï∞Èáè(ÁÆ±)': 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'})
                        prov_cur = pd.merge(s_prov_cur[['ÁúÅÂå∫', 'Êâ´Á†ÅÁÆ±Êï∞']], o_prov_cur, on='ÁúÅÂå∫', how='outer').fillna(0)
                        prov_cur['Êú¨ÊúàÊâ´Á†Å(ÁÆ±)'] = prov_cur['Êâ´Á†ÅÁÆ±Êï∞']
                        prov_cur['Êú¨ÊúàÊâ´Á†ÅÁéá'] = prov_cur.apply(lambda x: x['Êú¨ÊúàÊâ´Á†Å(ÁÆ±)'] / x['Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'] if x['Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        prov_cur = prov_cur[['ÁúÅÂå∫', 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†Å(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†ÅÁéá']]

                        # --- Same Period Last Year (Month) ---
                        s_prov_last = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == last_year) & (df_s_flt['Êúà‰ªΩ'] == cur_month)].groupby('ÁúÅÂå∫').size().reset_index(name='Êâ´Á†ÅÂê¨Êï∞')
                        s_prov_last['Êâ´Á†ÅÁÆ±Êï∞'] = s_prov_last['Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        o_prov_last = pd.DataFrame(columns=['ÁúÅÂå∫', 'ÂêåÊúüÂá∫Â∫ì(ÁÆ±)'])
                        if out_base_df is not None:
                            o_prov_last = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == last_year) & (out_base_df['Êúà‰ªΩ'] == cur_month)].groupby('ÁúÅÂå∫')['Êï∞Èáè(ÁÆ±)'].sum().reset_index().rename(columns={'Êï∞Èáè(ÁÆ±)': 'ÂêåÊúüÂá∫Â∫ì(ÁÆ±)'})
                        prov_last = pd.merge(s_prov_last[['ÁúÅÂå∫', 'Êâ´Á†ÅÁÆ±Êï∞']], o_prov_last, on='ÁúÅÂå∫', how='outer').fillna(0)
                        prov_last['ÂêåÊúüÊâ´Á†Å(ÁÆ±)'] = prov_last['Êâ´Á†ÅÁÆ±Êï∞']
                        prov_last['ÂêåÊúüÊâ´Á†ÅÁéá'] = prov_last.apply(lambda x: x['ÂêåÊúüÊâ´Á†Å(ÁÆ±)'] / x['ÂêåÊúüÂá∫Â∫ì(ÁÆ±)'] if x['ÂêåÊúüÂá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        prov_last = prov_last[['ÁúÅÂå∫', 'ÂêåÊúüÂá∫Â∫ì(ÁÆ±)', 'ÂêåÊúüÊâ´Á†Å(ÁÆ±)', 'ÂêåÊúüÊâ´Á†ÅÁéá']]

                        # --- Ring Period (Month) ---
                        if cur_month == 1:
                            ring_year = cur_year - 1
                            ring_month = 12
                        else:
                            ring_year = cur_year
                            ring_month = cur_month - 1

                        s_prov_ring = df_s_flt[(df_s_flt['Âπ¥‰ªΩ'] == ring_year) & (df_s_flt['Êúà‰ªΩ'] == ring_month)].groupby('ÁúÅÂå∫').size().reset_index(name='Êâ´Á†ÅÂê¨Êï∞')
                        s_prov_ring['Êâ´Á†ÅÁÆ±Êï∞'] = s_prov_ring['Êâ´Á†ÅÂê¨Êï∞'] / 6.0
                        o_prov_ring = pd.DataFrame(columns=['ÁúÅÂå∫', 'ÁéØÊØîÂá∫Â∫ì(ÁÆ±)'])
                        if out_base_df is not None:
                            o_prov_ring = out_base_df[(out_base_df['Âπ¥‰ªΩ'] == ring_year) & (out_base_df['Êúà‰ªΩ'] == ring_month)].groupby('ÁúÅÂå∫')['Êï∞Èáè(ÁÆ±)'].sum().reset_index().rename(columns={'Êï∞Èáè(ÁÆ±)': 'ÁéØÊØîÂá∫Â∫ì(ÁÆ±)'})
                        prov_ring = pd.merge(s_prov_ring[['ÁúÅÂå∫', 'Êâ´Á†ÅÁÆ±Êï∞']], o_prov_ring, on='ÁúÅÂå∫', how='outer').fillna(0)
                        prov_ring['ÁéØÊØîÊâ´Á†Å(ÁÆ±)'] = prov_ring['Êâ´Á†ÅÁÆ±Êï∞']
                        prov_ring['ÁéØÊØîÊâ´Á†ÅÁéá'] = prov_ring.apply(lambda x: x['ÁéØÊØîÊâ´Á†Å(ÁÆ±)'] / x['ÁéØÊØîÂá∫Â∫ì(ÁÆ±)'] if x['ÁéØÊØîÂá∫Â∫ì(ÁÆ±)'] > 0 else 0, axis=1)
                        prov_ring = prov_ring[['ÁúÅÂå∫', 'ÁéØÊØîÊâ´Á†ÅÁéá']]

                        # Merge All
                        prov_final = pd.merge(prov_cur, s_prov_day[['ÁúÅÂå∫', 'Êú¨Êó•Êâ´Á†Å(ÁÆ±)']], on='ÁúÅÂå∫', how='outer')
                        if o_prov_day is not None:
                            prov_final = pd.merge(prov_final, o_prov_day, on='ÁúÅÂå∫', how='outer')
                        prov_final = pd.merge(prov_final, prov_last[['ÁúÅÂå∫', 'ÂêåÊúüÂá∫Â∫ì(ÁÆ±)', 'ÂêåÊúüÊâ´Á†Å(ÁÆ±)', 'ÂêåÊúüÊâ´Á†ÅÁéá']], on='ÁúÅÂå∫', how='outer')
                        prov_final = pd.merge(prov_final, prov_ring[['ÁúÅÂå∫', 'ÁéØÊØîÊâ´Á†ÅÁéá']], on='ÁúÅÂå∫', how='left').fillna(0)
                        prov_final['ÁéØÊØîÂ¢ûÈïø'] = prov_final['Êú¨ÊúàÊâ´Á†ÅÁéá'] - prov_final['ÁéØÊØîÊâ´Á†ÅÁéá']
                        if '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)' not in prov_final.columns:
                            prov_final['‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'] = 0.0
                        prov_final['Êú¨Êó•Êâ´Á†ÅÁéá'] = prov_final.apply(lambda x: x['Êú¨Êó•Êâ´Á†Å(ÁÆ±)'] / x['‰ªäÊó•Âá∫Â∫ì(ÁÆ±)'] if x.get('‰ªäÊó•Âá∫Â∫ì(ÁÆ±)', 0) > 0 else 0, axis=1)

                        prov_disp = prov_final[['ÁúÅÂå∫', 'Êú¨Êó•Êâ´Á†Å(ÁÆ±)', '‰ªäÊó•Âá∫Â∫ì(ÁÆ±)', 'Êú¨Êó•Êâ´Á†ÅÁéá', 'Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†Å(ÁÆ±)', 'Êú¨ÊúàÊâ´Á†ÅÁéá', 'ÂêåÊúüÂá∫Â∫ì(ÁÆ±)', 'ÂêåÊúüÊâ´Á†Å(ÁÆ±)', 'ÂêåÊúüÊâ´Á†ÅÁéá', 'ÁéØÊØîÊâ´Á†ÅÁéá', 'ÁéØÊØîÂ¢ûÈïø']].copy()
                        prov_disp = prov_disp.sort_values('Êú¨ÊúàÊâ´Á†Å(ÁÆ±)', ascending=False)
                        prov_disp = prov_disp.rename(columns={'Êú¨Êó•Êâ´Á†Å(ÁÆ±)': '‰ªäÊó•Êâ´Á†Å(ÁÆ±)'})
                        prov_column_defs = [
                            {"headerName": "ÁúÅÂå∫", "field": "ÁúÅÂå∫", "pinned": "left", "minWidth": 110},
                            {"headerName": f"‰ªäÊó•Ôºà{cur_month}Êúà{cur_day}Êó•Ôºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "‰ªäÊó•Âá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "‰ªäÊó•Êâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "Êú¨Êó•Êâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"Êú¨ÊúàÔºà{cur_month}ÊúàÔºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "Êú¨ÊúàÂá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "Êú¨ÊúàÊâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "Êú¨ÊúàÊâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": f"ÂêåÊúüÔºà{last_year}Âπ¥{cur_month}ÊúàÔºâ", "children": [
                                {"headerName": "Âá∫Â∫ì(ÁÆ±)", "field": "ÂêåÊúüÂá∫Â∫ì(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†Å(ÁÆ±)", "field": "ÂêåÊúüÊâ´Á†Å(ÁÆ±)", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_NUM},
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "ÂêåÊúüÊâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                            ]},
                            {"headerName": "ÁéØÊØî", "children": [
                                {"headerName": "Êâ´Á†ÅÁéá", "field": "ÁéØÊØîÊâ´Á†ÅÁéá", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO},
                                {"headerName": "Â¢ûÈïø", "field": "ÁéØÊØîÂ¢ûÈïø", "type": ["numericColumn", "numberColumnFilter"], "valueFormatter": JS_FMT_PCT_RATIO, "cellStyle": JS_COLOR_CONDITIONAL},
                            ]},
                        ]

                        show_aggrid_table(prov_disp, key="scan_prov_ag", column_defs=prov_column_defs)

                    with tab_s_map:
                        if ("ÁªèÂ∫¶" not in df_s_flt.columns) or ("Á∫¨Â∫¶" not in df_s_flt.columns):
                            st.info("Êú™Ê£ÄÊµãÂà∞ÁªèÁ∫¨Â∫¶ÂàóÔºöËØ∑Á°ÆËÆ§Êâ´Á†ÅÊï∞ÊçÆSheetÁöÑMÂàó‰∏∫ÁªèÁ∫¨Â∫¶ÔºàÂΩ¢Â¶Ç 116.4,39.9 Êàñ 39.9,116.4Ôºâ„ÄÇ")
                        else:
                            c_map1, c_map2, c_map3 = st.columns([1.1, 1.1, 1.2])
                            metric_mode = c_map1.radio("ÂØπÊØîÂè£ÂæÑ", ["Êâ´Á†ÅÊï∞", "Êâ´Á†ÅÁéá"], horizontal=True, key="scan_map_metric_mode")
                            period_mode = c_map2.radio("Êó∂Èó¥ËåÉÂõ¥", ["‰ªäÊó•", "Êú¨Êúà", "Êú¨Âπ¥"], horizontal=True, key="scan_map_period")
                            style_mode = c_map3.radio("Âú∞ÂõæÊ†∑Âºè", ["ËØ¶ÁªÜ", "ÁÆÄÊ¥Å"], horizontal=True, key="scan_map_style_mode")

                            c_map4, c_map5 = st.columns([1.3, 1.0])
                            prov_opts_map = ["ÂÖ®ÂõΩ"] + sorted([p for p in df_s_flt["ÁúÅÂå∫"].unique().tolist() if str(p).strip() != ""])
                            focus_prov = c_map4.selectbox("ÁúÅÂå∫ËÅöÁÑ¶", prov_opts_map, key="scan_map_focus_prov")
                            palette_mode = c_map5.radio("ÈÖçËâ≤", ["È´òÂØπÊØî", "Ëâ≤Áõ≤ÂèãÂ•Ω"], horizontal=True, key="scan_map_palette")

                            c_map6, c_map7 = st.columns([1.2, 1.1])
                            basemap_provider = c_map6.selectbox("Â∫ïÂõæÊù•Ê∫ê", ["È´òÂæ∑(ÂõΩÂÜÖ)", "OpenStreetMap(Â§ñÁΩë)", "Êó†Â∫ïÂõæ(Á¶ªÁ∫ø)", "Ëá™ÂÆö‰πâÁì¶Áâá(ÂÜÖÁΩë/Ëá™Âª∫)"], key="scan_map_basemap_provider")
                            custom_tile_url = ""
                            if basemap_provider == "Ëá™ÂÆö‰πâÁì¶Áâá(ÂÜÖÁΩë/Ëá™Âª∫)":
                                custom_tile_url = c_map7.text_input("Áì¶ÁâáURLÊ®°Êùø", value="http://127.0.0.1:8080/{z}/{x}/{y}.png", key="scan_map_custom_tile_url")
                            else:
                                c_map7.write("")

                            show_cb_key = "scan_map_show_colorbar"
                            if show_cb_key not in st.session_state:
                                st.session_state[show_cb_key] = False
                            cb_label = "ÊòæÁ§∫È¢úËâ≤ÂàªÂ∫¶" if not st.session_state[show_cb_key] else "ÈöêËóèÈ¢úËâ≤ÂàªÂ∫¶"
                            if st.button(cb_label, key="scan_map_toggle_colorbar"):
                                st.session_state[show_cb_key] = not bool(st.session_state[show_cb_key])
                                st.rerun()

                            df_map = df_s_flt.copy()
                            if period_mode == "‰ªäÊó•":
                                df_map = df_map[(df_map["Âπ¥‰ªΩ"] == cur_year) & (df_map["Êúà‰ªΩ"] == cur_month) & (df_map["Êó•"] == cur_day)]
                            elif period_mode == "Êú¨Êúà":
                                df_map = df_map[(df_map["Âπ¥‰ªΩ"] == cur_year) & (df_map["Êúà‰ªΩ"] == cur_month)]
                            else:
                                df_map = df_map[df_map["Âπ¥‰ªΩ"] == cur_year]

                            if focus_prov != "ÂÖ®ÂõΩ":
                                df_map = df_map[df_map["ÁúÅÂå∫"] == focus_prov]

                            df_map = df_map.dropna(subset=["ÁªèÂ∫¶", "Á∫¨Â∫¶"])
                            df_map = df_map[df_map["ÁªèÂ∫¶"].between(70, 140) & df_map["Á∫¨Â∫¶"].between(0, 60)]

                            if df_map.empty:
                                st.info("ÂΩìÂâçÁ≠õÈÄâ‰∏éÂè£ÂæÑ‰∏ãÊ≤°ÊúâÂèØÁî®ÁöÑÁªèÁ∫¨Â∫¶Êï∞ÊçÆ„ÄÇ")
                            else:
                                center_lat = float(df_map["Á∫¨Â∫¶"].mean())
                                center_lon = float(df_map["ÁªèÂ∫¶"].mean())
                                default_zoom = 3.1 if focus_prov == "ÂÖ®ÂõΩ" else 4.9
                                min_zoom, max_zoom = 2.2, 10.5

                                zoom_key = "scan_map_zoom"
                                if zoom_key not in st.session_state:
                                    st.session_state[zoom_key] = default_zoom
                                if st.session_state[zoom_key] < min_zoom or st.session_state[zoom_key] > max_zoom:
                                    st.session_state[zoom_key] = default_zoom

                                zc1, zc2, zc3, zc4 = st.columns([0.13, 0.13, 0.18, 0.56])
                                if zc1.button("Ôºã", key="scan_map_zoom_in"):
                                    st.session_state[zoom_key] = min(max_zoom, float(st.session_state[zoom_key]) + 0.6)
                                    st.rerun()
                                if zc2.button("Ôºç", key="scan_map_zoom_out"):
                                    st.session_state[zoom_key] = max(min_zoom, float(st.session_state[zoom_key]) - 0.6)
                                    st.rerun()
                                if zc3.button("Â§ç‰Ωç", key="scan_map_zoom_reset"):
                                    st.session_state[zoom_key] = default_zoom
                                    st.rerun()
                                zc4.slider("Áº©Êîæ", min_value=min_zoom, max_value=max_zoom, value=float(st.session_state[zoom_key]), step=0.1, key=zoom_key)

                                basemap_layers = None
                                if basemap_provider == "OpenStreetMap(Â§ñÁΩë)":
                                    map_style = "carto-positron" if style_mode == "ÁÆÄÊ¥Å" else "open-street-map"
                                elif basemap_provider == "È´òÂæ∑(ÂõΩÂÜÖ)":
                                    map_style = "white-bg"
                                    gaode_style = "7" if style_mode == "ËØ¶ÁªÜ" else "8"
                                    gaode_url = f"https://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&size=1&scale=1&style={gaode_style}&x={{x}}&y={{y}}&z={{z}}"
                                    basemap_layers = [{"sourcetype": "raster", "source": [gaode_url], "below": "traces"}]
                                elif basemap_provider == "Ëá™ÂÆö‰πâÁì¶Áâá(ÂÜÖÁΩë/Ëá™Âª∫)":
                                    map_style = "white-bg"
                                    _u = (custom_tile_url or "").strip()
                                    if _u:
                                        basemap_layers = [{"sourcetype": "raster", "source": [_u], "below": "traces"}]
                                else:
                                    map_style = "white-bg"
                                marker_opacity = 0.86
                                color_scale_count = "Turbo" if palette_mode == "È´òÂØπÊØî" else "Cividis"
                                color_scale_rate = "Viridis" if palette_mode == "È´òÂØπÊØî" else "Cividis"
                                point_scale = [
                                    [0.0, "#00C853"],
                                    [0.35, "#00C853"],
                                    [0.65, "#FFEB3B"],
                                    [0.82, "#FF9800"],
                                    [1.0, "#F44336"],
                                ]

                                if metric_mode == "Êâ´Á†ÅÊï∞":
                                    c_u1, c_u2 = st.columns([0.55, 0.45])
                                    unit_mode = c_u1.radio("Âçï‰Ωç", ["Âê¨", "ÁÆ±"], horizontal=True, key="scan_map_unit")
                                    render_mode = c_u2.radio("Ê∏≤ÊüìÊñπÂºè", ["ÁÉ≠Âäõ", "Ê†áÁÇπ"], horizontal=True, key="scan_map_render_mode")
                                    precision = st.slider("ÂùêÊ†áËÅöÂêàÁ≤æÂ∫¶(Â∞èÊï∞‰Ωç)", 0, 3, 2, key="scan_map_precision")
                                    df_grid = df_map[["ÁªèÂ∫¶", "Á∫¨Â∫¶"]].copy()
                                    df_grid["ÁªèÂ∫¶"] = df_grid["ÁªèÂ∫¶"].round(int(precision))
                                    df_grid["Á∫¨Â∫¶"] = df_grid["Á∫¨Â∫¶"].round(int(precision))
                                    df_grid = df_grid.groupby(["ÁªèÂ∫¶", "Á∫¨Â∫¶"]).size().reset_index(name="Êâ´Á†ÅÂê¨Êï∞")
                                    df_grid["Êâ´Á†ÅÁÆ±Êï∞"] = df_grid["Êâ´Á†ÅÂê¨Êï∞"] / 6.0
                                    val_col = "Êâ´Á†ÅÂê¨Êï∞" if unit_mode == "Âê¨" else "Êâ´Á†ÅÁÆ±Êï∞"

                                    if render_mode == "ÁÉ≠Âäõ":
                                        fig = px.density_mapbox(
                                            df_grid,
                                            lat="Á∫¨Â∫¶",
                                            lon="ÁªèÂ∫¶",
                                            z=val_col,
                                            radius=18 if focus_prov == "ÂÖ®ÂõΩ" else 14,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=color_scale_count,
                                            hover_data={"Êâ´Á†ÅÂê¨Êï∞": ":,.0f", "Êâ´Á†ÅÁÆ±Êï∞": ":,.2f"}
                                        )
                                        fig.update_traces(opacity=0.82)
                                    else:
                                        fig = px.scatter_mapbox(
                                            df_grid,
                                            lat="Á∫¨Â∫¶",
                                            lon="ÁªèÂ∫¶",
                                            color=val_col,
                                            size=val_col,
                                            size_max=26,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=point_scale,
                                            hover_data={"Êâ´Á†ÅÂê¨Êï∞": ":,.0f", "Êâ´Á†ÅÁÆ±Êï∞": ":,.2f"}
                                        )
                                        fig.update_traces(marker={"opacity": marker_opacity})

                                    _layout_kwargs = {
                                        "mapbox_style": map_style,
                                        "margin": {"r": 0, "t": 0, "l": 0, "b": 0},
                                        "transition": {"duration": 260, "easing": "cubic-in-out"},
                                    }
                                    if basemap_layers is not None:
                                        _layout_kwargs["mapbox_layers"] = basemap_layers
                                    fig.update_layout(**_layout_kwargs)
                                    show_cb = bool(st.session_state.get(show_cb_key, False))
                                    cb_style = {"thickness": 10, "len": 0.55, "x": 1.0, "xpad": 0, "y": 0.5, "bgcolor": "rgba(255,255,255,0.25)", "outlinewidth": 0, "title": {"text": ""}}
                                    for _ax_name in [k for k in fig.layout if str(k).startswith("coloraxis")]:
                                        try:
                                            fig.layout[_ax_name].showscale = show_cb
                                        except Exception:
                                            pass
                                        if show_cb:
                                            try:
                                                fig.layout[_ax_name].colorbar = cb_style
                                            except Exception:
                                                pass
                                    for _t in fig.data:
                                        try:
                                            _t.update(showscale=show_cb)
                                        except Exception:
                                            pass
                                    st.plotly_chart(
                                        fig,
                                        use_container_width=True,
                                        config={"scrollZoom": True, "displayModeBar": True, "displaylogo": False, "responsive": True}
                                    )
                                else:
                                    render_mode_rate = st.radio("Ê∏≤ÊüìÊñπÂºè", ["ÁÉ≠Âäõ", "Ê†áÁÇπ"], horizontal=True, key="scan_map_render_mode_rate")
                                    scan_by_prov = df_map.groupby("ÁúÅÂå∫").size().reset_index(name="Êâ´Á†ÅÂê¨Êï∞")
                                    scan_by_prov["Êâ´Á†ÅÁÆ±Êï∞"] = scan_by_prov["Êâ´Á†ÅÂê¨Êï∞"] / 6.0
                                    cent = df_map.groupby("ÁúÅÂå∫")[["ÁªèÂ∫¶", "Á∫¨Â∫¶"]].mean().reset_index()
                                    prov_map = pd.merge(scan_by_prov, cent, on="ÁúÅÂå∫", how="left")
                                    prov_map["Âá∫Â∫ì(ÁÆ±)"] = 0.0

                                    if out_base_df is not None and not getattr(out_base_df, "empty", True) and ("ÁúÅÂå∫" in out_base_df.columns) and ("Êï∞Èáè(ÁÆ±)" in out_base_df.columns):
                                        out_map = out_base_df.copy()
                                        if period_mode == "‰ªäÊó•":
                                            out_map = out_map[(out_map["Âπ¥‰ªΩ"] == cur_year) & (out_map["Êúà‰ªΩ"] == cur_month) & (out_map["Êó•"] == cur_day)]
                                        elif period_mode == "Êú¨Êúà":
                                            out_map = out_map[(out_map["Âπ¥‰ªΩ"] == cur_year) & (out_map["Êúà‰ªΩ"] == cur_month)]
                                        else:
                                            out_map = out_map[out_map["Âπ¥‰ªΩ"] == cur_year]
                                        out_prov = out_map.groupby("ÁúÅÂå∫")["Êï∞Èáè(ÁÆ±)"].sum().reset_index().rename(columns={"Êï∞Èáè(ÁÆ±)": "Âá∫Â∫ì(ÁÆ±)"})
                                        prov_map = pd.merge(prov_map.drop(columns=["Âá∫Â∫ì(ÁÆ±)"], errors="ignore"), out_prov, on="ÁúÅÂå∫", how="left")
                                        prov_map["Âá∫Â∫ì(ÁÆ±)"] = pd.to_numeric(prov_map.get("Âá∫Â∫ì(ÁÆ±)"), errors="coerce").fillna(0.0)

                                    prov_map["Êâ´Á†ÅÁéá"] = prov_map.apply(lambda x: x["Êâ´Á†ÅÁÆ±Êï∞"] / x["Âá∫Â∫ì(ÁÆ±)"] if x["Âá∫Â∫ì(ÁÆ±)"] > 0 else None, axis=1)
                                    prov_map = prov_map.dropna(subset=["ÁªèÂ∫¶", "Á∫¨Â∫¶"])

                                    if render_mode_rate == "ÁÉ≠Âäõ":
                                        fig = px.density_mapbox(
                                            prov_map.dropna(subset=["Êâ´Á†ÅÁéá"]),
                                            lat="Á∫¨Â∫¶",
                                            lon="ÁªèÂ∫¶",
                                            z="Êâ´Á†ÅÁéá",
                                            radius=36 if focus_prov == "ÂÖ®ÂõΩ" else 24,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=color_scale_rate,
                                            hover_data={"ÁúÅÂå∫": True, "Êâ´Á†ÅÂê¨Êï∞": ":,.0f", "Êâ´Á†ÅÁÆ±Êï∞": ":,.2f", "Âá∫Â∫ì(ÁÆ±)": ":,.0f", "Êâ´Á†ÅÁéá": ":.2%"}
                                        )
                                        fig.update_traces(opacity=0.82)
                                    else:
                                        fig = px.scatter_mapbox(
                                            prov_map,
                                            lat="Á∫¨Â∫¶",
                                            lon="ÁªèÂ∫¶",
                                            color="Êâ´Á†ÅÁéá",
                                            size="Êâ´Á†ÅÁÆ±Êï∞",
                                            size_max=42,
                                            zoom=float(st.session_state[zoom_key]),
                                            center={"lat": center_lat, "lon": center_lon},
                                            color_continuous_scale=point_scale,
                                            hover_name="ÁúÅÂå∫",
                                            hover_data={"Êâ´Á†ÅÂê¨Êï∞": ":,.0f", "Êâ´Á†ÅÁÆ±Êï∞": ":,.2f", "Âá∫Â∫ì(ÁÆ±)": ":,.0f", "Êâ´Á†ÅÁéá": ":.2%"}
                                        )
                                        fig.update_traces(marker={"opacity": marker_opacity})
                                    _layout_kwargs = {
                                        "mapbox_style": map_style,
                                        "margin": {"r": 0, "t": 0, "l": 0, "b": 0},
                                        "transition": {"duration": 260, "easing": "cubic-in-out"},
                                    }
                                    if basemap_layers is not None:
                                        _layout_kwargs["mapbox_layers"] = basemap_layers
                                    fig.update_layout(**_layout_kwargs)
                                    show_cb = bool(st.session_state.get(show_cb_key, False))
                                    cb_style = {"thickness": 10, "len": 0.55, "x": 1.0, "xpad": 0, "y": 0.5, "bgcolor": "rgba(255,255,255,0.25)", "outlinewidth": 0, "title": {"text": ""}}
                                    for _ax_name in [k for k in fig.layout if str(k).startswith("coloraxis")]:
                                        try:
                                            fig.layout[_ax_name].showscale = show_cb
                                        except Exception:
                                            pass
                                        if show_cb:
                                            try:
                                                fig.layout[_ax_name].colorbar = cb_style
                                            except Exception:
                                                pass
                                    for _t in fig.data:
                                        try:
                                            _t.update(showscale=show_cb)
                                        except Exception:
                                            pass
                                    st.plotly_chart(
                                        fig,
                                        use_container_width=True,
                                        config={"scrollZoom": True, "displayModeBar": True, "displaylogo": False, "responsive": True}
                                    )

                else:
                    st.info("ËØ∑Âú®Excel‰∏≠ÂåÖÂê´Á¨¨6‰∏™SheetÔºàÊâ´Á†ÅÊï∞ÊçÆÔºâ‰ª•Êü•ÁúãÊ≠§ÂàÜÊûê„ÄÇ")

            # === TAB 3: ABCD ANALYSIS ===
            with tab3:
                st.subheader("üìä Q3 vs Q4 Èó®Â∫óÊïàËÉΩÂØπÊØîÂàÜÊûê")
                
                # Check for Q3/Q4 columns
                q3_cols = [c for c in month_cols if c in ['7Êúà', '8Êúà', '9Êúà']]
                q4_cols = [c for c in month_cols if c in ['10Êúà', '11Êúà', '12Êúà']]
                
                if not q3_cols or not q4_cols:
                    st.warning("‚ö†Ô∏è Êï∞ÊçÆÊ∫êÁº∫Â§±7-12ÊúàÁöÑÂÆåÊï¥Êï∞ÊçÆÔºåÊó†Ê≥ïËøõË°åQ3 vs Q4ÂØπÊØîÂàÜÊûê")
                else:
                    # Logic
                    # Calculate Q3 Class
                    df['Q3_Sum'] = df[q3_cols].sum(axis=1)
                    df['Q3_Avg'] = df['Q3_Sum'] / 3
                    
                    # Calculate Q4 Class
                    df['Q4_Sum'] = df[q4_cols].sum(axis=1)
                    df['Q4_Avg'] = df['Q4_Sum'] / 3
                    
                    def classify_score(x):
                        if x >= 4: return 'A'
                        elif 2 <= x < 4: return 'B'
                        elif 1 <= x < 2: return 'C'
                        else: return 'D'
                        
                    df['Class_Q3'] = df['Q3_Avg'].apply(classify_score)
                    df['Class_Q4'] = df['Q4_Avg'].apply(classify_score)
                    
                    # Comparison Metrics
                    q3_counts = df['Class_Q3'].value_counts().sort_index()
                    q4_counts = df['Class_Q4'].value_counts().sort_index()
                    
                    # Overview Cards
                    c1, c2, c3, c4 = st.columns(4)
                    
                    def render_metric(col, cls_label):
                        curr = q4_counts.get(cls_label, 0)
                        prev = q3_counts.get(cls_label, 0)
                        delta = curr - prev
                        col.metric(f"{cls_label}Á±ªÈó®Â∫ó (Q4)", fmt_num(curr), f"{fmt_num(delta)} (ÁéØÊØî)")
                        
                    render_metric(c1, 'A')
                    render_metric(c2, 'B')
                    render_metric(c3, 'C')
                    render_metric(c4, 'D')
                    
                    st.markdown("---")
                    
                    # Province Comparison Chart
                    st.subheader("üó∫Ô∏è ÂêÑÁúÅÂå∫ABCDÁ±ªÈó®Â∫óÊï∞ÈáèÂØπÊØî (Q3 vs Q4)")
                    
                    # Prepare Data for Chart
                    # Group by Province and Class for Q3
                    prov_q3 = df.groupby(['ÁúÅÂå∫', 'Class_Q3']).size().reset_index(name='Count')
                    prov_q3['Period'] = 'Q3'
                    prov_q3.rename(columns={'Class_Q3': 'Class'}, inplace=True)
                    
                    # Group by Province and Class for Q4
                    prov_q4 = df.groupby(['ÁúÅÂå∫', 'Class_Q4']).size().reset_index(name='Count')
                    prov_q4['Period'] = 'Q4'
                    prov_q4.rename(columns={'Class_Q4': 'Class'}, inplace=True)
                    
                    # Combine
                    prov_comp = pd.concat([prov_q3, prov_q4])
                    
                    # Interactive Selection
                    sel_period = st.radio("ÈÄâÊã©Â±ïÁ§∫Âë®Êúü:", ["Q4 (Êú¨Êúü)", "Q3 (‰∏äÊúü)"], horizontal=True)
                    target_period = 'Q4' if 'Q4' in sel_period else 'Q3'
                    
                    chart_data = prov_comp[prov_comp['Period'] == target_period]
                    
                    fig_bar_prov_class = px.bar(chart_data, x='ÁúÅÂå∫', y='Count', color='Class',
                                               title=f"ÂêÑÁúÅÂå∫Èó®Â∫óÁ≠âÁ∫ßÂàÜÂ∏É ({target_period})",
                                               category_orders={"Class": ["A", "B", "C", "D"]},
                                               color_discrete_map={'A':'#FFC400', 'B':'#6A3AD0', 'C':'#B79BFF', 'D':'#8A8AA3'},
                                               text='Count')
                    fig_bar_prov_class.update_traces(textposition='inside', texttemplate='%{y:,.1~f}', hovertemplate='ÁúÅÂå∫: %{x}<br>Êï∞Èáè: %{y:,.1~f}<extra></extra>')
                    fig_bar_prov_class.update_layout(yaxis_title="Èó®Â∫óÊï∞Èáè", xaxis_title="ÁúÅÂå∫", yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                    st.plotly_chart(fig_bar_prov_class, use_container_width=True)
                    
                    st.markdown("---")
                    
                    # Migration Matrix
                    st.subheader("üîÑ Èó®Â∫óÁ≠âÁ∫ßÂèòÂä®ÊòéÁªÜ")
                    
                    # Define Change Type
                    def get_change_type(row):
                        order = {'A': 4, 'B': 3, 'C': 2, 'D': 1}
                        score_q3 = order[row['Class_Q3']]
                        score_q4 = order[row['Class_Q4']]
                        
                        if score_q3 == score_q4: return 'ÊåÅÂπ≥'
                        elif score_q4 > score_q3: return 'ÂçáÁ∫ß ‚¨ÜÔ∏è'
                        else: return 'ÈôçÁ∫ß ‚¨áÔ∏è'
                        
                    df['ÂèòÂä®Á±ªÂûã'] = df.apply(get_change_type, axis=1)
                    
                    # Summary of Changes
                    change_counts = df['ÂèòÂä®Á±ªÂûã'].value_counts()
                    st.info(f"üìä ÂèòÂä®Ê¶ÇËßà: ÂçáÁ∫ß {fmt_num(change_counts.get('ÂçáÁ∫ß ‚¨ÜÔ∏è', 0), na='')} ÂÆ∂ | ÈôçÁ∫ß {fmt_num(change_counts.get('ÈôçÁ∫ß ‚¨áÔ∏è', 0), na='')} ÂÆ∂ | ÊåÅÂπ≥ {fmt_num(change_counts.get('ÊåÅÂπ≥', 0), na='')} ÂÆ∂")
                    
                    # Detailed Table
                    # Filters
                    c_f1, c_f2, c_f3 = st.columns(3)
                    filter_prov = c_f1.selectbox("Á≠õÈÄâÁúÅÂå∫", ['ÂÖ®ÈÉ®'] + list(df['ÁúÅÂå∫'].unique()), key='abcd_prov')
                    
                    # Distributor Filter (Dependent on Province)
                    if filter_prov != 'ÂÖ®ÈÉ®':
                        dist_opts = ['ÂÖ®ÈÉ®'] + sorted(list(df[df['ÁúÅÂå∫'] == filter_prov]['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
                    else:
                        dist_opts = ['ÂÖ®ÈÉ®'] + sorted(list(df['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
                    filter_dist = c_f2.selectbox("Á≠õÈÄâÁªèÈîÄÂïÜ", dist_opts, key='abcd_dist')
                    
                    filter_change = c_f3.selectbox("Á≠õÈÄâÂèòÂä®Á±ªÂûã", ['ÂÖ®ÈÉ®', 'ÂçáÁ∫ß ‚¨ÜÔ∏è', 'ÈôçÁ∫ß ‚¨áÔ∏è', 'ÊåÅÂπ≥'], key='abcd_change')
                    
                    view_df = df.copy()
                    if filter_prov != 'ÂÖ®ÈÉ®':
                        view_df = view_df[view_df['ÁúÅÂå∫'] == filter_prov]
                    if filter_dist != 'ÂÖ®ÈÉ®':
                        view_df = view_df[view_df['ÁªèÈîÄÂïÜÂêçÁß∞'] == filter_dist]
                    if filter_change != 'ÂÖ®ÈÉ®':
                        view_df = view_df[view_df['ÂèòÂä®Á±ªÂûã'] == filter_change]
                        
                    show_aggrid_table(view_df[['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'Èó®Â∫óÂêçÁß∞', 'Class_Q3', 'Class_Q4', 'ÂèòÂä®Á±ªÂûã', 'Q3_Avg', 'Q4_Avg']])

            with tab_other:
                other_rank, other_query, other_detail, other_review_2025 = st.tabs(["üèÜ Ê¶úÂçïÊéíÂêç", "üîç Êü•ËØ¢ÂàÜÊûê", "üìù Êï∞ÊçÆÊòéÁªÜ", "üìÖ 2025Âπ¥Â§çÁõò"])
                
                with other_rank:
                    # Initialize df_perf for this scope if not already present
                    if 'df_perf' not in locals():
                         if df_perf_raw is not None:
                             df_perf = df_perf_raw.copy()
                             if 'Âπ¥‰ªΩ' in df_perf.columns:
                                 df_perf['Âπ¥‰ªΩ'] = pd.to_numeric(df_perf['Âπ¥‰ªΩ'], errors='coerce').fillna(0).astype(int)
                             if 'Êúà‰ªΩ' in df_perf.columns:
                                 df_perf['Êúà‰ªΩ'] = pd.to_numeric(df_perf['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                             
                             if 'ÂèëË¥ßÈáëÈ¢ù' not in df_perf.columns:
                                     if 'ÂèëË¥ßÁÆ±Êï∞' in df_perf.columns:
                                         df_perf['ÂèëË¥ßÈáëÈ¢ù'] = df_perf['ÂèëË¥ßÁÆ±Êï∞']
                                     else:
                                         df_perf['ÂèëË¥ßÈáëÈ¢ù'] = 0.0
                             df_perf['ÂèëË¥ßÈáëÈ¢ù'] = pd.to_numeric(df_perf['ÂèëË¥ßÈáëÈ¢ù'], errors='coerce').fillna(0.0)

                             for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'ÂΩíÁ±ª', 'ÂèëË¥ß‰ªì', 'Â§ßÂàÜÁ±ª', 'ÊúàÂàÜÊûê']:
                                 if c in df_perf.columns:
                                     df_perf[c] = df_perf[c].fillna('').astype(str).str.strip()

                             if 'Âπ¥‰ªΩ' in df_perf.columns and 'Êúà‰ªΩ' in df_perf.columns:
                                 df_perf = df_perf[(df_perf['Âπ¥‰ªΩ'] > 0) & (df_perf['Êúà‰ªΩ'].between(1, 12))]
                                 df_perf['Âπ¥Êúà'] = pd.to_datetime(
                                     df_perf['Âπ¥‰ªΩ'].astype(str) + '-' + df_perf['Êúà‰ªΩ'].astype(str).str.zfill(2) + '-01',
                                     errors='coerce'
                                 )
                             else:
                                 df_perf['Âπ¥Êúà'] = pd.NaT
                         else:
                             df_perf = pd.DataFrame()

                    c_filter, c_main = st.columns([0.26, 0.74])
                    
                    with c_filter:
                        st.markdown("### üß≠ Á≠õÈÄâÂå∫")
                        
                        # Calculate Date Range from Data
                        if df_perf is not None and not df_perf.empty and 'Âπ¥Êúà' in df_perf.columns:
                            valid_dates = df_perf['Âπ¥Êúà'].dropna()
                            if not valid_dates.empty:
                                max_ym = valid_dates.max()
                                min_ym = valid_dates.min()
                            else:
                                max_ym = pd.Timestamp.now()
                                min_ym = max_ym - pd.DateOffset(months=12)
                        else:
                            max_ym = pd.Timestamp.now()
                            min_ym = max_ym - pd.DateOffset(months=12)

                        time_mode = st.selectbox(
                            "Êó∂Èó¥ËåÉÂõ¥",
                            ["Ëøë3‰∏™Êúà", "Ëøë6‰∏™Êúà", "Ëøë12‰∏™Êúà", "Ëá™ÂÆö‰πâÂπ¥Êúà"],
                            index=["Ëøë3‰∏™Êúà", "Ëøë6‰∏™Êúà", "Ëøë12‰∏™Êúà", "Ëá™ÂÆö‰πâÂπ¥Êúà"].index(st.session_state.perf_time_mode) if st.session_state.perf_time_mode in ["Ëøë3‰∏™Êúà", "Ëøë6‰∏™Êúà", "Ëøë12‰∏™Êúà", "Ëá™ÂÆö‰πâÂπ¥Êúà"] else 2,
                            key="perf_time_mode"
                        )

                        # Initialize default values before any condition
                        # Use pd.Timestamp to ensure correct type for comparisons
                        start_ym = pd.Timestamp(max_ym.year, max_ym.month, 1) - pd.DateOffset(months=11)
                        end_ym = pd.Timestamp(max_ym.year, max_ym.month, 1)

                        def _months_back(n):
                            end = pd.Timestamp(max_ym.year, max_ym.month, 1)
                            start = (end - pd.DateOffset(months=n - 1))
                            return start, end

                        if time_mode == "Ëøë3‰∏™Êúà":
                            start_ym, end_ym = _months_back(3)
                        elif time_mode == "Ëøë6‰∏™Êúà":
                            start_ym, end_ym = _months_back(6)
                        elif time_mode == "Ëøë12‰∏™Êúà":
                            start_ym, end_ym = _months_back(12)
                        else:
                                c_from, c_to = st.columns(2)
                                with c_from:
                                    start_ym = st.date_input("ÂºÄÂßãÊúà", value=pd.Timestamp(max_ym.year, max_ym.month, 1) - pd.DateOffset(months=11), min_value=min_ym.date(), max_value=max_ym.date(), key="perf_start")
                                with c_to:
                                    end_ym = st.date_input("ÁªìÊùüÊúà", value=max_ym.date(), min_value=min_ym.date(), max_value=max_ym.date(), key="perf_end")
                                start_ym = pd.Timestamp(pd.to_datetime(start_ym).year, pd.to_datetime(start_ym).month, 1)
                                end_ym = pd.Timestamp(pd.to_datetime(end_ym).year, pd.to_datetime(end_ym).month, 1)

                        prov_col = df_perf.get('ÁúÅÂå∫', pd.Series(dtype=str))
                        prov_opts = sorted(prov_col.dropna().astype(str).str.strip().unique().tolist())
                        selected_provs = st.multiselect("ÁúÅÂå∫ÔºàÂ§öÈÄâÔºâ", prov_opts, default=prov_opts if not st.session_state.perf_provs else st.session_state.perf_provs, key="perf_provs")

                        wh_opts = sorted([x for x in df_perf.get('ÂèëË¥ß‰ªì', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        wh_sel = st.selectbox("ÂèëË¥ß‰ªì", ["ÂÖ®ÈÉ®"] + wh_opts, index=0, key="perf_wh")

                        mid_opts = sorted([x for x in df_perf.get('‰∏≠Á±ª', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        mid_sel = st.selectbox("‰∏≠Á±ª", ["ÂÖ®ÈÉ®"] + mid_opts, index=0, key="perf_mid")

                        grp_opts = sorted([x for x in df_perf.get('ÂΩíÁ±ª', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        grp_sel = st.selectbox("ÂΩíÁ±ª", ["ÂÖ®ÈÉ®"] + grp_opts, index=0, key="perf_grp")

                        cat_col = 'Á±ªÁõÆ' if 'Á±ªÁõÆ' in df_perf.columns else ('Â§ßÁ±ª' if 'Â§ßÁ±ª' in df_perf.columns else None)
                        cat_opts = sorted([x for x in df_perf.get(cat_col, pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x]) if cat_col else []
                        
                        default_cats = []
                        if st.session_state.perf_cats:
                            default_cats = [c for c in st.session_state.perf_cats if c in cat_opts]
                        else:
                            default_cats = cat_opts
                            
                        cat_sel = st.multiselect("Á±ªÁõÆÔºàÂ§öÈÄâÔºâ", cat_opts, default=default_cats, key="perf_cats")

                        dist_opts = sorted([x for x in df_perf.get('ÁªèÈîÄÂïÜÂêçÁß∞', pd.Series(dtype=str)).dropna().astype(str).str.strip().unique().tolist() if x])
                        dist_sel = st.multiselect("ÁªèÈîÄÂïÜÔºàÂèØÈÄâÔºâ", dist_opts, default=[], key="perf_dists")

                        df_f = df_perf.copy()
                        df_f = df_f[(df_f['Âπ¥Êúà'] >= pd.Timestamp(start_ym)) & (df_f['Âπ¥Êúà'] <= pd.Timestamp(end_ym))]
                        if selected_provs:
                            df_f = df_f[df_f['ÁúÅÂå∫'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "ÂÖ®ÈÉ®" and 'ÂèëË¥ß‰ªì' in df_f.columns:
                            df_f = df_f[df_f['ÂèëË¥ß‰ªì'].astype(str) == str(wh_sel)]
                        if mid_sel != "ÂÖ®ÈÉ®" and '‰∏≠Á±ª' in df_f.columns:
                            df_f = df_f[df_f['‰∏≠Á±ª'].astype(str) == str(mid_sel)]
                        if grp_sel != "ÂÖ®ÈÉ®" and 'ÂΩíÁ±ª' in df_f.columns:
                            df_f = df_f[df_f['ÂΩíÁ±ª'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_f = df_f[df_f[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_f = df_f[df_f['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).isin([str(x) for x in dist_sel])]

                        months_in_scope = sorted(df_f['Âπ¥Êúà'].dropna().unique().tolist())
                        months_n = len(months_in_scope) if months_in_scope else 0

                        def _sum_by_month(_df):
                            return _df.groupby('Âπ¥Êúà', as_index=False)['ÂèëË¥ßÁÆ±Êï∞'].sum().rename(columns={'ÂèëË¥ßÁÆ±Êï∞': 'ÂÆûÈôÖ'})

                        actual_total = float(df_f['ÂèëË¥ßÁÆ±Êï∞'].sum()) if 'ÂèëË¥ßÁÆ±Êï∞' in df_f.columns else 0.0

                        base_start = pd.Timestamp(start_ym) - pd.DateOffset(years=1)
                        base_end = pd.Timestamp(end_ym) - pd.DateOffset(years=1)
                        df_base = df_perf.copy()
                        df_base = df_base[(df_base['Âπ¥Êúà'] >= base_start) & (df_base['Âπ¥Êúà'] <= base_end)]
                        if selected_provs:
                            df_base = df_base[df_base['ÁúÅÂå∫'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "ÂÖ®ÈÉ®" and 'ÂèëË¥ß‰ªì' in df_base.columns:
                            df_base = df_base[df_base['ÂèëË¥ß‰ªì'].astype(str) == str(wh_sel)]
                        if mid_sel != "ÂÖ®ÈÉ®" and '‰∏≠Á±ª' in df_base.columns:
                            df_base = df_base[df_base['‰∏≠Á±ª'].astype(str) == str(mid_sel)]
                        if grp_sel != "ÂÖ®ÈÉ®" and 'ÂΩíÁ±ª' in df_base.columns:
                            df_base = df_base[df_base['ÂΩíÁ±ª'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_base = df_base[df_base[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_base = df_base[df_base['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).isin([str(x) for x in dist_sel])]
                        plan_total = float(df_base['ÂèëË¥ßÁÆ±Êï∞'].sum()) if 'ÂèëË¥ßÁÆ±Êï∞' in df_base.columns else 0.0

                        yoy_pct = None
                        if plan_total > 0:
                            yoy_pct = (actual_total - plan_total) / plan_total

                        prev_start = pd.Timestamp(start_ym) - pd.DateOffset(months=months_n) if months_n else pd.Timestamp(start_ym) - pd.DateOffset(months=12)
                        prev_end = pd.Timestamp(end_ym) - pd.DateOffset(months=months_n) if months_n else pd.Timestamp(end_ym) - pd.DateOffset(months=12)
                        df_prev = df_perf.copy()
                        df_prev = df_prev[(df_prev['Âπ¥Êúà'] >= prev_start) & (df_prev['Âπ¥Êúà'] <= prev_end)]
                        if selected_provs:
                            df_prev = df_prev[df_prev['ÁúÅÂå∫'].astype(str).isin([str(x) for x in selected_provs])]
                        if wh_sel != "ÂÖ®ÈÉ®" and 'ÂèëË¥ß‰ªì' in df_prev.columns:
                            df_prev = df_prev[df_prev['ÂèëË¥ß‰ªì'].astype(str) == str(wh_sel)]
                        if mid_sel != "ÂÖ®ÈÉ®" and '‰∏≠Á±ª' in df_prev.columns:
                            df_prev = df_prev[df_prev['‰∏≠Á±ª'].astype(str) == str(mid_sel)]
                        if grp_sel != "ÂÖ®ÈÉ®" and 'ÂΩíÁ±ª' in df_prev.columns:
                            df_prev = df_prev[df_prev['ÂΩíÁ±ª'].astype(str) == str(grp_sel)]
                        if cat_col and cat_sel:
                            df_prev = df_prev[df_prev[cat_col].astype(str).isin([str(x) for x in cat_sel])]
                        if dist_sel:
                            df_prev = df_prev[df_prev['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).isin([str(x) for x in dist_sel])]
                        prev_total = float(df_prev['ÂèëË¥ßÁÆ±Êï∞'].sum()) if 'ÂèëË¥ßÁÆ±Êï∞' in df_prev.columns else 0.0

                        mom_pct = None
                        if prev_total > 0:
                            mom_pct = (actual_total - prev_total) / prev_total
        
                    with c_main:
                        st.subheader("üè™ TOP 10 Èó®Â∫ó")
                        store_rank = df.nlargest(10, 'ÊÄªÂá∫Â∫ìÊï∞')[['Èó®Â∫óÂêçÁß∞', 'ÊÄªÂá∫Â∫ìÊï∞', 'ÁúÅÂå∫']]
                        fig_store = px.bar(store_rank, x='ÊÄªÂá∫Â∫ìÊï∞', y='Èó®Â∫óÂêçÁß∞', orientation='h', text='ÊÄªÂá∫Â∫ìÊï∞',
                                          title="Èó®Â∫óÂá∫Â∫ìÊéíË°å (Ââç10)", color='ÁúÅÂå∫')
                        fig_store.update_traces(texttemplate='%{x:,.1~f}', hovertemplate='Èó®Â∫ó: %{y}<br>ÊÄªÂá∫Â∫ìÊï∞: %{x:,.1~f}<extra></extra>')
                        fig_store.update_layout(yaxis_title="", yaxis={'categoryorder':'total ascending'}, xaxis=dict(tickformat=",.1~f"))
                        st.plotly_chart(fig_store, use_container_width=True)
                        
                        st.subheader("üåç ÁúÅÂå∫ÊéíÂêç")
                        prov_rank = df.groupby('ÁúÅÂå∫')['ÊÄªÂá∫Â∫ìÊï∞'].sum().sort_values(ascending=False).reset_index()
                        prov_rank['ÊÄªÂá∫Â∫ìÊï∞'] = prov_rank['ÊÄªÂá∫Â∫ìÊï∞'].astype(int)
                        n_rows = len(prov_rank)
                        calc_height = (n_rows + 1) * 35 + 10
                        final_height = max(150, min(calc_height, 2000))
                        show_aggrid_table(
                            prov_rank,
                            height=final_height,
                            columns_props={'ÊÄªÂá∫Â∫ìÊï∞': {'type': 'bar'}}
                        )

                with other_query:
                    st.subheader("üîç Â§öÁª¥Â∫¶Êü•ËØ¢ÂàÜÊûê")
                    
                    sc1, sc2, sc3 = st.columns(3)
                    search_provinces = ['ÂÖ®ÈÉ®'] + sorted(list(df['ÁúÅÂå∫'].unique()))
                    s_prov = sc1.selectbox("ÈÄâÊã©ÁúÅÂå∫ (Province)", search_provinces, key='s_prov')
                    
                    if s_prov != 'ÂÖ®ÈÉ®':
                        s_dist_opts = ['ÂÖ®ÈÉ®'] + sorted(list(df[df['ÁúÅÂå∫'] == s_prov]['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
                    else:
                        s_dist_opts = ['ÂÖ®ÈÉ®'] + sorted(list(df['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()))
                    s_dist = sc2.selectbox("ÈÄâÊã©ÁªèÈîÄÂïÜ (Distributor)", s_dist_opts, key='s_dist')
                    
                    df_store_filter = df.copy()
                    if s_prov != 'ÂÖ®ÈÉ®':
                        df_store_filter = df_store_filter[df_store_filter['ÁúÅÂå∫'] == s_prov]
                    if s_dist != 'ÂÖ®ÈÉ®':
                        df_store_filter = df_store_filter[df_store_filter['ÁªèÈîÄÂïÜÂêçÁß∞'] == s_dist]
                        
                    s_store_opts = ['ÂÖ®ÈÉ®'] + sorted(list(df_store_filter['Èó®Â∫óÂêçÁß∞'].unique()))
                    s_store = sc3.selectbox("ÈÄâÊã©Èó®Â∫ó (Store)", s_store_opts, key='s_store')

                    st.markdown("---")
                    
                    if s_store != 'ÂÖ®ÈÉ®':
                        store_row = df_store_filter[df_store_filter['Èó®Â∫óÂêçÁß∞'] == s_store].iloc[0]
                        st.markdown(f"### üè™ Èó®Â∫óËØ¶ÊÉÖ: {s_store}")
                        st.caption(f"ÊâÄÂ±ûÁªèÈîÄÂïÜ: {store_row['ÁªèÈîÄÂïÜÂêçÁß∞']} | ÊâÄÂ±ûÁúÅÂå∫: {store_row['ÁúÅÂå∫']}")
                        
                        if month_cols:
                            row_trend = pd.DataFrame({'Êúà‰ªΩ': month_cols, 'Âá∫Â∫ìÊï∞': [store_row[c] for c in month_cols]})
                            row_trend['Month_Num'] = row_trend['Êúà‰ªΩ'].str.extract(r'(\d+)')[0].astype(int)
                            row_trend = row_trend.sort_values('Month_Num')
                            fig_s = px.line(row_trend, x='Êúà‰ªΩ', y='Âá∫Â∫ìÊï∞', markers=True, text='Âá∫Â∫ìÊï∞', title=f"{s_store} - ÊúàÂ∫¶Âá∫Â∫ìË∂ãÂäø")
                            fig_s.update_traces(
                                mode='lines+markers+text',
                                line_color='#6A3AD0',
                                line_width=3,
                                hovertemplate='Êúà‰ªΩ: %{x}<br>Âá∫Â∫ìÊï∞: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_s.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_s, use_container_width=True)
                            show_aggrid_table(pd.DataFrame([store_row]), height=150, key="s_store_table")

                    elif s_dist != 'ÂÖ®ÈÉ®':
                        st.markdown(f"### üè¢ ÁªèÈîÄÂïÜËØ¶ÊÉÖ: {s_dist}")
                        dist_sub = df[df['ÁªèÈîÄÂïÜÂêçÁß∞'] == s_dist]
                        st.caption(f"Ë¶ÜÁõñÁúÅÂå∫: {', '.join(dist_sub['ÁúÅÂå∫'].unique())} | Êóó‰∏ãÈó®Â∫óÊï∞: {len(dist_sub)}")
                        
                        if month_cols:
                            dist_trend = pd.DataFrame({'Êúà‰ªΩ': month_cols, 'Âá∫Â∫ìÊï∞': dist_sub[month_cols].sum().values})
                            dist_trend['Month_Num'] = dist_trend['Êúà‰ªΩ'].str.extract(r'(\d+)')[0].astype(int)
                            dist_trend = dist_trend.sort_values('Month_Num')
                            fig_d = px.line(dist_trend, x='Êúà‰ªΩ', y='Âá∫Â∫ìÊï∞', markers=True, text='Âá∫Â∫ìÊï∞', title=f"{s_dist} - Êï¥‰ΩìÊúàÂ∫¶Âá∫Â∫ìË∂ãÂäø")
                            fig_d.update_traces(
                                mode='lines+markers+text',
                                line_color='#FFC400',
                                line_width=3,
                                hovertemplate='Êúà‰ªΩ: %{x}<br>ÂêàËÆ°Âá∫Â∫ì: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_d.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_d, use_container_width=True)
                            st.markdown("#### Êóó‰∏ãÈó®Â∫óÂàóË°®")
                            show_aggrid_table(dist_sub[['ÁúÅÂå∫', 'Èó®Â∫óÂêçÁß∞', 'ÊÄªÂá∫Â∫ìÊï∞', 'Èó®Â∫óÂàÜÁ±ª']], height=300, key="s_dist_table")

                    elif s_prov != 'ÂÖ®ÈÉ®':
                        st.markdown(f"### üèôÔ∏è ÁúÅÂå∫ËØ¶ÊÉÖ: {s_prov}")
                        prov_sub = df[df['ÁúÅÂå∫'] == s_prov]
                        st.caption(f"ÁªèÈîÄÂïÜÊï∞Èáè: {prov_sub['ÁªèÈîÄÂïÜÂêçÁß∞'].nunique()} | Èó®Â∫óÊÄªÊï∞: {len(prov_sub)}")
                        
                        if month_cols:
                            prov_trend = pd.DataFrame({'Êúà‰ªΩ': month_cols, 'Âá∫Â∫ìÊï∞': prov_sub[month_cols].sum().values})
                            prov_trend['Month_Num'] = prov_trend['Êúà‰ªΩ'].str.extract(r'(\d+)')[0].astype(int)
                            prov_trend = prov_trend.sort_values('Month_Num')
                            fig_p = px.line(prov_trend, x='Êúà‰ªΩ', y='Âá∫Â∫ìÊï∞', markers=True, text='Âá∫Â∫ìÊï∞', title=f"{s_prov} - ÂÖ®ÁúÅÊúàÂ∫¶Âá∫Â∫ìË∂ãÂäø")
                            fig_p.update_traces(
                                mode='lines+markers+text',
                                line_color='#5B2EA6',
                                line_width=3,
                                hovertemplate='Êúà‰ªΩ: %{x}<br>ÂêàËÆ°Âá∫Â∫ì: %{y:,.1~f}<extra></extra>',
                                texttemplate='%{y:,.1~f}',
                                textposition="top center"
                            )
                            fig_p.update_layout(yaxis=dict(tickformat=",.1~f"), paper_bgcolor='rgba(255,255,255,0.25)', plot_bgcolor='rgba(255,255,255,0.25)')
                            st.plotly_chart(fig_p, use_container_width=True)
                            st.markdown("#### ÁúÅÂÜÖÁªèÈîÄÂïÜÊ¶ÇËßà")
                            dist_summary = prov_sub.groupby('ÁªèÈîÄÂïÜÂêçÁß∞')['ÊÄªÂá∫Â∫ìÊï∞'].sum().reset_index().sort_values('ÊÄªÂá∫Â∫ìÊï∞', ascending=False)
                            show_aggrid_table(dist_summary, height=400, key="s_prov_table")
                    else:
                        st.info("üëà ËØ∑Âú®‰∏äÊñπÈÄâÊã© ÁúÅÂå∫ / ÁªèÈîÄÂïÜ / Èó®Â∫ó ËøõË°åÊü•ËØ¢")

                with other_detail:
                    st.subheader("üìù Êï∞ÊçÆÊòéÁªÜ")
                    ds_opts = ["Èó®Â∫óÂá∫Â∫ìÊ±áÊÄª(Sheet1)", "Â∫ìÂ≠òÊòéÁªÜ(Sheet2)", "Âá∫Â∫ìÂ∫ïË°®(Sheet3)", "ÂèëË¥ß‰∏öÁª©(Sheet4)", "‰ªªÂä°Ë°®(Sheet5)"]
                    ds = st.selectbox("ÈÄâÊã©Êï∞ÊçÆÈõÜ", ds_opts, key="other_ds_sel")

                    df_show = None
                    if ds.startswith("Èó®Â∫óÂá∫Â∫ì"):
                        df_show = df.copy()
                    elif ds.startswith("Â∫ìÂ≠ò") and (df_stock_raw is not None):
                        df_show = df_stock_raw.copy()
                    elif ds.startswith("Âá∫Â∫ìÂ∫ïË°®") and (df_q4_raw is not None):
                        df_show = df_q4_raw.copy()
                    elif ds.startswith("ÂèëË¥ß‰∏öÁª©") and (df_perf_raw is not None):
                        df_show = df_perf_raw.copy()
                    elif ds.startswith("‰ªªÂä°Ë°®") and (df_target_raw is not None):
                        df_show = df_target_raw.copy()

                    if df_show is None or df_show.empty:
                        st.info("ÂΩìÂâçÊï∞ÊçÆÈõÜÊó†Êï∞ÊçÆ„ÄÇ")
                    else:
                        show_aggrid_table(df_show, height=520, key="other_detail_table")
                        out_buf = io.BytesIO()
                        try:
                            with pd.ExcelWriter(out_buf, engine='openpyxl') as writer:
                                df_show.to_excel(writer, index=False, sheet_name='data')
                        except Exception:
                            with pd.ExcelWriter(out_buf, engine='xlsxwriter') as writer:
                                df_show.to_excel(writer, index=False, sheet_name='data')
                        st.download_button(
                            "üì• ÂØºÂá∫ÂΩìÂâçÊï∞ÊçÆÈõÜÔºàExcelÔºâ",
                            data=out_buf.getvalue(),
                            file_name=f"{ds}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="other_detail_download"
                        )
                
                # --- New Tab for 2025 Review ---
                with other_review_2025:
                     st.header("üìÖ 2025Âπ¥Â§çÁõò (2025 Review)")
                     
                     # Construct df_2025 from df_perf_raw and df_target_raw
                     # Needs: 'ÁúÅÂå∫', 'ÂÆûÈôÖÂèëË¥ß', 'Âπ¥Â∫¶‰ªªÂä°', 'ÂêåÊØîÂ¢ûÈïø', '‰∫ßÂìÅÂìÅÁ±ª'
                     df_2025 = None
                     if df_perf_raw is not None and df_target_raw is not None:
                         # 1. Actuals 2025
                         # Ensure numeric
                         if 'Âπ¥‰ªΩ' in df_perf_raw.columns:
                            perf_2025 = df_perf_raw[df_perf_raw['Âπ¥‰ªΩ'] == 2025].copy()
                         else:
                            perf_2025 = pd.DataFrame()

                         if not perf_2025.empty:
                            if 'ÂèëË¥ßÈáëÈ¢ù' not in perf_2025.columns and 'ÂèëË¥ßÁÆ±Êï∞' in perf_2025.columns:
                                perf_2025['ÂèëË¥ßÈáëÈ¢ù'] = perf_2025['ÂèëË¥ßÁÆ±Êï∞'] # Fallback
                            
                            # Agg by Prov
                            act_prov = perf_2025.groupby('ÁúÅÂå∫')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂÆûÈôÖÂèëË¥ß'})
                            
                            # 2. Targets 2025 (Assuming df_target_raw is 2025 targets)
                            # Target sheet: C=Prov, D=Cat, E=Month, F=Task
                            # We need to sum Task by Prov
                            tgt_prov = df_target_raw.groupby('ÁúÅÂå∫')['‰ªªÂä°Èáè'].sum().reset_index().rename(columns={'‰ªªÂä°Èáè': 'Âπ¥Â∫¶‰ªªÂä°'})
                            
                            # 3. Merge
                            df_2025 = pd.merge(act_prov, tgt_prov, on='ÁúÅÂå∫', how='outer').fillna(0)
                            
                            # 4. YoY (Need 2024 data)
                            perf_2024 = df_perf_raw[df_perf_raw['Âπ¥‰ªΩ'] == 2024].copy()
                            if not perf_2024.empty:
                                if 'ÂèëË¥ßÈáëÈ¢ù' not in perf_2024.columns and 'ÂèëË¥ßÁÆ±Êï∞' in perf_2024.columns:
                                    perf_2024['ÂèëË¥ßÈáëÈ¢ù'] = perf_2024['ÂèëË¥ßÁÆ±Êï∞']
                                act_2024 = perf_2024.groupby('ÁúÅÂå∫')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                df_2025 = pd.merge(df_2025, act_2024, on='ÁúÅÂå∫', how='left').fillna(0)
                                df_2025['ÂêåÊØîÂ¢ûÈïø'] = df_2025.apply(lambda x: ((x['ÂÆûÈôÖÂèëË¥ß'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                            else:
                                df_2025['ÂêåÊØîÂ¢ûÈïø'] = 0.0
                                
                            # 5. Category Breakdown (Optional, if '‰∫ßÂìÅÂìÅÁ±ª' needed)
                            # Create a separate df for category view if needed, or try to add it to df_2025?
                            # The code expects df_2025 to have '‰∫ßÂìÅÂìÅÁ±ª' column if possible. 
                            # But df_2025 above is aggregated by Province. 
                            # If we want Category breakdown, we need a different aggregation.
                            # Let's check usage: 
                            # prov_summ = df_2025.groupby('ÁúÅÂå∫')... -> This works on the prov-agg df
                            # cat_summ = df_2025.groupby('‰∫ßÂìÅÂìÅÁ±ª')... -> This implies df_2025 should be granular?
                            # If df_2025 is granular (Prov, Cat), we can do both.
                            
                            # Let's try to build granular df_2025 (Prov, Cat)
                            cat_col_p = 'Á±ªÁõÆ' if 'Á±ªÁõÆ' in perf_2025.columns else ('Â§ßÁ±ª' if 'Â§ßÁ±ª' in perf_2025.columns else 'Â§ßÂàÜÁ±ª')
                            if cat_col_p not in perf_2025.columns: cat_col_p = 'ÁúÅÂå∫' # Fallback
                            
                            act_gran = perf_2025.groupby(['ÁúÅÂå∫', cat_col_p])['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂÆûÈôÖÂèëË¥ß', cat_col_p: '‰∫ßÂìÅÂìÅÁ±ª'})
                            
                            # Target Granular
                            # Sheet 5: 'ÂìÅÁ±ª' column exists?
                            if 'ÂìÅÁ±ª' in df_target_raw.columns:
                                tgt_gran = df_target_raw.groupby(['ÁúÅÂå∫', 'ÂìÅÁ±ª'])['‰ªªÂä°Èáè'].sum().reset_index().rename(columns={'‰ªªÂä°Èáè': 'Âπ¥Â∫¶‰ªªÂä°', 'ÂìÅÁ±ª': '‰∫ßÂìÅÂìÅÁ±ª'})
                            else:
                                tgt_gran = pd.DataFrame(columns=['ÁúÅÂå∫', '‰∫ßÂìÅÂìÅÁ±ª', 'Âπ¥Â∫¶‰ªªÂä°'])
                                
                            df_2025_g = pd.merge(act_gran, tgt_gran, on=['ÁúÅÂå∫', '‰∫ßÂìÅÂìÅÁ±ª'], how='outer').fillna(0)
                            
                            # YoY Granular
                            if not perf_2024.empty:
                                cat_col_24 = 'Á±ªÁõÆ' if 'Á±ªÁõÆ' in perf_2024.columns else ('Â§ßÁ±ª' if 'Â§ßÁ±ª' in perf_2024.columns else 'Â§ßÂàÜÁ±ª')
                                if cat_col_24 not in perf_2024.columns: cat_col_24 = 'ÁúÅÂå∫'
                                act_2024_g = perf_2024.groupby(['ÁúÅÂå∫', cat_col_24])['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü', cat_col_24: '‰∫ßÂìÅÂìÅÁ±ª'})
                                df_2025_g = pd.merge(df_2025_g, act_2024_g, on=['ÁúÅÂå∫', '‰∫ßÂìÅÂìÅÁ±ª'], how='left').fillna(0)
                                df_2025_g['ÂêåÊØîÂ¢ûÈïø'] = df_2025_g.apply(lambda x: ((x['ÂÆûÈôÖÂèëË¥ß'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                            else:
                                df_2025_g['ÂêåÊØîÂ¢ûÈïø'] = 0.0
                                
                            df_2025 = df_2025_g

                     if df_2025 is None or df_2025.empty:
                         st.warning("‚ö†Ô∏è Êú™ÊâæÂà∞ 2025 Âπ¥Â§çÁõòÊï∞ÊçÆ (Sheet2)„ÄÇËØ∑Ê£ÄÊü•‰∏ä‰º†Êñá‰ª∂„ÄÇ")
                     else:
                         # 1. Total KPI
                         st.subheader("1. Êï¥‰ΩìÂÖ≥ÈîÆÊåáÊ†á")
                         c1, c2, c3, c4 = st.columns(4)
                         total_sales = df_2025['ÂÆûÈôÖÂèëË¥ß'].sum()
                         total_target = df_2025['Âπ¥Â∫¶‰ªªÂä°'].sum()
                         ach_rate = total_sales / total_target if total_target else 0
                         yoy_growth = df_2025['ÂêåÊØîÂ¢ûÈïø'].mean()  # This might need weighted avg
                         
                         c1.metric("2025ÊÄªÂÆûÈôÖÂèëË¥ß", fmt_num(total_sales), delta=fmt_pct_value(yoy_growth))
                         c2.metric("2025ÊÄªÂπ¥Â∫¶‰ªªÂä°", fmt_num(total_target))
                         c3.metric("Âπ¥Â∫¶ËææÊàêÁéá", fmt_pct_ratio(ach_rate))
                         
                         # 2. Province Performance
                         st.subheader("2. ÁúÅÂå∫Ë°®Áé∞Ê¶ÇËßà")
                         prov_summ = df_2025.groupby('ÁúÅÂå∫')[['Âπ¥Â∫¶‰ªªÂä°', 'ÂÆûÈôÖÂèëË¥ß', 'ÂêåÊØîÂ¢ûÈïø']].sum().reset_index()
                         prov_summ['ËææÊàêÁéá'] = prov_summ['ÂÆûÈôÖÂèëË¥ß'] / prov_summ['Âπ¥Â∫¶‰ªªÂä°']
                         prov_summ = prov_summ.sort_values('ÂÆûÈôÖÂèëË¥ß', ascending=False)
                         
                         show_aggrid_table(prov_summ, height=400, key="review_2025_prov")
                         
                         # 3. Category Breakdown (if available)
                         if '‰∫ßÂìÅÂìÅÁ±ª' in df_2025.columns:
                             st.subheader("3. ÂìÅÁ±ªË°®Áé∞")
                             cat_summ = df_2025.groupby('‰∫ßÂìÅÂìÅÁ±ª')[['ÂÆûÈôÖÂèëË¥ß', 'Âπ¥Â∫¶‰ªªÂä°']].sum().reset_index()
                             cat_summ['ËææÊàêÁéá'] = cat_summ['ÂÆûÈôÖÂèëË¥ß'] / cat_summ['Âπ¥Â∫¶‰ªªÂä°']
                             
                             c_chart, c_data = st.columns([2, 1])
                             with c_chart:
                                 fig_cat = px.bar(cat_summ, x='‰∫ßÂìÅÂìÅÁ±ª', y=['ÂÆûÈôÖÂèëË¥ß', 'Âπ¥Â∫¶‰ªªÂä°'], barmode='group', title="ÂìÅÁ±ª‰ªªÂä° vs ÂÆûÈôÖ")
                                 st.plotly_chart(fig_cat, use_container_width=True)
                             with c_data:
                                 show_aggrid_table(cat_summ, height=300, key="review_2025_cat")


            # --- Tab 6: Inventory Analysis ---
            with tab6:
                if df_stock_raw is None:
                    st.warning("‚ö†Ô∏è Êú™Ê£ÄÊµãÂà∞Â∫ìÂ≠òÊï∞ÊçÆ (Sheet2)„ÄÇËØ∑Á°Æ‰øù‰∏ä‰º†ÁöÑ Excel Êñá‰ª∂ÂåÖÂê´Á¨¨‰∫å‰∏™ Sheet È°µÔºå‰∏îÊ†ºÂºèÊ≠£Á°Æ„ÄÇ")
                    st.info("Êï∞ÊçÆÊ†ºÂºèË¶ÅÊ±ÇÔºö\nSheet2 ÈúÄÂåÖÂê´ A-L ÂàóÔºåÈ°∫Â∫è‰∏∫ÔºöÁªèÈîÄÂïÜÁºñÁ†Å„ÄÅÁªèÈîÄÂïÜÂêçÁß∞„ÄÅ‰∫ßÂìÅÁºñÁ†Å„ÄÅ‰∫ßÂìÅÂêçÁß∞„ÄÅÂ∫ìÂ≠òÊï∞Èáè„ÄÅÁÆ±Êï∞„ÄÅÁúÅÂå∫ÂêçÁß∞„ÄÅÂÆ¢Êà∑ÁÆÄÁß∞„ÄÅ‰∫ßÂìÅÂ§ßÁ±ª„ÄÅ‰∫ßÂìÅÂ∞èÁ±ª„ÄÅÈáçÈáè„ÄÅËßÑÊ†º„ÄÇ")
                else:
                    st.caption(f"üïí Êï∞ÊçÆÊõ¥Êñ∞Êó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    with st.expander("üõ†Ô∏è Â∫ìÂ≠òÁ≠õÈÄâ", expanded=False):
                        # Prepare filter lists
                        stock_provs = ['ÂÖ®ÈÉ®'] + sorted(list(df_stock_raw['ÁúÅÂå∫ÂêçÁß∞'].dropna().unique()))
                        stock_dists = ['ÂÖ®ÈÉ®'] + sorted(list(df_stock_raw['ÁªèÈîÄÂïÜÂêçÁß∞'].dropna().unique()))
                        stock_cats = ['ÂÖ®ÈÉ®'] + sorted(list(df_stock_raw['‰∫ßÂìÅÂ§ßÁ±ª'].dropna().unique()))
                        
                        # Helper to reset drill status
                        def reset_inv_drill():
                            st.session_state.drill_level = 1
                            st.session_state.selected_prov = None
                            st.session_state.selected_dist = None

                        # --- Subcategory Logic Adjustment ---
                        # User requirement: "Subcategory" dropdown should include 'Segment' and 'Ya Series'.
                        # When 'Segment' is selected, Specific Category options are ['1ÊÆµ', '2ÊÆµ', '3ÊÆµ'].
                        # When 'Ya Series' is selected, Specific Category options are ['ÈõÖËµã', 'ÈõÖËÄÄ', 'ÈõÖËàí', 'ÈõÖÊä§'].
                        
                        # 1. Base Subcategories
                        base_subcats = sorted(list(df_stock_raw['‰∫ßÂìÅÂ∞èÁ±ª'].dropna().unique()))
                        # 2. Add Virtual Subcategories (Ensure uniqueness)
                        virtual_subcats = ['ÂàÜÊÆµ', 'ÈõÖÁ≥ªÂàó']
                        stock_subcats = ['ÂÖ®ÈÉ®'] + virtual_subcats + [s for s in base_subcats if s not in virtual_subcats]
                        
                        c1, c2, c3, c4, c5 = st.columns(5)
                        with c1: s_prov = st.selectbox("ÁúÅÂå∫ÂêçÁß∞", stock_provs, key='stock_s_prov', on_change=reset_inv_drill)
                        with c2: 
                            if s_prov != 'ÂÖ®ÈÉ®':
                                valid_dists = df_stock_raw[df_stock_raw['ÁúÅÂå∫ÂêçÁß∞'] == s_prov]['ÁªèÈîÄÂïÜÂêçÁß∞'].unique()
                                s_dist_opts = ['ÂÖ®ÈÉ®'] + sorted(list(valid_dists))
                            else:
                                s_dist_opts = stock_dists
                            s_dist = st.selectbox("ÁªèÈîÄÂïÜÂêçÁß∞", s_dist_opts, key='stock_s_dist', on_change=reset_inv_drill)
                            
                        with c3: s_cat = st.selectbox("‰∫ßÂìÅÂ§ßÁ±ª", stock_cats, key='stock_s_cat', on_change=reset_inv_drill)
                        
                        with c4: 
                            # Dynamic filter for subcat based on cat
                            # If we are using virtual subcats, we might want to show them regardless of Category?
                            # Or only if the Category allows? Assuming 'ÁæéÊÄùÈõÖÊÆµÁ≤â' allows them.
                            if s_cat != 'ÂÖ®ÈÉ®':
                                valid_sub = df_stock_raw[df_stock_raw['‰∫ßÂìÅÂ§ßÁ±ª'] == s_cat]['‰∫ßÂìÅÂ∞èÁ±ª'].unique()
                                # Mix in virtuals if they make sense (assuming they are always available for filtering)
                                current_sub_opts = ['ÂÖ®ÈÉ®'] + virtual_subcats + sorted([s for s in valid_sub if s not in virtual_subcats])
                                s_sub_opts = current_sub_opts
                            else:
                                s_sub_opts = stock_subcats
                            if 'stock_s_sub' in st.session_state:
                                st.session_state.pop('stock_s_sub', None)
                            s_sub_selected = st.multiselect("‰∫ßÂìÅÂ∞èÁ±ª(ÂèØÂ§öÈÄâ)", s_sub_opts, default=['ÂÖ®ÈÉ®'], key='stock_s_sub_ms', on_change=reset_inv_drill)
                        
                        with c5:
                            # --- Dynamic Specific Category Options based on Subcategory Selection ---
                            if 'ÂàÜÊÆµ' in s_sub_selected and 'ÈõÖÁ≥ªÂàó' in s_sub_selected:
                                stock_specs = ['1ÊÆµ', '2ÊÆµ', '3ÊÆµ', 'ÈõÖËµã', 'ÈõÖËÄÄ', 'ÈõÖËàí', 'ÈõÖÊä§']
                            elif 'ÂàÜÊÆµ' in s_sub_selected:
                                stock_specs = ['1ÊÆµ', '2ÊÆµ', '3ÊÆµ']
                            elif 'ÈõÖÁ≥ªÂàó' in s_sub_selected:
                                stock_specs = ['ÈõÖËµã', 'ÈõÖËÄÄ', 'ÈõÖËàí', 'ÈõÖÊä§']
                            else:
                                raw_specs = df_stock_raw['ÂÖ∑‰ΩìÂàÜÁ±ª'].dropna().unique()
                                spec_opts = set(raw_specs)
                                stock_specs = sorted(list(spec_opts))
                                
                            s_spec = st.multiselect("ÂÖ∑‰ΩìÂàÜÁ±ª (ÊîØÊåÅÂ§öÈÄâ)", stock_specs, default=[], placeholder="ÈÄâÊã©ÂÖ∑‰ΩìÂàÜÁ±ª...", on_change=reset_inv_drill)
                        
                        # Apply Filters
                        df_s_filtered = df_stock_raw.copy()
                        if s_prov != 'ÂÖ®ÈÉ®': df_s_filtered = df_s_filtered[df_s_filtered['ÁúÅÂå∫ÂêçÁß∞'] == s_prov]
                        if s_dist != 'ÂÖ®ÈÉ®': df_s_filtered = df_s_filtered[df_s_filtered['ÁªèÈîÄÂïÜÂêçÁß∞'] == s_dist]
                        if s_cat != 'ÂÖ®ÈÉ®': df_s_filtered = df_s_filtered[df_s_filtered['‰∫ßÂìÅÂ§ßÁ±ª'] == s_cat]
                        
                        # --- Subcategory Filter Logic ---
                        if s_sub_selected and ('ÂÖ®ÈÉ®' not in s_sub_selected):
                            mask_sub = pd.Series(False, index=df_s_filtered.index)
                            if 'ÂàÜÊÆµ' in s_sub_selected:
                                mask_sub = mask_sub | (
                                    (df_s_filtered['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == 'ÁæéÊÄùÈõÖÊÆµÁ≤â')
                                    & (df_s_filtered['ÂÖ∑‰ΩìÂàÜÁ±ª'].fillna('').astype(str).isin(['1ÊÆµ', '2ÊÆµ', '3ÊÆµ']))
                                )
                            if 'ÈõÖÁ≥ªÂàó' in s_sub_selected:
                                mask_sub = mask_sub | (
                                    df_s_filtered['ÂÖ∑‰ΩìÂàÜÁ±ª'].fillna('').astype(str).isin(['ÈõÖËµã', 'ÈõÖËÄÄ', 'ÈõÖËàí', 'ÈõÖÊä§'])
                                )
                            normal_subs = [x for x in s_sub_selected if x not in ['ÂàÜÊÆµ', 'ÈõÖÁ≥ªÂàó', 'ÂÖ®ÈÉ®']]
                            if normal_subs:
                                mask_sub = mask_sub | df_s_filtered['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str).isin([str(x) for x in normal_subs])
                            df_s_filtered = df_s_filtered[mask_sub]
                        
                        # Apply Specific Category Filter
                        if s_spec:
                            def match_spec(row_val):
                                row_val = str(row_val)
                                for sel in s_spec:
                                    if sel in row_val: return True
                                return False
                            
                            mask = df_s_filtered['ÂÖ∑‰ΩìÂàÜÁ±ª'].apply(match_spec)
                            df_s_filtered = df_s_filtered[mask]
                    
                    st.markdown("---")

                    outbound_pivot = pd.DataFrame()
                    df_o_filtered = pd.DataFrame()
                    sales_agg_q4 = pd.DataFrame(columns=['ÁªèÈîÄÂïÜÂêçÁß∞', 'Q4_Total', 'Q4_Avg'])

                    with st.expander("üöö Âá∫Â∫ìÁ≠õÈÄâ", expanded=False):
                        if df_q4_raw is None or df_q4_raw.empty:
                            st.warning("‚ö†Ô∏è Êú™Ê£ÄÊµãÂà∞Âá∫Â∫ìÂ∫ïË°®Êï∞ÊçÆ (Sheet3)„ÄÇ")
                        else:
                            o_raw = df_q4_raw.copy()
                            required_out_cols = ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'Êï∞Èáè(ÁÆ±)', 'Êúà‰ªΩ']
                            missing_out = [c for c in required_out_cols if c not in o_raw.columns]

                            if missing_out:
                                st.warning(f"‚ö†Ô∏è Âá∫Â∫ìÂ∫ïË°®Áº∫Â§±Â≠óÊÆµÔºö{', '.join(missing_out)}")
                            else:
                                if '‰∫ßÂìÅÂ§ßÁ±ª' not in o_raw.columns:
                                    o_raw['‰∫ßÂìÅÂ§ßÁ±ª'] = 'ÂÖ®ÈÉ®'
                                if '‰∫ßÂìÅÂ∞èÁ±ª' not in o_raw.columns:
                                    o_raw['‰∫ßÂìÅÂ∞èÁ±ª'] = 'ÂÖ®ÈÉ®'
                                else:
                                    o_raw['‰∫ßÂìÅÂ∞èÁ±ª'] = o_raw['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str).str.strip()
                                    o_raw.loc[o_raw['‰∫ßÂìÅÂ∞èÁ±ª'].isin(['', 'nan', 'None', 'NULL', 'NaN']), '‰∫ßÂìÅÂ∞èÁ±ª'] = pd.NA

                            out_provs = ['ÂÖ®ÈÉ®'] + sorted(o_raw['ÁúÅÂå∫'].dropna().astype(str).unique().tolist())
                            out_dists_all = ['ÂÖ®ÈÉ®'] + sorted(o_raw['ÁªèÈîÄÂïÜÂêçÁß∞'].dropna().astype(str).unique().tolist())
                            out_cats = ['ÂÖ®ÈÉ®'] + sorted(o_raw['‰∫ßÂìÅÂ§ßÁ±ª'].dropna().astype(str).unique().tolist())
                            out_subs_clean = o_raw['‰∫ßÂìÅÂ∞èÁ±ª'].dropna().astype(str).str.strip()
                            out_subs_clean = out_subs_clean[out_subs_clean != '']
                            out_subs_list = sorted(out_subs_clean.unique().tolist())
                            out_subs = ['ÂÖ®ÈÉ®'] + out_subs_list
                            empty_sub_cnt = int(o_raw['‰∫ßÂìÅÂ∞èÁ±ª'].isna().sum()) if '‰∫ßÂìÅÂ∞èÁ±ª' in o_raw.columns else 0
                            dup_sub_cnt = int(out_subs_clean.shape[0] - out_subs_clean.nunique())
                            if empty_sub_cnt > 0:
                                st.warning(f"‚ö†Ô∏è Sheet3 ÁöÑMÂàó(‰∫ßÂìÅÂ∞èÁ±ª)Â≠òÂú®Á©∫ÂÄºÔºö{empty_sub_cnt} Ë°å")
                            if dup_sub_cnt > 0:
                                st.info(f"‚ÑπÔ∏è Sheet3 ÁöÑMÂàó(‰∫ßÂìÅÂ∞èÁ±ª)Â≠òÂú®ÈáçÂ§çÂÄºÔºö{dup_sub_cnt} Ë°åÔºà‰∏ãÊãâÂ∑≤Ëá™Âä®ÂéªÈáçÔºâ")
                            out_month_opts = list(range(1, 13))

                            oc1, oc2, oc3, oc4, oc5 = st.columns(5)
                            with oc1:
                                o_prov = st.selectbox("ÁúÅÂå∫", out_provs, key='out_s_prov')
                            with oc2:
                                if o_prov != 'ÂÖ®ÈÉ®':
                                    dists_in_prov = o_raw[o_raw['ÁúÅÂå∫'].astype(str) == str(o_prov)]['ÁªèÈîÄÂïÜÂêçÁß∞'].dropna().astype(str).unique().tolist()
                                    out_dists = ['ÂÖ®ÈÉ®'] + sorted(dists_in_prov)
                                else:
                                    out_dists = out_dists_all
                                o_dist = st.selectbox("ÁªèÈîÄÂïÜ", out_dists, key='out_s_dist')
                            with oc3:
                                o_cat = st.selectbox("‰∫ßÂìÅÂ§ßÁ±ª", out_cats, key='out_s_cat')
                            with oc4:
                                if o_cat != 'ÂÖ®ÈÉ®':
                                    subs_in_cat = o_raw[o_raw['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == str(o_cat)]['‰∫ßÂìÅÂ∞èÁ±ª'].dropna().astype(str).unique().tolist()
                                    out_subs2 = ['ÂÖ®ÈÉ®'] + sorted(subs_in_cat)
                                else:
                                    out_subs2 = out_subs
                                if 'out_s_sub' in st.session_state:
                                    st.session_state.pop('out_s_sub', None)
                                o_sub_selected = st.multiselect("‰∫ßÂìÅÂ∞èÁ±ª(ÂèØÂ§öÈÄâ)", out_subs2, default=['ÂÖ®ÈÉ®'], key='out_s_sub_ms')
                            with oc5:
                                o_months = st.multiselect("Êó∂Èó¥ÔºàÊúàÔºâ", out_month_opts, default=[10, 11, 12], key='out_s_months')

                            df_o_filtered = o_raw.copy()
                            
                            # Filter for Year 2025 (as per Q4 definition)
                            if 'Âπ¥‰ªΩ' in df_o_filtered.columns:
                                df_o_filtered = df_o_filtered[df_o_filtered['Âπ¥‰ªΩ'] == 2025]
                                
                            if o_prov != 'ÂÖ®ÈÉ®':
                                df_o_filtered = df_o_filtered[df_o_filtered['ÁúÅÂå∫'].astype(str) == str(o_prov)]
                            if o_dist != 'ÂÖ®ÈÉ®':
                                df_o_filtered = df_o_filtered[df_o_filtered['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str) == str(o_dist)]
                            if o_cat != 'ÂÖ®ÈÉ®':
                                df_o_filtered = df_o_filtered[df_o_filtered['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == str(o_cat)]
                            if o_sub_selected and ('ÂÖ®ÈÉ®' not in o_sub_selected):
                                df_o_filtered = df_o_filtered[df_o_filtered['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str).isin([str(x) for x in o_sub_selected])]

                            def _to_month(v):
                                if pd.isna(v):
                                    return None
                                if isinstance(v, (int, float)) and not pd.isna(v):
                                    m = int(v)
                                    return m if 1 <= m <= 12 else None
                                s = str(v).strip()
                                if s.isdigit():
                                    m = int(s)
                                    return m if 1 <= m <= 12 else None
                                if 'Êúà' in s:
                                    digits = ''.join([ch for ch in s if ch.isdigit()])
                                    if digits:
                                        for k in (2, 1):
                                            if len(digits) >= k:
                                                m = int(digits[-k:])
                                                if 1 <= m <= 12:
                                                    return m
                                    return None
                                dt = pd.to_datetime(s, errors='coerce')
                                if pd.isna(dt):
                                    return None
                                m = int(dt.month)
                                return m if 1 <= m <= 12 else None

                            df_o_filtered['Êúà'] = df_o_filtered['Êúà‰ªΩ'].apply(_to_month)
                            df_o_filtered = df_o_filtered[df_o_filtered['Êúà'].notna()].copy()
                            df_o_filtered['Êúà'] = df_o_filtered['Êúà'].astype(int)

                            if o_months:
                                df_o_filtered = df_o_filtered[df_o_filtered['Êúà'].isin(o_months)].copy()

                            df_o_filtered['ÊúàÂàó'] = df_o_filtered['Êúà'].astype(str) + 'Êúà'

                            idx_cols = ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', '‰∫ßÂìÅÂ§ßÁ±ª', '‰∫ßÂìÅÂ∞èÁ±ª']
                            outbound_pivot = (
                                df_o_filtered
                                .pivot_table(index=idx_cols, columns='ÊúàÂàó', values='Êï∞Èáè(ÁÆ±)', aggfunc='sum', fill_value=0)
                                .reset_index()
                            )

                            month_cols_full = [f"{i}Êúà" for i in range(1, 13)]
                            for mc in month_cols_full:
                                if mc not in outbound_pivot.columns:
                                    outbound_pivot[mc] = 0

                            outbound_pivot['Q4ÊúàÂùáÈîÄ'] = (outbound_pivot['10Êúà'] + outbound_pivot['11Êúà'] + outbound_pivot['12Êúà']) / 3
                            outbound_pivot = outbound_pivot[idx_cols + month_cols_full + ['Q4ÊúàÂùáÈîÄ']]

                            with st.expander("üìÑ Âá∫Â∫ìÂàÜÊûêÂ∫ïË°®ÔºàSheet3Ôºâ", expanded=False):
                                show_aggrid_table(outbound_pivot, height=520, key="outbound_pivot_table")

                            if not outbound_pivot.empty:
                                dist_q4 = outbound_pivot.groupby('ÁªèÈîÄÂïÜÂêçÁß∞')[['10Êúà', '11Êúà', '12Êúà']].sum().reset_index()
                                dist_q4['Q4_Total'] = dist_q4['10Êúà'] + dist_q4['11Êúà'] + dist_q4['12Êúà']
                                dist_q4['Q4_Avg'] = dist_q4['Q4_Total'] / 3
                                sales_agg_q4 = dist_q4[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Q4_Total', 'Q4_Avg']].copy()

                            out_xlsx = io.BytesIO()
                            try:
                                with pd.ExcelWriter(out_xlsx, engine='openpyxl') as writer:
                                    outbound_pivot.to_excel(writer, index=False, sheet_name='Sheet3')
                            except Exception:
                                with pd.ExcelWriter(out_xlsx, engine='xlsxwriter') as writer:
                                    outbound_pivot.to_excel(writer, index=False, sheet_name='Sheet3')
                                st.download_button(
                                    "üì• ‰∏ãËΩΩÂá∫Â∫ìÂàÜÊûêÂ∫ïË°® (Excel)",
                                    data=out_xlsx.getvalue(),
                                    file_name="Âá∫Â∫ìÂàÜÊûêÂ∫ïË°®_Sheet3.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                )
                    
                    # --- Drill-down State Management ---
                    # (Initialized at top of script)
                    
                    # Threshold Config
                    with st.expander("‚öôÔ∏è ÈòàÂÄºÈÖçÁΩÆ", expanded=False):
                        c_th1, c_th2 = st.columns(2)
                        high_th = c_th1.number_input("Â∫ìÂ≠òËøáÈ´òÈòàÂÄº (DOS >)", value=2.0, step=0.1)
                        low_th = c_th2.number_input("Â∫ìÂ≠òËøá‰ΩéÈòàÂÄº (DOS <)", value=0.5, step=0.1)

                    # Logic:
                    # 1. Sum Stock 'ÁÆ±Êï∞' by Distributor (from filtered stock df_s_filtered)
                    # 2. Match with Sheet3 Sales 'Q4_Avg' by Distributor
                    
                    # Note: df_s_filtered 'ÁªèÈîÄÂïÜÂêçÁß∞' is now 'ÂÆ¢Êà∑ÁÆÄÁß∞' (H column) due to load_data mapping
                    stock_agg = df_s_filtered.groupby(['ÁúÅÂå∫ÂêçÁß∞', 'ÁªèÈîÄÂïÜÂêçÁß∞'])['ÁÆ±Êï∞'].sum().reset_index()
                    stock_agg.rename(columns={'ÁÆ±Êï∞': 'ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±'}, inplace=True)
                    stock_agg['ÁªèÈîÄÂïÜÂêçÁß∞'] = stock_agg['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.strip()
                    
                    # Merge with Q4 sales data from Sheet3
                    # LEFT JOIN ensures we only keep distributors present in the STOCK file (filtered by top filters)
                    # However, if we filter by province in top filter, df_s_filtered only has that province.
                    # sales_agg_q4 has ALL distributors from Sheet3.
                    # Merging them attaches Sales info to the Stock info.
                    analysis_df = pd.merge(stock_agg, sales_agg_q4[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Q4_Avg']], on='ÁªèÈîÄÂïÜÂêçÁß∞', how='left')
                    analysis_df['Q4_Avg'] = analysis_df['Q4_Avg'].fillna(0)
                    
                    # 3. Calc DOS & Status
                    analysis_df['Ëøë‰∏âÊúàÊú™Âá∫Â∫ì'] = (analysis_df['Q4_Avg'] <= 0) & (analysis_df['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±'] > 0)

                    # Calculate DOS
                    # Optimized: Vectorized
                    q4_avg_series = analysis_df['Q4_Avg']
                    stock_series = analysis_df['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±']
                    mask_no_outbound = analysis_df.get('Ëøë‰∏âÊúàÊú™Âá∫Â∫ì', pd.Series(False, index=analysis_df.index)).astype(bool)
                    
                    analysis_df['ÂèØÈîÄÊúà(DOS)'] = np.where(
                        mask_no_outbound, np.nan,
                        np.where(
                            q4_avg_series <= 0, 0.0,
                            (stock_series / q4_avg_series)
                        )
                    )
                    
                    # Ensure thresholds are defined before use
                    if 'high_th' not in locals(): high_th = 2.0
                    if 'low_th' not in locals(): low_th = 0.5

                    # Optimized: Vectorized select
                    # Pre-calculate boolean mask for 'Ëøë‰∏âÊúàÊú™Âá∫Â∫ì'
                    mask_no_outbound = analysis_df.get('Ëøë‰∏âÊúàÊú™Âá∫Â∫ì', pd.Series(False, index=analysis_df.index)).astype(bool)
                    
                    dos_series = analysis_df['ÂèØÈîÄÊúà(DOS)']
                    
                    conditions = [
                        mask_no_outbound,
                        pd.isna(dos_series),
                        dos_series > high_th,
                        dos_series < low_th
                    ]
                    choices = [
                        '‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì',
                        'üü¢ Ê≠£Â∏∏',
                        'üî¥ Â∫ìÂ≠òËøáÈ´ò',
                        'üü† Â∫ìÂ≠ò‰∏çË∂≥'
                    ]
                    analysis_df['Â∫ìÂ≠òÁä∂ÊÄÅ'] = np.select(conditions, choices, default='üü¢ Ê≠£Â∏∏')

                    # --- OVERVIEW METRICS (Moved Back & Enhanced) ---
                    # Calculate metrics based on the CURRENT context (filtered data analysis_df)
                    # If drill level is 1 (All Provs), it shows total.
                    # If drill level is 2 (One Prov), we should filter analysis_df to that prov for metrics?
                    # Or should metrics always reflect the TOP filters (df_s_filtered)?
                    # User request: "When I select a specific province (in filter), real-time update."
                    # df_s_filtered IS filtered by the top dropdowns. analysis_df is derived from it.
                    # So calculating from analysis_df is correct for the top filters.
                    # However, if user clicks "Drill Down" to level 2, should the metrics update to that province?
                    # User said "When I select to specific province". 
                    # If the user uses the *Sidebar/Top Filter*, df_s_filtered updates, so analysis_df updates.
                    # If the user uses *Drill Down*, st.session_state.selected_prov is set.
                    # Usually Overview Metrics reflect the *Global Context* of the current view.
                    # Let's support both: If Drill Level > 1, filter metrics to selected scope.
                    
                    metrics_df = analysis_df.copy()
                    if st.session_state.drill_level == 2 and st.session_state.selected_prov:
                        metrics_df = metrics_df[metrics_df['ÁúÅÂå∫ÂêçÁß∞'] == st.session_state.selected_prov]
                    elif st.session_state.drill_level == 3 and st.session_state.selected_dist:
                        # For level 3, it's single distributor
                         metrics_df = metrics_df[metrics_df['ÁªèÈîÄÂïÜÂêçÁß∞'] == st.session_state.selected_dist]

                    # Calc Metrics
                    total_stock_show = metrics_df['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±'].sum()
                    if sales_agg_q4 is not None and not sales_agg_q4.empty and 'Q4_Total' in sales_agg_q4.columns:
                        dist_scope = (
                            metrics_df['ÁªèÈîÄÂïÜÂêçÁß∞']
                            .dropna()
                            .astype(str)
                            .str.strip()
                            .unique()
                            .tolist()
                        )
                        sales_scope = sales_agg_q4[sales_agg_q4['ÁªèÈîÄÂïÜÂêçÁß∞'].isin(dist_scope)].copy()
                        total_q4_avg_show = float(sales_scope['Q4_Total'].sum()) / 3 if not sales_scope.empty else 0.0
                    else:
                        total_q4_avg_show = 0.0
                    
                    # DOS = Total Stock / Total Sales
                    if total_q4_avg_show > 0:
                        dos_show = total_stock_show / total_q4_avg_show
                    else:
                        dos_show = 0.0
                    
                    if metrics_df is None or metrics_df.empty or 'Â∫ìÂ≠òÁä∂ÊÄÅ' not in metrics_df.columns:
                        abnormal_count_show = 0
                    else:
                        abnormal_count_show = int(
                            metrics_df['Â∫ìÂ≠òÁä∂ÊÄÅ']
                            .fillna('')
                            .astype(str)
                            .str.contains('üî¥|üü†|‚ö´', na=False)
                            .sum()
                        )
                    
                    st.markdown("### üìä ÂÖ≥ÈîÆÊåáÊ†áÊ¶ÇËßà")
                    col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                    col_m1.metric("üì¶ ÊÄªÂ∫ìÂ≠ò (ÁÆ±)", fmt_num(total_stock_show))
                    col_m2.metric("üìâ Q4ÊúàÂùáÈîÄ", fmt_num(total_q4_avg_show))
                    col_m3.metric("üìÖ Êï¥‰ΩìÂèØÈîÄÊúà", fmt_num(dos_show))
                    col_m4.metric("üö® ÂºÇÂ∏∏ÂÆ¢Êà∑Êï∞", f"{abnormal_count_show} ÂÆ∂")
                    st.markdown("---")

                    rank_stock = (
                        metrics_df.groupby('ÁªèÈîÄÂïÜÂêçÁß∞', as_index=False)['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±']
                        .sum()
                        .rename(columns={'ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±': 'Â∫ìÂ≠òÊï∞(ÁÆ±)'})
                    )
                    rank_stock['ÁªèÈîÄÂïÜÂêçÁß∞'] = rank_stock['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str).str.strip()
                    rank_stock = pd.merge(
                        rank_stock,
                        sales_agg_q4[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Q4_Avg']] if (sales_agg_q4 is not None and 'Q4_Avg' in sales_agg_q4.columns) else pd.DataFrame(columns=['ÁªèÈîÄÂïÜÂêçÁß∞', 'Q4_Avg']),
                        on='ÁªèÈîÄÂïÜÂêçÁß∞',
                        how='left'
                    )
                    rank_stock['Q4_Avg'] = pd.to_numeric(rank_stock.get('Q4_Avg', 0), errors='coerce').fillna(0)
                    rank_stock['Ëøë‰∏âÊúàÊú™Âá∫Â∫ì'] = (rank_stock['Q4_Avg'] <= 0) & (rank_stock['Â∫ìÂ≠òÊï∞(ÁÆ±)'] > 0)

                    def _rank_dos(row):
                        q4 = float(row.get('Q4_Avg', 0) or 0)
                        stk = float(row.get('Â∫ìÂ≠òÊï∞(ÁÆ±)', 0) or 0)
                        if q4 <= 0:
                            return float('nan') if stk > 0 else 0.0
                        return stk / q4

                    rank_stock['ÂèØÈîÄÊúà'] = rank_stock.apply(_rank_dos, axis=1)
                    rank_stock['ËøáÈ´òÂ∑ÆÂÄº'] = (rank_stock['ÂèØÈîÄÊúà'] - float(high_th))
                    rank_stock['Ëøá‰ΩéÂ∑ÆÂÄº'] = (float(low_th) - rank_stock['ÂèØÈîÄÊúà'])

                    rank_stock_rankable = rank_stock[~rank_stock['Ëøë‰∏âÊúàÊú™Âá∫Â∫ì']].copy()
                    high_top = rank_stock_rankable[rank_stock_rankable['ËøáÈ´òÂ∑ÆÂÄº'] > 0].copy().sort_values('ËøáÈ´òÂ∑ÆÂÄº', ascending=False).head(10)
                    low_top = rank_stock_rankable[rank_stock_rankable['Ëøá‰ΩéÂ∑ÆÂÄº'] > 0].copy().sort_values('Ëøá‰ΩéÂ∑ÆÂÄº', ascending=False).head(10)

                    st.markdown("### üèÜ ÂºÇÂ∏∏Â∫ìÂ≠òTOP10ÁªèÈîÄÂïÜ")
                    r1, r2 = st.columns(2)
                    with r1:
                        st.subheader("üî¥ Â∫ìÂ≠òËøáÈ´ò TOP10")
                        if high_top.empty:
                            st.info("ÂΩìÂâçËåÉÂõ¥Êó†Â∫ìÂ≠òËøáÈ´òÁªèÈîÄÂïÜ")
                        else:
                            high_chart = high_top.sort_values('ËøáÈ´òÂ∑ÆÂÄº', ascending=True).copy()
                            high_chart['Ê†áÊ≥®'] = high_chart['ËøáÈ´òÂ∑ÆÂÄº'].map(lambda x: f"+{fmt_num(x, na='')}")
                            high_chart['_Â∫ìÂ≠òÊï∞_fmt'] = high_chart['Â∫ìÂ≠òÊï∞(ÁÆ±)'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_q4_fmt'] = high_chart['Q4_Avg'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_dos_fmt'] = high_chart['ÂèØÈîÄÊúà'].map(lambda x: fmt_num(x, na=''))
                            high_chart['_diff_fmt'] = high_chart['ËøáÈ´òÂ∑ÆÂÄº'].map(lambda x: fmt_num(x, na=''))
                            fig_high = px.bar(
                                high_chart,
                                x='ËøáÈ´òÂ∑ÆÂÄº',
                                y='ÁªèÈîÄÂïÜÂêçÁß∞',
                                orientation='h',
                                text='Ê†áÊ≥®',
                                title="Ë∂ÖÂá∫ËøáÈ´òÈòàÂÄºÁöÑÂ∑ÆÂÄºÔºàÂèØÈîÄÊúà - ÈòàÂÄºÔºâ",
                                color_discrete_sequence=['#E5484D'],
                                custom_data=['_Â∫ìÂ≠òÊï∞_fmt', '_q4_fmt', '_dos_fmt', '_diff_fmt']
                            )
                            fig_high.update_traces(
                                textposition='outside',
                                hovertemplate=(
                                    "ÁªèÈîÄÂïÜ: %{y}<br>"
                                    "Â∫ìÂ≠òÊï∞(ÁÆ±): %{customdata[0]}<br>"
                                    "Q4ÊúàÂùáÈîÄ: %{customdata[1]}<br>"
                                    "ÂèØÈîÄÊúà: %{customdata[2]}<br>"
                                    "Ë∂ÖÈòàÂÄºÂ∑ÆÂÄº: +%{customdata[3]}<extra></extra>"
                                )
                            )
                            fig_high.update_layout(height=420, xaxis_title="Â∑ÆÂÄº", yaxis_title="")
                            st.plotly_chart(fig_high, use_container_width=True)
                            show_aggrid_table(high_top[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Â∫ìÂ≠òÊï∞(ÁÆ±)', 'Q4_Avg', 'ÂèØÈîÄÊúà', 'ËøáÈ´òÂ∑ÆÂÄº']], height=250, key='high_stock_ag')

                    with r2:
                        st.subheader("üü† Â∫ìÂ≠òËøá‰Ωé TOP10")
                        if low_top.empty:
                            st.info("ÂΩìÂâçËåÉÂõ¥Êó†Â∫ìÂ≠òËøá‰ΩéÁªèÈîÄÂïÜ")
                        else:
                            low_chart = low_top.sort_values('Ëøá‰ΩéÂ∑ÆÂÄº', ascending=True).copy()
                            low_chart['Ê†áÊ≥®'] = low_chart['Ëøá‰ΩéÂ∑ÆÂÄº'].map(lambda x: f"+{fmt_num(x, na='')}")
                            low_chart['_Â∫ìÂ≠òÊï∞_fmt'] = low_chart['Â∫ìÂ≠òÊï∞(ÁÆ±)'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_q4_fmt'] = low_chart['Q4_Avg'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_dos_fmt'] = low_chart['ÂèØÈîÄÊúà'].map(lambda x: fmt_num(x, na=''))
                            low_chart['_diff_fmt'] = low_chart['Ëøá‰ΩéÂ∑ÆÂÄº'].map(lambda x: fmt_num(x, na=''))
                            fig_low = px.bar(
                                low_chart,
                                x='Ëøá‰ΩéÂ∑ÆÂÄº',
                                y='ÁªèÈîÄÂïÜÂêçÁß∞',
                                orientation='h',
                                text='Ê†áÊ≥®',
                                title="‰Ωé‰∫éËøá‰ΩéÈòàÂÄºÁöÑÂ∑ÆÂÄºÔºàÈòàÂÄº - ÂèØÈîÄÊúàÔºâ",
                                color_discrete_sequence=['#FFB000'],
                                custom_data=['_Â∫ìÂ≠òÊï∞_fmt', '_q4_fmt', '_dos_fmt', '_diff_fmt']
                            )
                            fig_low.update_traces(
                                textposition='outside',
                                hovertemplate=(
                                    "ÁªèÈîÄÂïÜ: %{y}<br>"
                                    "Â∫ìÂ≠òÊï∞(ÁÆ±): %{customdata[0]}<br>"
                                    "Q4ÊúàÂùáÈîÄ: %{customdata[1]}<br>"
                                    "ÂèØÈîÄÊúà: %{customdata[2]}<br>"
                                    "‰Ωé‰∫éÈòàÂÄºÂ∑ÆÂÄº: +%{customdata[3]}<extra></extra>"
                                )
                            )
                            fig_low.update_layout(height=420, xaxis_title="Â∑ÆÂÄº", yaxis_title="")
                            st.plotly_chart(fig_low, use_container_width=True)
                            show_aggrid_table(low_top[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Â∫ìÂ≠òÊï∞(ÁÆ±)', 'Q4_Avg', 'ÂèØÈîÄÊúà', 'Ëøá‰ΩéÂ∑ÆÂÄº']], height=250, key='low_stock_ag')

                    with st.expander("üîç ÂØπË¥¶‰ø°ÊÅØ", expanded=False):
                        if df_o_filtered is None or df_o_filtered.empty or 'Êúà' not in df_o_filtered.columns:
                            st.warning("ÂΩìÂâçÁ≠õÈÄâ‰∏ãÊó†Âá∫Â∫ìÊòéÁªÜÂèØÂØπË¥¶„ÄÇ")
                        else:
                            s10 = float(df_o_filtered[df_o_filtered['Êúà'] == 10]['Êï∞Èáè(ÁÆ±)'].sum()) if 'Êï∞Èáè(ÁÆ±)' in df_o_filtered.columns else 0.0
                            s11 = float(df_o_filtered[df_o_filtered['Êúà'] == 11]['Êï∞Èáè(ÁÆ±)'].sum()) if 'Êï∞Èáè(ÁÆ±)' in df_o_filtered.columns else 0.0
                            s12 = float(df_o_filtered[df_o_filtered['Êúà'] == 12]['Êï∞Èáè(ÁÆ±)'].sum()) if 'Êï∞Èáè(ÁÆ±)' in df_o_filtered.columns else 0.0
                            st.write(f"ÂΩìÂâçÁ≠õÈÄâ‰∏ãSheet3ÂêàËÆ°Ôºö10Êúà={fmt_num(s10)}Ôºå11Êúà={fmt_num(s11)}Ôºå12Êúà={fmt_num(s12)}")
                            st.write(f"ÂΩìÂâçÁ≠õÈÄâ‰∏ãQ4ÊúàÂùáÈîÄ=(10+11+12)/3 = {fmt_num((s10+s11+s12)/3)}")
                            if sales_agg_q4 is not None and 'Q4_Total' in sales_agg_q4.columns:
                                dist_scope_dbg = (
                                    metrics_df['ÁªèÈîÄÂïÜÂêçÁß∞']
                                    .dropna()
                                    .astype(str)
                                    .str.strip()
                                    .unique()
                                    .tolist()
                                )
                                matched = sales_agg_q4[sales_agg_q4['ÁªèÈîÄÂïÜÂêçÁß∞'].isin(dist_scope_dbg)]
                                st.write(f"ÂΩìÂâçËåÉÂõ¥ÁªèÈîÄÂïÜÊï∞(ÂéªÈáç)Ôºö{len(dist_scope_dbg)}ÔºåSheet3ÂåπÈÖçÂà∞Ôºö{len(matched)}")
                                st.write(f"ÂΩìÂâçËåÉÂõ¥Q4ÊúàÂùáÈîÄ=(sum(Q4_Total))/3 = {fmt_num(float(matched['Q4_Total'].sum())/3)}")

                    # --- Navigation & Breadcrumbs ---
                    cols_nav = st.columns([1, 8])
                    if st.session_state.drill_level > 1:
                        if cols_nav[0].button("‚¨ÖÔ∏è ËøîÂõû"):
                            st.session_state.drill_level -= 1
                            st.rerun()
                    
                    breadcrumbs = "üè† ÂÖ®ÈÉ®ÁúÅÂå∫"
                    if st.session_state.drill_level >= 2:
                        breadcrumbs += f" > üìç {st.session_state.selected_prov}"
                    if st.session_state.drill_level >= 3:
                        breadcrumbs += f" > üè¢ {st.session_state.selected_dist}"
                    cols_nav[1].markdown(f"**ÂΩìÂâç‰ΩçÁΩÆ**: {breadcrumbs}")

                    # --- Level 1: Province View ---
                    if st.session_state.drill_level == 1:
                        
                        # Agg by Prov
                        prov_agg = analysis_df.groupby('ÁúÅÂå∫ÂêçÁß∞').agg({
                            'ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±': 'sum',
                            'Q4_Avg': 'sum',
                            'ÁªèÈîÄÂïÜÂêçÁß∞': 'count' # Count of distributors
                        }).reset_index()
                        
                        # Calc Prov DOS
                        prov_agg['ÂèØÈîÄÊúà(DOS)'] = prov_agg.apply(lambda x: (x['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±'] / x['Q4_Avg']) if x['Q4_Avg'] > 0 else (float('nan') if x['ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±'] > 0 else 0.0), axis=1)
                        
                        # Count Abnormal Distributors per Prov
                        abnormal_counts = analysis_df.groupby('ÁúÅÂå∫ÂêçÁß∞')['Â∫ìÂ≠òÁä∂ÊÄÅ'].value_counts().unstack(fill_value=0)
                        if 'üî¥ Â∫ìÂ≠òËøáÈ´ò' not in abnormal_counts.columns: abnormal_counts['üî¥ Â∫ìÂ≠òËøáÈ´ò'] = 0
                        if 'üü† Â∫ìÂ≠ò‰∏çË∂≥' not in abnormal_counts.columns: abnormal_counts['üü† Â∫ìÂ≠ò‰∏çË∂≥'] = 0
                        if '‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì' not in abnormal_counts.columns: abnormal_counts['‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì'] = 0
                        
                        prov_view = pd.merge(prov_agg, abnormal_counts[['üî¥ Â∫ìÂ≠òËøáÈ´ò', 'üü† Â∫ìÂ≠ò‰∏çË∂≥', '‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì']], on='ÁúÅÂå∫ÂêçÁß∞', how='left').fillna(0)
                        
                        # New Logic: Calculate Total Abnormal Count and Sort
                        prov_view['ÂêàËÆ°ÂºÇÂ∏∏Êï∞'] = prov_view['üî¥ Â∫ìÂ≠òËøáÈ´ò'] + prov_view['üü† Â∫ìÂ≠ò‰∏çË∂≥'] + prov_view['‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì']
                        prov_view['ÁªèÈîÄÂïÜÊÄªÊï∞'] = prov_view['ÁªèÈîÄÂïÜÂêçÁß∞'] # Rename for clarity
                        
                        # Filter slider
                        max_abnormal = int(prov_view['ÂêàËÆ°ÂºÇÂ∏∏Êï∞'].max()) if not prov_view.empty else 10
                        c_filter, _ = st.columns([1, 2])
                        min_abnormal_filter = c_filter.slider("üîé ÂºÇÂ∏∏Êï∞ËøáÊª§ (‚â•)", 0, max_abnormal, 0)
                        
                        prov_view_filtered = prov_view[prov_view['ÂêàËÆ°ÂºÇÂ∏∏Êï∞'] >= min_abnormal_filter].copy()
                        
                        # Sort Descending by Total Abnormal Count
                        prov_view_filtered = prov_view_filtered.sort_values('ÂêàËÆ°ÂºÇÂ∏∏Êï∞', ascending=False)
                        
                        st.markdown("### üìã ÁúÅÂå∫Â∫ìÂ≠òÂºÇÂ∏∏ËØ¶ÊÉÖÂàóË°®")
                        st.caption("üí° ÊèêÁ§∫Ôºö**Áõ¥Êé•ÁÇπÂáªË°®Ê†º‰∏≠ÁöÑÊüê‰∏ÄË°å**ÔºåÂç≥ÂèØ‰∏ãÈíªÊü•ÁúãËØ•ÁúÅÂå∫ÁöÑÁªèÈîÄÂïÜËØ¶ÊÉÖ„ÄÇ")
                        
                        # Prepare DF for display
                        display_df = prov_view_filtered[["ÁúÅÂå∫ÂêçÁß∞", "ÂêàËÆ°ÂºÇÂ∏∏Êï∞", "üî¥ Â∫ìÂ≠òËøáÈ´ò", "üü† Â∫ìÂ≠ò‰∏çË∂≥", "‚ö´ Ëøë‰∏âÊúàÊú™Âá∫Â∫ì", "ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±", "Q4_Avg", "ÂèØÈîÄÊúà(DOS)"]].reset_index(drop=True)
                        
                        # Use interactive dataframe with selection
                        # Dynamic height to show all rows
                        n_rows = len(display_df)
                        # Estimate height: 35px per row + 35px header + buffer
                        calc_height = (n_rows + 1) * 35 + 10
                        # Ensure a minimum height and reasonable max height (e.g., 2000px)
                        final_height = max(150, min(calc_height, 2000))

                        ag_inv = show_aggrid_table(
                            display_df,
                            height=final_height,
                            columns_props={'ÂêàËÆ°ÂºÇÂ∏∏Êï∞': {'type': 'bar_count'}, 'ÂèØÈîÄÊúà(DOS)': {'type': 'number'}},
                            on_row_selected='single',
                            key='inv_prov_ag'
                        )
                        
                        # Show all province names as tags below for quick view
                        with st.expander("Êü•ÁúãÊâÄÊúâÁúÅÂå∫ÂêçÁß∞ÂàóË°® (ÁÇπÂáªÂ±ïÂºÄ)", expanded=False):
                            st.markdown("  ".join([f"`{p}`" for p in display_df['ÁúÅÂå∫ÂêçÁß∞'].tolist()]))
                        
                        # Handle Selection
                        selected_rows = ag_inv.get('selected_rows') if ag_inv else None
                        if selected_rows is not None and len(selected_rows) > 0:
                            if isinstance(selected_rows, pd.DataFrame):
                                first_row = selected_rows.iloc[0]
                            else:
                                first_row = selected_rows[0]
                            
                            selected_prov_name = first_row.get("ÁúÅÂå∫ÂêçÁß∞") if isinstance(first_row, dict) else first_row["ÁúÅÂå∫ÂêçÁß∞"]
                            st.session_state.selected_prov = selected_prov_name
                            st.session_state.drill_level = 2
                            st.rerun()

                        # Visualization: Stacked Bar Chart of Abnormalities
                        if not prov_view_filtered.empty:
                            fig_abnormal = px.bar(
                                prov_view_filtered,
                                x='ÁúÅÂå∫ÂêçÁß∞',
                                y=['üî¥ Â∫ìÂ≠òËøáÈ´ò', 'üü† Â∫ìÂ≠ò‰∏çË∂≥'],
                                title='ÂêÑÁúÅÂºÇÂ∏∏Â∫ìÂ≠òÂàÜÂ∏É',
                                labels={'value': 'ÁªèÈîÄÂïÜÊï∞Èáè', 'variable': 'ÂºÇÂ∏∏Á±ªÂûã'},
                                color_discrete_map={'üî¥ Â∫ìÂ≠òËøáÈ´ò': '#E5484D', 'üü† Â∫ìÂ≠ò‰∏çË∂≥': '#FFB000'}
                            )
                            fig_abnormal.update_layout(height=350, margin=dict(l=20, r=20, t=40, b=20))
                            st.plotly_chart(fig_abnormal, use_container_width=True)

                    # --- Level 2: Distributor View ---
                    elif st.session_state.drill_level == 2:
                        prov = st.session_state.selected_prov
                        st.caption("üí° ÊèêÁ§∫Ôºö**ÁÇπÂáªË°®Ê†ºË°å** ÂèØÊü•ÁúãËØ•ÁªèÈîÄÂïÜÁöÑ SKU Â∫ìÂ≠òÊòéÁªÜ„ÄÇ")
                        
                        # Filter by Prov
                        dist_view = analysis_df[analysis_df['ÁúÅÂå∫ÂêçÁß∞'] == prov].copy().reset_index(drop=True)
                        
                        # Interactive Table
                        ag_dist_inv = show_aggrid_table(
                            dist_view[['ÁªèÈîÄÂïÜÂêçÁß∞', 'ÂΩìÂâçÂ∫ìÂ≠ò_ÁÆ±', 'Q4_Avg', 'ÂèØÈîÄÊúà(DOS)', 'Â∫ìÂ≠òÁä∂ÊÄÅ']],
                            height=520,
                            columns_props={'ÂèØÈîÄÊúà(DOS)': {'type': 'number'}},
                            on_row_selected='single',
                            key='inv_dist_ag'
                        )
                        
                        # Handle Selection
                        selected_rows_d = ag_dist_inv.get('selected_rows') if ag_dist_inv else None
                        if selected_rows_d is not None and len(selected_rows_d) > 0:
                            if isinstance(selected_rows_d, pd.DataFrame):
                                first_row_d = selected_rows_d.iloc[0]
                            else:
                                first_row_d = selected_rows_d[0]
                            
                            selected_dist_name = first_row_d.get("ÁªèÈîÄÂïÜÂêçÁß∞") if isinstance(first_row_d, dict) else first_row_d["ÁªèÈîÄÂïÜÂêçÁß∞"]
                            st.session_state.selected_dist = selected_dist_name
                            st.session_state.drill_level = 3
                            st.rerun()

                    # --- Level 3: SKU/Store View ---
                    elif st.session_state.drill_level == 3:
                        dist = st.session_state.selected_dist
                        
                        # Get SKU details for this distributor from filtered stock data
                        # Note: We don't have store-level sales in Sheet3 (only Dist level), 
                        # so we can only show Stock Details here, potentially calculating SKU-level DOS if we had SKU-level sales (which we don't from Sheet3).
                        # We will show SKU stock details.
                        
                        sku_view = df_s_filtered[df_s_filtered['ÁªèÈîÄÂïÜÂêçÁß∞'] == dist][['‰∫ßÂìÅÂêçÁß∞', '‰∫ßÂìÅÁºñÁ†Å', 'ÁÆ±Êï∞', 'ËßÑÊ†º', 'ÈáçÈáè']].copy()
                        
                        show_aggrid_table(sku_view, height=520, key='inv_sku_ag')
                        st.caption("Ê≥®ÔºöÂõ†Q4Âá∫Â∫ìÊï∞ÊçÆ‰ªÖÁ≤æÁ°ÆÂà∞ÁªèÈîÄÂïÜÂ±ÇÁ∫ßÔºåÊ≠§Â§Ñ‰ªÖÂ±ïÁ§∫SKUÂ∫ìÂ≠òÊòéÁªÜÔºå‰∏çËÆ°ÁÆóÂçïÂìÅDOS„ÄÇ")

            with tab_out:
                if df_q4_raw is None or df_q4_raw.empty:
                    st.warning("‚ö†Ô∏è Êú™Ê£ÄÊµãÂà∞Âá∫Â∫ìÊï∞ÊçÆ (Sheet3)„ÄÇËØ∑Á°ÆËÆ§ExcelÂåÖÂê´Sheet3‰∏îÊï∞ÊçÆÂÆåÊï¥„ÄÇ")
                    with st.expander("üõ†Ô∏è Ë∞ÉËØï‰ø°ÊÅØ", expanded=False):
                        for log in debug_logs:
                            st.text(log)
                else:
                    st.caption(f"üïí Êï∞ÊçÆÊõ¥Êñ∞Êó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

                    o_raw = df_q4_raw.copy()

                    if '‰∫ßÂìÅÂ§ßÁ±ª' not in o_raw.columns:
                        o_raw['‰∫ßÂìÅÂ§ßÁ±ª'] = 'ÂÖ®ÈÉ®'
                    if '‰∫ßÂìÅÂ∞èÁ±ª' not in o_raw.columns:
                        o_raw['‰∫ßÂìÅÂ∞èÁ±ª'] = 'ÂÖ®ÈÉ®'

                    day_col = next((c for c in o_raw.columns if str(c).strip() == 'Êó•'), None)
                    if day_col is None:
                        day_col = next((c for c in o_raw.columns if ('Êó•Êúü' in str(c)) or (str(c).strip().endswith('Êó•') and 'Êúà' not in str(c))), None)
                    if day_col is None and len(o_raw.columns) > 14:
                        day_col = o_raw.columns[14]

                    store_name_col = o_raw.columns[5] if len(o_raw.columns) > 5 else None

                    if 'Êï∞Èáè(ÁÆ±)' in o_raw.columns:
                        o_raw['Êï∞Èáè(ÁÆ±)'] = pd.to_numeric(o_raw['Êï∞Èáè(ÁÆ±)'], errors='coerce').fillna(0.0)
                    else:
                        o_raw['Êï∞Èáè(ÁÆ±)'] = 0.0

                    if store_name_col is not None and store_name_col in o_raw.columns:
                        o_raw['_Èó®Â∫óÂêç'] = (
                            o_raw[store_name_col]
                            .fillna('')
                            .astype(str)
                            .str.replace(r'\s+', '', regex=True)
                        )
                        o_raw.loc[o_raw['_Èó®Â∫óÂêç'].isin(['', 'nan', 'None', 'NULL', 'NaN']), '_Èó®Â∫óÂêç'] = pd.NA
                    else:
                        o_raw['_Èó®Â∫óÂêç'] = pd.NA

                    def _to_month(v):
                        if pd.isna(v):
                            return None
                        if isinstance(v, (int, float)) and not pd.isna(v):
                            m = int(v)
                            return m if 1 <= m <= 12 else None
                        s = str(v).strip()
                        if s.isdigit():
                            m = int(s)
                            return m if 1 <= m <= 12 else None
                        if 'Êúà' in s:
                            digits = ''.join([ch for ch in s if ch.isdigit()])
                            if digits:
                                for k in (2, 1):
                                    if len(digits) >= k:
                                        m = int(digits[-k:])
                                        if 1 <= m <= 12:
                                            return m
                            return None
                        dt = pd.to_datetime(s, errors='coerce')
                        if pd.isna(dt):
                            return None
                        m = int(dt.month)
                        return m if 1 <= m <= 12 else None

                    def _to_day(v):
                        if pd.isna(v):
                            return None
                        if isinstance(v, (int, float)) and not pd.isna(v):
                            d = int(v)
                            return d if 1 <= d <= 31 else None
                        s = str(v).strip()
                        digits = ''.join([ch for ch in s if ch.isdigit()])
                        if not digits:
                            return None
                        d = int(digits[-2:]) if len(digits) >= 2 else int(digits)
                        return d if 1 <= d <= 31 else None

                    if 'Âπ¥‰ªΩ' in o_raw.columns:
                        o_raw['_Âπ¥'] = pd.to_numeric(o_raw['Âπ¥‰ªΩ'], errors='coerce').fillna(0).astype(int)
                    else:
                        o_raw['_Âπ¥'] = 0
                    if 'Êúà‰ªΩ' in o_raw.columns:
                        o_raw['_Êúà'] = o_raw['Êúà‰ªΩ'].apply(_to_month)
                    else:
                        o_raw['_Êúà'] = None

                    if day_col is not None and day_col in o_raw.columns:
                        if 'Êó•Êúü' in str(day_col):
                            dt_series = pd.to_datetime(o_raw[day_col], errors='coerce')
                            o_raw['_Âπ¥'] = np.where(dt_series.notna(), dt_series.dt.year, o_raw['_Âπ¥']).astype(int)
                            o_raw['_Êúà'] = np.where(dt_series.notna(), dt_series.dt.month, o_raw['_Êúà'])
                            o_raw['_Êó•'] = np.where(dt_series.notna(), dt_series.dt.day, None)
                        else:
                            o_raw['_Êó•'] = o_raw[day_col].apply(_to_day)
                    else:
                        o_raw['_Êó•'] = None

                    o_raw = o_raw[o_raw['_Âπ¥'] > 0].copy()
                    o_raw = o_raw[o_raw['_Êúà'].notna()].copy()
                    o_raw['_Êúà'] = o_raw['_Êúà'].astype(int)
                    o_raw['_Êó•'] = pd.to_numeric(o_raw['_Êó•'], errors='coerce')

                    with st.expander("üõ†Ô∏è Âá∫Â∫ìÁ≠õÈÄâ", expanded=False):
                        out_provs = ['ÂÖ®ÈÉ®'] + sorted(o_raw['ÁúÅÂå∫'].dropna().astype(str).unique().tolist()) if 'ÁúÅÂå∫' in o_raw.columns else ['ÂÖ®ÈÉ®']
                        oc1, oc2, oc3, oc4, oc5 = st.columns(5)
                        with oc1:
                            o_prov = st.selectbox("ÁúÅÂå∫", out_provs, key='out2_prov')
                        with oc2:
                            if 'ÁªèÈîÄÂïÜÂêçÁß∞' in o_raw.columns:
                                if o_prov != 'ÂÖ®ÈÉ®' and 'ÁúÅÂå∫' in o_raw.columns:
                                    dists_in_prov = o_raw[o_raw['ÁúÅÂå∫'].astype(str) == str(o_prov)]['ÁªèÈîÄÂïÜÂêçÁß∞'].dropna().astype(str).unique().tolist()
                                    out_dists = ['ÂÖ®ÈÉ®'] + sorted(dists_in_prov)
                                else:
                                    out_dists = ['ÂÖ®ÈÉ®'] + sorted(o_raw['ÁªèÈîÄÂïÜÂêçÁß∞'].dropna().astype(str).unique().tolist())
                            else:
                                out_dists = ['ÂÖ®ÈÉ®']
                            o_dist = st.selectbox("ÁªèÈîÄÂïÜ", out_dists, key='out2_dist')
                        with oc3:
                            out_cats = ['ÂÖ®ÈÉ®'] + sorted(o_raw['‰∫ßÂìÅÂ§ßÁ±ª'].dropna().astype(str).unique().tolist())
                            o_cat = st.selectbox("‰∫ßÂìÅÂ§ßÁ±ª", out_cats, key='out2_cat')
                        with oc4:
                            if o_cat != 'ÂÖ®ÈÉ®':
                                subs_in_cat = o_raw[o_raw['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == str(o_cat)]['‰∫ßÂìÅÂ∞èÁ±ª'].dropna().astype(str).unique().tolist()
                                out_subs = ['ÂÖ®ÈÉ®'] + sorted(subs_in_cat)
                            else:
                                out_subs = ['ÂÖ®ÈÉ®'] + sorted(o_raw['‰∫ßÂìÅÂ∞èÁ±ª'].dropna().astype(str).unique().tolist())
                            o_sub = st.selectbox("‰∫ßÂìÅÂ∞èÁ±ª", out_subs, key='out2_sub')
                        with oc5:
                            year_opts = sorted([int(y) for y in o_raw['_Âπ¥'].dropna().unique().tolist() if int(y) > 0])
                            default_year = 2025 if 2025 in year_opts else (max(year_opts) if year_opts else 2025)
                            y_index = year_opts.index(default_year) if default_year in year_opts else 0
                            o_year = st.selectbox("Âπ¥‰ªΩ", year_opts if year_opts else [2025], index=y_index, key='out2_year')
                            month_in_year = sorted([int(m) for m in o_raw[o_raw['_Âπ¥'] == int(o_year)]['_Êúà'].dropna().unique().tolist() if 1 <= int(m) <= 12])
                            month_opts = ['ÂÖ®ÈÉ®'] + month_in_year
                            o_month = st.selectbox("Êúà‰ªΩ", month_opts, index=0, key='out2_month')

                    df_o = o_raw.copy()
                    if o_prov != 'ÂÖ®ÈÉ®' and 'ÁúÅÂå∫' in df_o.columns:
                        df_o = df_o[df_o['ÁúÅÂå∫'].astype(str) == str(o_prov)]
                    if o_dist != 'ÂÖ®ÈÉ®' and 'ÁªèÈîÄÂïÜÂêçÁß∞' in df_o.columns:
                        df_o = df_o[df_o['ÁªèÈîÄÂïÜÂêçÁß∞'].astype(str) == str(o_dist)]
                    if o_cat != 'ÂÖ®ÈÉ®':
                        df_o = df_o[df_o['‰∫ßÂìÅÂ§ßÁ±ª'].astype(str) == str(o_cat)]
                    if o_sub != 'ÂÖ®ÈÉ®':
                        df_o = df_o[df_o['‰∫ßÂìÅÂ∞èÁ±ª'].astype(str) == str(o_sub)]

                    def _agg_scope(df_scope: pd.DataFrame):
                        boxes = float(df_scope.get('Êï∞Èáè(ÁÆ±)', 0).sum()) if df_scope is not None and not df_scope.empty else 0.0
                        if df_scope is None or df_scope.empty or '_Èó®Â∫óÂêç' not in df_scope.columns:
                            stores = 0.0
                        else:
                            df_s = df_scope[df_scope['Êï∞Èáè(ÁÆ±)'] > 0].copy()
                            stores = float(df_s['_Èó®Â∫óÂêç'].dropna().astype(str).nunique()) if not df_s.empty else 0.0
                        return boxes, stores

                    def _yoy(cur, last):
                        if last is None:
                            return None
                        last_v = float(last or 0)
                        if last_v <= 0:
                            return None
                        return (float(cur or 0) - last_v) / last_v

                    def _avg(boxes, stores):
                        try:
                            s = float(stores or 0)
                            return float(boxes or 0) / s if s > 0 else 0.0
                        except Exception:
                            return 0.0

                    def _fmt_num(x):
                        return fmt_num(x, na="0")

                    def _fmt_pct(x):
                        return fmt_pct_ratio(x) if x is not None else "‚Äî"

                    def _trend_cls(x):
                        if x is None or (isinstance(x, float) and pd.isna(x)):
                            return "trend-neutral"
                        return "trend-up" if x > 0 else ("trend-down" if x < 0 else "trend-neutral")

                    def _arrow(x):
                        if x is None or (isinstance(x, float) and pd.isna(x)):
                            return ""
                        return "‚Üë" if x > 0 else ("‚Üì" if x < 0 else "")

                    # === Use Native Tabs for Consistency with Other Modules ===
                    tab_kpi, tab_cat, tab_prov = st.tabs(["üìä ÂÖ≥ÈîÆÊåáÊ†á", "üì¶ ÂàÜÂìÅÁ±ª", "üó∫Ô∏è ÂàÜÁúÅÂå∫"])
                    
                    # Prepare Data Context (Shared)
                    sig = (o_prov, o_dist, o_cat, o_sub, o_year, o_month)
                    if "out_subtab_cache" not in st.session_state:
                        st.session_state.out_subtab_cache = {}
                    
                    def _get_ctx():
                        ck = ("ctx", sig)
                        if ck in st.session_state.out_subtab_cache:
                            return st.session_state.out_subtab_cache[ck]
                        
                        # No spinner here to avoid flashing on every rerun, 
                        # relying on Streamlit's natural execution speed or cache if possible.
                        # If slow, we might add st.spinner inside specific heavy blocks.
                        if o_month != 'ÂÖ®ÈÉ®':
                            _kpi_year = int(o_year)
                            _kpi_month = int(o_month)
                        else:
                            years_avail = sorted([int(y) for y in df_o['_Âπ¥'].dropna().unique().tolist() if int(y) > 0])
                            _kpi_year = 2026 if 2026 in years_avail else (max(years_avail) if years_avail else int(o_year))
                            months_avail = sorted([int(m) for m in df_o[df_o['_Âπ¥'] == int(_kpi_year)]['_Êúà'].dropna().unique().tolist() if 1 <= int(m) <= 12])
                            _kpi_month = max(months_avail) if months_avail else 1

                        days_avail = sorted([int(d) for d in df_o[(df_o['_Âπ¥'] == int(_kpi_year)) & (df_o['_Êúà'] == int(_kpi_month))]['_Êó•'].dropna().unique().tolist() if 1 <= int(d) <= 31])
                        _kpi_day = max(days_avail) if days_avail else None
                        _cmp_year = int(_kpi_year) - 1

                        _cur_today = (df_o[(df_o['_Âπ¥'] == int(_kpi_year)) & (df_o['_Êúà'] == int(_kpi_month)) & (df_o['_Êó•'] == int(_kpi_day))] if _kpi_day is not None else df_o.iloc[0:0])
                        _cur_month = df_o[(df_o['_Âπ¥'] == int(_kpi_year)) & (df_o['_Êúà'] == int(_kpi_month))]
                        _cur_year = df_o[(df_o['_Âπ¥'] == int(_kpi_year))]

                        _last_today = (df_o[(df_o['_Âπ¥'] == int(_cmp_year)) & (df_o['_Êúà'] == int(_kpi_month)) & (df_o['_Êó•'] == int(_kpi_day))] if _kpi_day is not None else df_o.iloc[0:0])
                        _last_month = df_o[(df_o['_Âπ¥'] == int(_cmp_year)) & (df_o['_Êúà'] == int(_kpi_month))]
                        _last_year = df_o[(df_o['_Âπ¥'] == int(_cmp_year))]

                        ctx = {
                            "kpi_year": _kpi_year,
                            "kpi_month": _kpi_month,
                            "kpi_day": _kpi_day,
                            "cmp_year": _cmp_year,
                            "cur_today": _cur_today,
                            "cur_month": _cur_month,
                            "cur_year": _cur_year,
                            "last_today": _last_today,
                            "last_month": _last_month,
                            "last_year": _last_year,
                        }
                        st.session_state.out_subtab_cache[ck] = ctx
                        return ctx

                    ctx = _get_ctx()
                    
                    # Common Caption
                    st.caption(
                        f"ÂΩìÂâçÈªòËÆ§Âè£ÂæÑÔºö{ctx['kpi_year']}Âπ¥{int(ctx['kpi_month'])}Êúà"
                        + (f"{int(ctx['kpi_day'])}Êó•" if ctx["kpi_day"] is not None else "")
                    )

                    # --- Tab 1: KPI ---
                    with tab_kpi:
                        ck = ("kpi", sig)
                        if ck not in st.session_state.out_subtab_cache:
                             t_boxes, t_stores = _agg_scope(ctx["cur_today"])
                             tm_boxes, tm_stores = _agg_scope(ctx["cur_month"])
                             ty_boxes, ty_stores = _agg_scope(ctx["cur_year"])
                             lt_boxes, lt_stores = _agg_scope(ctx["last_today"])
                             ltm_boxes, ltm_stores = _agg_scope(ctx["last_month"])
                             lty_boxes, lty_stores = _agg_scope(ctx["last_year"])
                             t_yoy = _yoy(t_boxes, lt_boxes)
                             tm_yoy = _yoy(tm_boxes, ltm_boxes)
                             ty_yoy = _yoy(ty_boxes, lty_boxes)
                             t_avg = _avg(t_boxes, t_stores)
                             tm_avg = _avg(tm_boxes, tm_stores)
                             ty_avg = _avg(ty_boxes, ty_stores)
                             lt_avg = _avg(lt_boxes, lt_stores)
                             ltm_avg = _avg(ltm_boxes, ltm_stores)
                             lty_avg = _avg(lty_boxes, lty_stores)
                             st.session_state.out_subtab_cache[ck] = {
                                "t_boxes": t_boxes, "t_stores": t_stores, "t_yoy": t_yoy, "t_avg": t_avg, "lt_boxes": lt_boxes, "lt_stores": lt_stores, "lt_avg": lt_avg,
                                "tm_boxes": tm_boxes, "tm_stores": tm_stores, "tm_yoy": tm_yoy, "tm_avg": tm_avg, "ltm_boxes": ltm_boxes, "ltm_stores": ltm_stores, "ltm_avg": ltm_avg,
                                "ty_boxes": ty_boxes, "ty_stores": ty_stores, "ty_yoy": ty_yoy, "ty_avg": ty_avg, "lty_boxes": lty_boxes, "lty_stores": lty_stores, "lty_avg": lty_avg,
                             }
                        m = st.session_state.out_subtab_cache[ck]

                        k1, k2, k3 = st.columns(3)
                        with k1:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üöö</div>
                                    <div class="out-kpi-title">Êú¨Êó•Âá∫Â∫ì</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['t_boxes'])} ÁÆ±</div>
                                <div class="out-kpi-sub"><span>Èó®Â∫óÊï∞</span><span>{_fmt_num(m['t_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>Â∫óÂùáÔºàÁÆ±/Â∫óÔºâ</span><span>{fmt_num(m['t_avg'])} <span style="color:rgba(27,21,48,0.55);">ÔΩúÂêåÊúü {fmt_num(m['lt_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({ctx['cmp_year']})</span><span>{_fmt_num(m['lt_boxes'])} ÁÆ± / {_fmt_num(m['lt_stores'])} Â∫ó</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÁÆ±Ôºâ</span><span class="{_trend_cls(m['t_yoy'])}">{_arrow(m['t_yoy'])} {_fmt_pct(m['t_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                        with k2:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üì¶</div>
                                    <div class="out-kpi-title">Êú¨ÊúàÁ¥ØËÆ°Âá∫Â∫ì</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['tm_boxes'])} ÁÆ±</div>
                                <div class="out-kpi-sub"><span>Èó®Â∫óÊï∞</span><span>{_fmt_num(m['tm_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>Â∫óÂùáÔºàÁÆ±/Â∫óÔºâ</span><span>{fmt_num(m['tm_avg'])} <span style="color:rgba(27,21,48,0.55);">ÔΩúÂêåÊúü {fmt_num(m['ltm_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({ctx['cmp_year']})</span><span>{_fmt_num(m['ltm_boxes'])} ÁÆ± / {_fmt_num(m['ltm_stores'])} Â∫ó</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÁÆ±Ôºâ</span><span class="{_trend_cls(m['tm_yoy'])}">{_arrow(m['tm_yoy'])} {_fmt_pct(m['tm_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                        with k3:
                            st.markdown(f"""
                            <div class="out-kpi-card">
                                <div class="out-kpi-bar"></div>
                                <div class="out-kpi-head">
                                    <div class="out-kpi-ico">üèÅ</div>
                                    <div class="out-kpi-title">Êú¨Âπ¥Á¥ØËÆ°Âá∫Â∫ì</div>
                                </div>
                                <div class="out-kpi-val">{_fmt_num(m['ty_boxes'])} ÁÆ±</div>
                                <div class="out-kpi-sub"><span>Èó®Â∫óÊï∞</span><span>{_fmt_num(m['ty_stores'])}</span></div>
                                <div class="out-kpi-sub2"><span>Â∫óÂùáÔºàÁÆ±/Â∫óÔºâ</span><span>{fmt_num(m['ty_avg'])} <span style="color:rgba(27,21,48,0.55);">ÔΩúÂêåÊúü {fmt_num(m['lty_avg'])}</span></span></div>
                                <div class="out-kpi-sub2" style="margin-top:10px;"><span>ÂêåÊúü({ctx['cmp_year']})</span><span>{_fmt_num(m['lty_boxes'])} ÁÆ± / {_fmt_num(m['lty_stores'])} Â∫ó</span></div>
                                <div class="out-kpi-sub2"><span>ÂêåÊØîÔºàÁÆ±Ôºâ</span><span class="{_trend_cls(m['ty_yoy'])}">{_arrow(m['ty_yoy'])} {_fmt_pct(m['ty_yoy'])}</span></div>
                            </div>
                            """, unsafe_allow_html=True)

                    # --- Tab 2: Category ---
                    with tab_cat:
                        ck = ("cat", sig)
                        if ck not in st.session_state.out_subtab_cache:
                            with st.spinner("Ê≠£Âú®Âä†ËΩΩÂàÜÂìÅÁ±ª‚Ä¶"):
                                cat_dim = '‰∫ßÂìÅÂ∞èÁ±ª' if o_cat != 'ÂÖ®ÈÉ®' else '‰∫ßÂìÅÂ§ßÁ±ª'
                                st.session_state.out_subtab_cache[ck] = {"cat_dim": cat_dim}
                        cat_dim = st.session_state.out_subtab_cache[ck]["cat_dim"]
                        dim_label = '‰∫ßÂìÅÂ∞èÁ±ª' if cat_dim == '‰∫ßÂìÅÂ∞èÁ±ª' else '‰∫ßÂìÅÂ§ßÁ±ª'

                        st.caption(f"ÁªüËÆ°Áª¥Â∫¶Ôºö{dim_label}ÔºàÈöèÁ≠õÈÄâÊù°‰ª∂ÂÆûÊó∂Êõ¥Êñ∞Ôºâ")

                        def _cat_agg(df_scope: pd.DataFrame):
                            if df_scope is None or df_scope.empty:
                                return pd.DataFrame(columns=[cat_dim, 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞'])
                            df_t = df_scope.copy()
                            if cat_dim not in df_t.columns:
                                df_t[cat_dim] = 'Êú™Áü•'
                            df_t[cat_dim] = df_t[cat_dim].fillna('Êú™Áü•').astype(str).str.strip()
                            df_t = df_t[df_t['Êï∞Èáè(ÁÆ±)'] > 0].copy()
                            if df_t.empty:
                                return pd.DataFrame(columns=[cat_dim, 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞'])
                            g_box = df_t.groupby(cat_dim, as_index=False)['Êï∞Èáè(ÁÆ±)'].sum().rename(columns={'Êï∞Èáè(ÁÆ±)': 'ÁÆ±Êï∞'})
                            if '_Èó®Â∫óÂêç' in df_t.columns:
                                g_store = df_t[df_t['_Èó®Â∫óÂêç'].notna()].groupby(cat_dim, as_index=False)['_Èó®Â∫óÂêç'].nunique().rename(columns={'_Èó®Â∫óÂêç': 'Èó®Â∫óÊï∞'})
                            else:
                                g_store = pd.DataFrame({cat_dim: g_box[cat_dim], 'Èó®Â∫óÊï∞': 0})
                            out = pd.merge(g_box, g_store, on=cat_dim, how='left').fillna(0)
                            out = out.sort_values('ÁÆ±Êï∞', ascending=False).reset_index(drop=True)
                            return out

                        def _topn_with_other(df_sum: pd.DataFrame, n: int = 15):
                            if df_sum is None or df_sum.empty:
                                return df_sum
                            head = df_sum.head(n).copy()
                            tail = df_sum.iloc[n:].copy()
                            if not tail.empty:
                                other = pd.DataFrame([{
                                    cat_dim: 'ÂÖ∂‰ªñ',
                                    'ÁÆ±Êï∞': float(tail['ÁÆ±Êï∞'].sum()),
                                    'Èó®Â∫óÊï∞': float(tail['Èó®Â∫óÊï∞'].sum())
                                }])
                                head = pd.concat([head, other], ignore_index=True)
                            return head

                        def _cat_table(df_cur: pd.DataFrame, df_last: pd.DataFrame):
                            cur_sum = _topn_with_other(_cat_agg(df_cur), 15)
                            last_sum = _topn_with_other(_cat_agg(df_last), 15)
                            if cur_sum is None or cur_sum.empty:
                                cur_sum = pd.DataFrame(columns=[cat_dim, 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞'])
                            if last_sum is None or last_sum.empty:
                                last_sum = pd.DataFrame(columns=[cat_dim, 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞'])
                            m = pd.merge(
                                cur_sum.rename(columns={'ÁÆ±Êï∞': 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞': 'Èó®Â∫óÊï∞'}),
                                last_sum[[cat_dim, 'ÁÆ±Êï∞']].rename(columns={'ÁÆ±Êï∞': 'ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ'}),
                                on=cat_dim,
                                how='outer'
                            ).fillna(0)
                            m['ÂêåÊØî'] = np.where(m['ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ'] > 0, (m['ÁÆ±Êï∞'] - m['ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ']) / m['ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ'], None)
                            m = m.sort_values('ÁÆ±Êï∞', ascending=False).reset_index(drop=True)
                            m = m.rename(columns={cat_dim: 'ÂìÅÁ±ª'})
                            return m[['ÂìÅÁ±ª', 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞', 'ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ', 'ÂêåÊØî']]

                        tab_cat_today, tab_cat_month, tab_cat_year = st.tabs(["Êú¨Êó•", "Êú¨Êúà", "Êú¨Âπ¥"])
                        with tab_cat_today:
                            cat_tbl = _cat_table(ctx["cur_today"], ctx["last_today"])
                            show_aggrid_table(cat_tbl, columns_props={'ÂêåÊØî': {'type': 'percent'}}, auto_height_limit=520)
                        with tab_cat_month:
                            cat_tbl = _cat_table(ctx["cur_month"], ctx["last_month"])
                            show_aggrid_table(cat_tbl, columns_props={'ÂêåÊØî': {'type': 'percent'}}, auto_height_limit=520)
                        with tab_cat_year:
                            cat_tbl = _cat_table(ctx["cur_year"], ctx["last_year"])
                            show_aggrid_table(cat_tbl, columns_props={'ÂêåÊØî': {'type': 'percent'}}, auto_height_limit=520)

                    # --- Tab 3: Province ---
                    with tab_prov:

                        def _prov_agg(df_scope: pd.DataFrame):
                            if df_scope is None or df_scope.empty or 'ÁúÅÂå∫' not in df_scope.columns:
                                return pd.DataFrame(columns=['ÁúÅÂå∫', 'ÁÆ±Êï∞', 'Èó®Â∫óÊï∞'])
                            g_box = (
                                df_scope
                                .groupby('ÁúÅÂå∫', as_index=False)['Êï∞Èáè(ÁÆ±)']
                                .sum()
                                .rename(columns={'Êï∞Èáè(ÁÆ±)': 'ÁÆ±Êï∞'})
                            )

                            if '_Èó®Â∫óÂêç' in df_scope.columns:
                                tmp = df_scope[(df_scope['Êï∞Èáè(ÁÆ±)'] > 0) & (df_scope['_Èó®Â∫óÂêç'].notna())].copy()
                                g_store = (
                                    tmp
                                    .groupby('ÁúÅÂå∫', as_index=False)['_Èó®Â∫óÂêç']
                                    .nunique()
                                    .rename(columns={'_Èó®Â∫óÂêç': 'Èó®Â∫óÊï∞'})
                                )
                            else:
                                g_store = pd.DataFrame(columns=['ÁúÅÂå∫', 'Èó®Â∫óÊï∞'])

                            return pd.merge(g_box, g_store, on='ÁúÅÂå∫', how='left').fillna(0)

                        p_cur_today = _prov_agg(ctx["cur_today"])
                        p_cur_month = _prov_agg(ctx["cur_month"])
                        p_cur_year = _prov_agg(ctx["cur_year"])
                        p_last_today = _prov_agg(ctx["last_today"])
                        p_last_month = _prov_agg(ctx["last_month"])
                        p_last_year = _prov_agg(ctx["last_year"])

                        prov_all = sorted(set(
                            p_cur_today['ÁúÅÂå∫'].astype(str).tolist()
                            + p_cur_month['ÁúÅÂå∫'].astype(str).tolist()
                            + p_cur_year['ÁúÅÂå∫'].astype(str).tolist()
                        ))
                        prov_df = pd.DataFrame({'ÁúÅÂå∫': prov_all})

                        def _merge(prov_base, df_left, prefix):
                            d = df_left.copy()
                            d.columns = ['ÁúÅÂå∫'] + [f"{prefix}{c}" for c in d.columns if c != 'ÁúÅÂå∫']
                            return pd.merge(prov_base, d, on='ÁúÅÂå∫', how='left').fillna(0)

                        prov_df = _merge(prov_df, p_cur_today, "‰ªäÊó•")
                        prov_df = _merge(prov_df, p_last_today, "ÂêåÊúü‰ªäÊó•")
                        prov_df = _merge(prov_df, p_cur_month, "Êú¨Êúà")
                        prov_df = _merge(prov_df, p_last_month, "ÂêåÊúüÊú¨Êúà")
                        prov_df = _merge(prov_df, p_cur_year, "Êú¨Âπ¥")
                        prov_df = _merge(prov_df, p_last_year, "ÂêåÊúüÊú¨Âπ¥")

                        prov_df['‰ªäÊó•ÂêåÊØî(ÁÆ±)'] = prov_df.apply(lambda r: _yoy(r.get('‰ªäÊó•ÁÆ±Êï∞', 0), r.get('ÂêåÊúü‰ªäÊó•ÁÆ±Êï∞', 0)), axis=1)
                        prov_df['‰ªäÊó•ÂêåÊØî(Èó®Â∫ó)'] = prov_df.apply(lambda r: _yoy(r.get('‰ªäÊó•Èó®Â∫óÊï∞', 0), r.get('ÂêåÊúü‰ªäÊó•Èó®Â∫óÊï∞', 0)), axis=1)
                        prov_df['Êú¨ÊúàÂêåÊØî(ÁÆ±)'] = prov_df.apply(lambda r: _yoy(r.get('Êú¨ÊúàÁÆ±Êï∞', 0), r.get('ÂêåÊúüÊú¨ÊúàÁÆ±Êï∞', 0)), axis=1)
                        prov_df['Êú¨ÊúàÂêåÊØî(Èó®Â∫ó)'] = prov_df.apply(lambda r: _yoy(r.get('Êú¨ÊúàÈó®Â∫óÊï∞', 0), r.get('ÂêåÊúüÊú¨ÊúàÈó®Â∫óÊï∞', 0)), axis=1)
                        prov_df['Êú¨Âπ¥ÂêåÊØî(ÁÆ±)'] = prov_df.apply(lambda r: _yoy(r.get('Êú¨Âπ¥ÁÆ±Êï∞', 0), r.get('ÂêåÊúüÊú¨Âπ¥ÁÆ±Êï∞', 0)), axis=1)
                        prov_df['Êú¨Âπ¥ÂêåÊØî(Èó®Â∫ó)'] = prov_df.apply(lambda r: _yoy(r.get('Êú¨Âπ¥Èó®Â∫óÊï∞', 0), r.get('ÂêåÊúüÊú¨Âπ¥Èó®Â∫óÊï∞', 0)), axis=1)

                        prov_show = pd.DataFrame({
                            'ÁúÅÂå∫': prov_df['ÁúÅÂå∫'],
                            '‰ªäÊó•ÁÆ±Êï∞': pd.to_numeric(prov_df.get('‰ªäÊó•ÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            '‰ªäÊó•Èó®Â∫óÊï∞': pd.to_numeric(prov_df.get('‰ªäÊó•Èó®Â∫óÊï∞', 0), errors='coerce').fillna(0),
                            '‰ªäÊó•ÂêåÊúü(ÁÆ±Êï∞)': pd.to_numeric(prov_df.get('ÂêåÊúü‰ªäÊó•ÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            '‰ªäÊó•ÂêåÊØî(ÁÆ±)': pd.to_numeric(prov_df.get('‰ªäÊó•ÂêåÊØî(ÁÆ±)', None), errors='coerce'),
                            'Êú¨ÊúàÁÆ±Êï∞': pd.to_numeric(prov_df.get('Êú¨ÊúàÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            'Êú¨ÊúàÈó®Â∫óÊï∞': pd.to_numeric(prov_df.get('Êú¨ÊúàÈó®Â∫óÊï∞', 0), errors='coerce').fillna(0),
                            'Êú¨ÊúàÂêåÊúü(ÁÆ±Êï∞)': pd.to_numeric(prov_df.get('ÂêåÊúüÊú¨ÊúàÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            'Êú¨ÊúàÂêåÊØî(ÁÆ±)': pd.to_numeric(prov_df.get('Êú¨ÊúàÂêåÊØî(ÁÆ±)', None), errors='coerce'),
                            'Êú¨Âπ¥ÁÆ±Êï∞': pd.to_numeric(prov_df.get('Êú¨Âπ¥ÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            'Êú¨Âπ¥Èó®Â∫óÊï∞': pd.to_numeric(prov_df.get('Êú¨Âπ¥Èó®Â∫óÊï∞', 0), errors='coerce').fillna(0),
                            'Êú¨Âπ¥ÂêåÊúü(ÁÆ±Êï∞)': pd.to_numeric(prov_df.get('ÂêåÊúüÊú¨Âπ¥ÁÆ±Êï∞', 0), errors='coerce').fillna(0),
                            'Êú¨Âπ¥ÂêåÊØî(ÁÆ±)': pd.to_numeric(prov_df.get('Êú¨Âπ¥ÂêåÊØî(ÁÆ±)', None), errors='coerce'),
                        }).fillna({'‰ªäÊó•ÂêåÊØî(ÁÆ±)': np.nan, 'Êú¨ÊúàÂêåÊØî(ÁÆ±)': np.nan, 'Êú¨Âπ¥ÂêåÊØî(ÁÆ±)': np.nan})

                        day_txt = f"{int(ctx['kpi_month'])}Êúà{int(ctx['kpi_day'])}Êó•" if ctx["kpi_day"] is not None else f"{int(ctx['kpi_month'])}Êúà"
                        grp_today = f"‰ªäÊó•Ôºà{day_txt}Ôºâ"
                        grp_month = f"Êú¨ÊúàÔºà{int(ctx['kpi_month'])}ÊúàÔºâ"
                        grp_year = f"Êú¨Âπ¥Ôºà{int(ctx['kpi_year'])}Âπ¥Ôºâ"

                        col_defs = [
                            {'headerName': 'ÁúÅÂå∫', 'field': 'ÁúÅÂå∫', 'minWidth': 110, 'headerClass': 'ag-header-center'},
                            {
                                'headerName': grp_today,
                                'children': [
                                    {'headerName': 'ÁÆ±Êï∞', 'field': '‰ªäÊó•ÁÆ±Êï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'Èó®Â∫óÊï∞', 'field': '‰ªäÊó•Èó®Â∫óÊï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ', 'field': '‰ªäÊó•ÂêåÊúü(ÁÆ±Êï∞)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊØîÔºàÁÆ±Ôºâ', 'field': '‰ªäÊó•ÂêåÊØî(ÁÆ±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                            {
                                'headerName': grp_month,
                                'children': [
                                    {'headerName': 'ÁÆ±Êï∞', 'field': 'Êú¨ÊúàÁÆ±Êï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'Èó®Â∫óÊï∞', 'field': 'Êú¨ÊúàÈó®Â∫óÊï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ', 'field': 'Êú¨ÊúàÂêåÊúü(ÁÆ±Êï∞)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊØîÔºàÁÆ±Ôºâ', 'field': 'Êú¨ÊúàÂêåÊØî(ÁÆ±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                            {
                                'headerName': grp_year,
                                'children': [
                                    {'headerName': 'ÁÆ±Êï∞', 'field': 'Êú¨Âπ¥ÁÆ±Êï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'Èó®Â∫óÊï∞', 'field': 'Êú¨Âπ¥Èó®Â∫óÊï∞', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊúüÔºàÁÆ±Êï∞Ôºâ', 'field': 'Êú¨Âπ¥ÂêåÊúü(ÁÆ±Êï∞)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_NUM},
                                    {'headerName': 'ÂêåÊØîÔºàÁÆ±Ôºâ', 'field': 'Êú¨Âπ¥ÂêåÊØî(ÁÆ±)', 'type': ['numericColumn', 'numberColumnFilter'], 'headerClass': 'ag-header-center', 'valueFormatter': JS_FMT_PCT_RATIO}, 
                                ],
                            },
                        ]

                        def _sum_col(col_name: str) -> float:
                            if col_name not in prov_show.columns:
                                return 0.0
                            return float(pd.to_numeric(prov_show[col_name], errors='coerce').fillna(0).sum())

                        _t_cur = _sum_col('‰ªäÊó•ÁÆ±Êï∞')
                        _t_last = _sum_col('‰ªäÊó•ÂêåÊúü(ÁÆ±Êï∞)')
                        _m_cur = _sum_col('Êú¨ÊúàÁÆ±Êï∞')
                        _m_last = _sum_col('Êú¨ÊúàÂêåÊúü(ÁÆ±Êï∞)')
                        _y_cur = _sum_col('Êú¨Âπ¥ÁÆ±Êï∞')
                        _y_last = _sum_col('Êú¨Âπ¥ÂêåÊúü(ÁÆ±Êï∞)')

                        pinned_total = {
                            'ÁúÅÂå∫': 'ÂêàËÆ°',
                            '‰ªäÊó•ÁÆ±Êï∞': _t_cur,
                            '‰ªäÊó•Èó®Â∫óÊï∞': _sum_col('‰ªäÊó•Èó®Â∫óÊï∞'),
                            '‰ªäÊó•ÂêåÊúü(ÁÆ±Êï∞)': _t_last,
                            '‰ªäÊó•ÂêåÊØî(ÁÆ±)': ((_t_cur - _t_last) / _t_last) if _t_last > 0 else None,
                            'Êú¨ÊúàÁÆ±Êï∞': _m_cur,
                            'Êú¨ÊúàÈó®Â∫óÊï∞': _sum_col('Êú¨ÊúàÈó®Â∫óÊï∞'),
                            'Êú¨ÊúàÂêåÊúü(ÁÆ±Êï∞)': _m_last,
                            'Êú¨ÊúàÂêåÊØî(ÁÆ±)': ((_m_cur - _m_last) / _m_last) if _m_last > 0 else None,
                            'Êú¨Âπ¥ÁÆ±Êï∞': _y_cur,
                            'Êú¨Âπ¥Èó®Â∫óÊï∞': _sum_col('Êú¨Âπ¥Èó®Â∫óÊï∞'),
                            'Êú¨Âπ¥ÂêåÊúü(ÁÆ±Êï∞)': _y_last,
                            'Êú¨Âπ¥ÂêåÊØî(ÁÆ±)': ((_y_cur - _y_last) / _y_last) if _y_last > 0 else None,
                        }

                        gridOptions = {
                            'pinnedBottomRowData': [pinned_total],
                            'columnDefs': col_defs,
                            'defaultColDef': {
                                'resizable': True,
                                'sortable': True,
                                'filter': True,
                                'wrapHeaderText': True,
                                'autoHeaderHeight': True,
                                'minWidth': 70,
                                'flex': 1,
                                'cellStyle': {'textAlign': 'center', 'display': 'flex', 'justifyContent': 'center', 'alignItems': 'center'},
                                'headerClass': 'ag-header-center',
                            },
                            'rowHeight': 40,
                            'headerHeight': 60,
                            'groupHeaderHeight': 60,
                            'animateRows': True,
                            'suppressCellFocus': True,
                            'enableCellTextSelection': True,
                            'suppressDragLeaveHidesColumns': True,
                            'sideBar': {
                                "toolPanels": [
                                    {
                                        "id": "columns",
                                        "labelDefault": "Âàó",
                                        "iconKey": "columns",
                                        "toolPanel": "agColumnsToolPanel",
                                        "toolPanelParams": {
                                            "suppressRowGroups": True,
                                            "suppressValues": True,
                                            "suppressPivots": True,
                                            "suppressPivotMode": True
                                        }
                                    }
                                ],
                                "defaultToolPanel": None
                            },
                        }

                        AgGrid(
                            prov_show,
                            gridOptions=gridOptions,
                            height=520,
                            width='100%',
                            data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
                            update_mode=GridUpdateMode.NO_UPDATE,
                            fit_columns_on_grid_load=True,
                            allow_unsafe_jscode=True,
                            theme='streamlit',
                            key="outbound_prov_table"
                        )

                    st.markdown("</div>", unsafe_allow_html=True)

                    # === TAB 7: PERFORMANCE ===
            with tab7:
                st.markdown("""
                <style>
                  .perf-wrap {display:flex; flex-direction:column; gap:16px;}
                  .perf-kpis {display:grid; grid-template-columns: repeat(4, 1fr); gap:14px;}
                  .perf-card {background:#F3E5F5; border:1px solid rgba(156,39,176,0.18); border-radius:12px; padding:14px 16px; box-shadow:0 6px 20px rgba(18,12,28,0.06);}
                  .perf-k {font-size:13px; color:rgba(27,21,48,0.72);}
                  .perf-v {font-size:20px; font-weight:800; color:#9C27B0; margin-top:8px;}
                  .perf-sub {display:flex; justify-content:space-between; align-items:center; margin-top:8px; font-size:12px; color:rgba(27,21,48,0.72);}
                  .perf-up {color:#2FBF71; font-weight:700;}
                  .perf-down {color:#E5484D; font-weight:700;}
                  .perf-mid {color:#FFB000; font-weight:700;}
                  .stDataFrame td { vertical-align: middle !important; }
                  @media (max-width: 1100px) {.perf-kpis {grid-template-columns: repeat(2, 1fr);} }
                </style>
                """, unsafe_allow_html=True)

                if df_perf_raw is None or df_perf_raw.empty:
                    st.warning("‚ö†Ô∏è Êú™Ê£ÄÊµãÂà∞ÂèëË¥ß‰∏öÁª©Êï∞ÊçÆ (Sheet4)„ÄÇËØ∑Á°ÆËÆ§ExcelÂåÖÂê´Sheet4‰∏îÊï∞ÊçÆÂÆåÊï¥„ÄÇ")
                    with st.expander("üõ†Ô∏è Ë∞ÉËØï‰ø°ÊÅØ", expanded=False):
                        for log in debug_logs: st.text(log)
                else:
                    df_perf = df_perf_raw.copy()
                    
                    # --- 1. Data Prep ---
                    # Load Targets from Sheet5 (C=Prov, D=Cat, E=Month, F=Task)
                    df_target = None
                    if df_target_raw is not None and len(df_target_raw.columns) >= 6:
                        try:
                            # Use iloc to be safe about column names
                            df_target = df_target_raw.iloc[:, [2, 3, 4, 5]].copy()
                            df_target.columns = ['ÁúÅÂå∫', 'ÂìÅÁ±ª', 'Êúà‰ªΩ', '‰ªªÂä°Èáè']
                            df_target['‰ªªÂä°Èáè'] = pd.to_numeric(df_target['‰ªªÂä°Èáè'], errors='coerce').fillna(0)
                            df_target['Êúà‰ªΩ'] = pd.to_numeric(df_target['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                            df_target['ÁúÅÂå∫'] = df_target['ÁúÅÂå∫'].astype(str).str.strip()
                            df_target['ÂìÅÁ±ª'] = df_target['ÂìÅÁ±ª'].astype(str).str.strip()
                        except Exception as e:
                            st.error(f"‰ªªÂä°Ë°®Ëß£ÊûêÂ§±Ë¥•: {e}")
                            df_target = None
                    
                    # Data Cleaning
                    df_track = df_perf.copy()
                    df_track['Âπ¥‰ªΩ'] = pd.to_numeric(df_track['Âπ¥‰ªΩ'], errors='coerce').fillna(0).astype(int)
                    df_track['Êúà‰ªΩ'] = pd.to_numeric(df_track['Êúà‰ªΩ'], errors='coerce').fillna(0).astype(int)
                    
                    # Fix: Check if 'ÂèëË¥ßÈáëÈ¢ù' exists, if not, try to use 'ÂèëË¥ßÁÆ±Êï∞' or create empty
                    if 'ÂèëË¥ßÈáëÈ¢ù' not in df_track.columns:
                            if 'ÂèëË¥ßÁÆ±Êï∞' in df_track.columns:
                                df_track['ÂèëË¥ßÈáëÈ¢ù'] = df_track['ÂèëË¥ßÁÆ±Êï∞'] # Fallback
                            else:
                                df_track['ÂèëË¥ßÈáëÈ¢ù'] = 0.0
                    
                    df_track['ÂèëË¥ßÈáëÈ¢ù'] = pd.to_numeric(df_track['ÂèëË¥ßÈáëÈ¢ù'], errors='coerce').fillna(0.0)
                    
                    for c in ['ÁúÅÂå∫', 'ÁªèÈîÄÂïÜÂêçÁß∞', 'ÂΩíÁ±ª', 'ÂèëË¥ß‰ªì', 'Â§ßÂàÜÁ±ª', 'ÊúàÂàÜÊûê']:
                        if c in df_track.columns:
                            df_track[c] = df_track[c].fillna('').astype(str).str.strip()
                    
                    # Determine Year
                    years = sorted([y for y in df_track['Âπ¥‰ªΩ'].unique() if y > 2000])
                    cur_year = 2026 if 2026 in years else (max(years) if years else 2025)
                    last_year = cur_year - 1
                    
                    # --- 2. Filters ---
                    with st.expander("üéõÔ∏è Á≠õÈÄâÊéßÂà∂Èù¢Êùø", expanded=False):
                        f1, f2, f3, f4, f5 = st.columns(5)
                        
                        # Province
                        prov_opts = ['ÂÖ®ÈÉ®'] + sorted([x for x in df_track['ÁúÅÂå∫'].unique() if x])
                        with f1:
                            sel_prov = st.selectbox("ÁúÅÂå∫", prov_opts, key="t26_prov")
                        
                        # Filter Step 1
                        df_f = df_track if sel_prov == 'ÂÖ®ÈÉ®' else df_track[df_track['ÁúÅÂå∫'] == sel_prov]
                        
                        # Distributor
                        dist_opts = ['ÂÖ®ÈÉ®'] + sorted([x for x in df_f['ÁªèÈîÄÂïÜÂêçÁß∞'].unique() if x])
                        with f2:
                            sel_dist = st.selectbox("ÁªèÈîÄÂïÜ", dist_opts, key="t26_dist")
                        if sel_dist != 'ÂÖ®ÈÉ®':
                            df_f = df_f[df_f['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist]
                            
                        if 'Â§ßÂàÜÁ±ª' in df_track.columns:
                            cat_col_S = 'Â§ßÂàÜÁ±ª'
                        elif 'ÊúàÂàÜÊûê' in df_track.columns:
                            cat_col_S = 'ÊúàÂàÜÊûê'
                            st.warning("‚ö†Ô∏è Êú™ÊâæÂà∞'Sheet4 SÂàóÂ§ßÂàÜÁ±ª'Â≠óÊÆµÂêç‚ÄúÂ§ßÂàÜÁ±ª‚ÄùÔºåÂ∑≤‰ΩøÁî®‚ÄúÊúàÂàÜÊûê‚ÄùÂàó‰Ωú‰∏∫Êõø‰ª£„ÄÇËØ∑Á°ÆËÆ§Ê∫êÊï∞ÊçÆÂàóÂêç„ÄÇ")
                        else:
                            cat_col_S = 'ÂèëË¥ß‰ªì'
                            st.error("‚ùå Êï∞ÊçÆÊ∫ê‰∏≠Êú™ÊâæÂà∞Sheet4 SÂàó‚ÄúÂ§ßÂàÜÁ±ª‚Äù/‚ÄúÊúàÂàÜÊûê‚ÄùÂàóÔºåÂ∑≤‰∏¥Êó∂‰ΩøÁî®‚ÄúÂèëË¥ß‰ªì‚ÄùÂàó‰Ωú‰∏∫Â§ßÂàÜÁ±ªÁ≠õÈÄâ„ÄÇ")

                        if cat_col_S in df_f.columns:
                            df_f[cat_col_S] = df_f[cat_col_S].fillna('').astype(str).str.strip()

                        if cat_col_S in df_track.columns:
                            df_track[cat_col_S] = df_track[cat_col_S].fillna('').astype(str).str.strip()

                        cat_check_value = "ÁõäÁõäÊàê‰∫∫Á≤â"
                        cat_exists_all = False
                        cat_exists_filtered = False
                        if cat_col_S in df_track.columns:
                            cat_exists_all = bool((df_track[cat_col_S] == cat_check_value).any())
                        if cat_col_S in df_f.columns:
                            cat_exists_filtered = bool((df_f[cat_col_S] == cat_check_value).any())

                        if cat_exists_all and (not cat_exists_filtered):
                            st.warning(f"‚ö†Ô∏è Ê∫êÊï∞ÊçÆ‚ÄúÂ§ßÂàÜÁ±ª‚ÄùÂåÖÂê´‚Äú{cat_check_value}‚ÄùÔºå‰ΩÜÂú®ÂΩìÂâçÁúÅÂå∫/ÁªèÈîÄÂïÜÁ≠õÈÄâ‰∏ãÊó†Êï∞ÊçÆ„ÄÇËØ∑Ë∞ÉÊï¥Á≠õÈÄâÊü•Áúã„ÄÇ")

                        with st.expander("üîé Â§ßÂàÜÁ±ªÊï∞ÊçÆÊ†°È™å", expanded=False):
                            if cat_col_S not in df_track.columns:
                                st.error(f"Êú™ÊâæÂà∞Áî®‰∫éÂ§ßÂàÜÁ±ªÁöÑÂ≠óÊÆµÔºö{cat_col_S}")
                            else:
                                s_all = df_track[cat_col_S]
                                s_all_nonempty = s_all[s_all != ""]
                                st.write(f"Â§ßÂàÜÁ±ªÂ≠óÊÆµÔºö{cat_col_S}")
                                st.write(f"ÂîØ‰∏ÄÁ±ªÁõÆÊï∞Ôºö{int(s_all_nonempty.nunique())}")
                                st.write(f"Á©∫ÂÄºÂç†ÊØîÔºö{fmt_pct_ratio(float((s_all == '').mean()))}")
                                st.write(f"ÊòØÂê¶ÂåÖÂê´‚Äú{cat_check_value}‚ÄùÔºö{'ÊòØ' if cat_exists_all else 'Âê¶'}")
                                top_counts = s_all_nonempty.value_counts().head(12).reset_index()
                                top_counts.columns = ["Á±ªÁõÆ", "Ë°åÊï∞"]
                                show_aggrid_table(top_counts, height=300, key="verify_table")

                        wh_opts = ['ÂÖ®ÈÉ®'] + sorted([x for x in df_f.get(cat_col_S, pd.Series(dtype=str)).unique() if x])
                        with f3:
                            sel_wh = st.selectbox(f"Â§ßÁ±ª ({cat_col_S})", wh_opts, key="t26_wh")
                        
                        if sel_wh != 'ÂÖ®ÈÉ®':
                            df_f = df_f[df_f.get(cat_col_S, pd.Series(dtype=str)) == sel_wh]
                            
                        # Small Category (Group) - Multi Select
                        grp_opts = sorted([x for x in df_f['ÂΩíÁ±ª'].unique() if x])
                        with f4:
                            sel_grp = st.multiselect("Â∞èÁ±ª (ÂΩíÁ±ª)", grp_opts, default=[], key="t26_grp")
                        if sel_grp:
                            df_f = df_f[df_f['ÂΩíÁ±ª'].isin(sel_grp)]
                            
                        # Month Selection (Single)
                        avail_months = sorted(df_f[df_f['Âπ¥‰ªΩ'] == cur_year]['Êúà‰ªΩ'].unique())
                        def_month = int(avail_months[-1]) if avail_months else 1
                        with f5:
                            sel_month = st.selectbox("ÁªüËÆ°Êúà‰ªΩ", list(range(1, 13)), index=def_month-1, key="t26_month")
                    
                    # --- 3. Calculations ---
                    # Actuals
                    act_cur_year = df_f[df_f['Âπ¥‰ªΩ'] == cur_year]['ÂèëË¥ßÈáëÈ¢ù'].sum()
                    act_last_year = df_f[df_f['Âπ¥‰ªΩ'] == last_year]['ÂèëË¥ßÈáëÈ¢ù'].sum()
                    
                    act_cur_month = df_f[(df_f['Âπ¥‰ªΩ'] == cur_year) & (df_f['Êúà‰ªΩ'] == sel_month)]['ÂèëË¥ßÈáëÈ¢ù'].sum()
                    act_last_month = df_f[(df_f['Âπ¥‰ªΩ'] == last_year) & (df_f['Êúà‰ªΩ'] == sel_month)]['ÂèëË¥ßÈáëÈ¢ù'].sum()
                    
                    # Targets
                    target_cur_year = 0.0
                    target_cur_month = 0.0
                    if df_target is not None:
                        # Apply filters to target (Province, Category)
                        # Note: Distributor filter can't apply to Target usually, unless target is by dist. 
                        # User said Sheet5 has Province/Category.
                        df_t_f = df_target.copy()
                        if sel_prov != 'ÂÖ®ÈÉ®':
                            df_t_f = df_t_f[df_t_f['ÁúÅÂå∫'] == sel_prov]
                        # Category mapping? Sheet5 'ÂìÅÁ±ª' vs Sheet4 'ÂΩíÁ±ª'/'ÂèëË¥ß‰ªì'.
                        # User said D col is Category. Assuming it matches 'ÂΩíÁ±ª' or needs mapping.
                        # For now, we sum all if no specific match logic provided or if 'ÂÖ®ÈÉ®'.
                        # If user selected specific categories, we try to filter.
                        # BUT, without exact mapping, filtering Targets by Category is risky. 
                        # We'll calculate Total Target for selected Province.
                        
                        target_cur_year = df_t_f['‰ªªÂä°Èáè'].sum()
                        target_cur_month = df_t_f[df_t_f['Êúà‰ªΩ'] == sel_month]['‰ªªÂä°Èáè'].sum()
                    
                    # Rates & YoY
                    rate_year = (act_cur_year / target_cur_year) if target_cur_year > 0 else None
                    rate_month = (act_cur_month / target_cur_month) if target_cur_month > 0 else None
                    
                    yoy_year = (act_cur_year - act_last_year) / act_last_year if act_last_year > 0 else None
                    yoy_month = (act_cur_month - act_last_month) / act_last_month if act_last_month > 0 else None
                    
                    # --- 4. KPI Cards ---
                    def _fmt_wan(x): return fmt_num((x or 0) / 10000)
                    def _fmt_pct(x): return fmt_pct_ratio(x) if x is not None else "‚Äî"
                    def _color_pct(x): return "perf-up" if x and x>0 else "perf-down"
                    def _arrow(x): return "‚Üë" if x and x>0 else ("‚Üì" if x and x<0 else "")

                    def _render_card(title, icon, val_wan, target_wan, rate, yoy_val_wan, yoy_pct):
                        trend_cls = "trend-up" if yoy_pct and yoy_pct > 0 else ("trend-down" if yoy_pct and yoy_pct < 0 else "trend-neutral")
                        arrow = _arrow(yoy_pct)
                        rate_txt = _fmt_pct(rate)
                        yoy_txt = _fmt_pct(yoy_pct)
                        pct_val = min(max(rate * 100 if rate else 0, 0), 100)
                        prog_color = "#28A745" if rate and rate >= 1.0 else ("#FFC107" if rate and rate >= 0.8 else "#DC3545")

                        st.markdown(f"""
                        <div class="out-kpi-card">
                            <div class="out-kpi-bar"></div>
                            <div class="out-kpi-head">
                                <div class="out-kpi-ico">{icon}</div>
                                <div class="out-kpi-title">{title}</div>
                            </div>
                            <div class="out-kpi-val">¬• {val_wan}‰∏á</div>
                            <div class="out-kpi-sub2" style="margin-top:8px;">
                                <span>ËææÊàêÁéá</span>
                                <span style="font-weight:800; color:{prog_color}">{rate_txt}</span>
                            </div>
                            <div class="out-kpi-progress" style="margin-top:6px;">
                                <div class="out-kpi-progress-bar" style="background:{prog_color}; width:{pct_val}%;"></div>
                            </div>
                            <div class="out-kpi-sub2" style="margin-top:10px;">
                                <span>ÁõÆÊ†á</span>
                                <span>{target_wan}‰∏á</span>
                            </div>
                            <div class="out-kpi-sub2">
                                <span>ÂêåÊúü</span>
                                <span>{yoy_val_wan}‰∏á</span>
                            </div>
                            <div class="out-kpi-sub2">
                                <span>ÂêåÊØî</span>
                                <span class="{trend_cls}">{arrow} {yoy_txt}</span>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                    # --- TABS: KPI, Category, Province ---
                    tab_perf_kpi, tab_perf_cat, tab_perf_prov = st.tabs(["üìä Ê†∏ÂøÉ‰∏öÁª©ÊåáÊ†á", "üì¶ ÂàÜÂìÅÁ±ª", "üó∫Ô∏è ÂàÜÁúÅÂå∫"])

                    with tab_perf_kpi:
                        k1, k2 = st.columns(2)
                        
                        with k1:
                            _render_card("Êú¨Êúà‰∏öÁª©", "üìÖ", _fmt_wan(act_cur_month), _fmt_wan(target_cur_month), rate_month, _fmt_wan(act_last_month), yoy_month)
                        with k2:
                            _render_card("Âπ¥Â∫¶Á¥ØËÆ°‰∏öÁª©", "üèÜ", _fmt_wan(act_cur_year), _fmt_wan(target_cur_year), rate_year, _fmt_wan(act_last_year), yoy_year)
                    
                    with tab_perf_cat:
                        # --- NEW: Category Performance Cards ---
                        
                        # Prepare Category Data
                        # Using cat_col_S ('Â§ßÂàÜÁ±ª' or 'ÊúàÂàÜÊûê' or 'ÂèëË¥ß‰ªì')
                        
                        # 1. Monthly Category Data
                        cat_cur_m = df_f[(df_f['Âπ¥‰ªΩ'] == cur_year) & (df_f['Êúà‰ªΩ'] == sel_month)].groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                        cat_last_m = df_f[(df_f['Âπ¥‰ªΩ'] == last_year) & (df_f['Êúà‰ªΩ'] == sel_month)].groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                        
                        cat_m_final = pd.merge(cat_cur_m, cat_last_m, on=cat_col_S, how='outer').fillna(0)
                        cat_m_final['Êú¨Êúà(‰∏á)'] = cat_m_final['Êú¨Êúà'] / 10000
                        cat_m_final['ÂêåÊúü(‰∏á)'] = cat_m_final['ÂêåÊúü'] / 10000
                        cat_m_final['ÂêåÊØî'] = np.where(cat_m_final['Êú¨Êúà'] > 0, (cat_m_final['Êú¨Êúà'] - cat_m_final['ÂêåÊúü']) / cat_m_final['Êú¨Êúà'], None)
                        cat_m_final = cat_m_final.sort_values('Êú¨Êúà', ascending=False)

                        # 2. Yearly Category Data
                        cat_cur_y = df_f[df_f['Âπ¥‰ªΩ'] == cur_year].groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Âπ¥'})
                        cat_last_y = df_f[df_f['Âπ¥‰ªΩ'] == last_year].groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                        
                        cat_y_final = pd.merge(cat_cur_y, cat_last_y, on=cat_col_S, how='outer').fillna(0)
                        cat_y_final['Êú¨Âπ¥(‰∏á)'] = cat_y_final['Êú¨Âπ¥'] / 10000
                        cat_y_final['ÂêåÊúü(‰∏á)'] = cat_y_final['ÂêåÊúü'] / 10000
                        cat_y_final['ÂêåÊØî'] = np.where(cat_y_final['Êú¨Âπ¥'] > 0, (cat_y_final['Êú¨Âπ¥'] - cat_y_final['ÂêåÊúü']) / cat_y_final['Êú¨Âπ¥'], None)
                        cat_y_final = cat_y_final.sort_values('Êú¨Âπ¥', ascending=False)

                        # Render 2 Columns for Tables
                        c_cat_m, c_cat_y = st.columns(2)

                        with c_cat_m:
                            st.markdown(
                                """
                                <div style="background-color: #F8F9FA; border-radius: 8px; padding: 16px; border: 1px solid #E9ECEF; box-shadow: 0 2px 4px rgba(0,0,0,0.05); height: 100%;">
                                    <div style="font-size: 14px; color: #6C757D; margin-bottom: 12px; font-weight: 500;">üìÖ Êú¨ÊúàÂàÜÂìÅÁ±ª‰∏öÁª©</div>
                                """, 
                                unsafe_allow_html=True
                            )
                            # Replaced with AgGrid
                            show_aggrid_table(
                                cat_m_final[[cat_col_S, 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØî']],
                                height=250,
                                key="ag_cat_m"
                            )
                            
                            # Donut Chart for Month
                            if not cat_m_final.empty and cat_m_final['Êú¨Êúà(‰∏á)'].sum() > 0:
                                total_m = cat_m_final['Êú¨Êúà(‰∏á)'].sum()
                                cat_m_final['legend_label'] = cat_m_final.apply(
                                    lambda r: f"{r[cat_col_S]}   {r['Êú¨Êúà(‰∏á)']:.1f}‰∏á   {r['Êú¨Êúà(‰∏á)']/total_m:.1%}", axis=1
                                )
                                
                                fig_m = go.Figure(data=[go.Pie(
                                    labels=cat_m_final['legend_label'],
                                    values=cat_m_final['Êú¨Êúà(‰∏á)'],
                                    hole=0.6,
                                    marker=dict(colors=px.colors.qualitative.Pastel),
                                    textinfo='none',
                                    domain={'x': [0.4, 1.0]}
                                )])
                                fig_m.update_layout(
                                    showlegend=True,
                                    legend=dict(
                                        yanchor="middle", y=0.5,
                                        xanchor="left", x=0,
                                        font=dict(size=12, color="#333333")
                                    ),
                                    margin=dict(t=10, b=10, l=0, r=0), 
                                    height=250
                                )
                                st.plotly_chart(fig_m, use_container_width=True, key="perf_cat_month_donut")
                            else:
                                st.info("ÊöÇÊó†Êï∞ÊçÆ")
                                
                            st.markdown("</div>", unsafe_allow_html=True)

                        with c_cat_y:
                            st.markdown(
                                """
                                <div style="background-color: #F8F9FA; border-radius: 8px; padding: 16px; border: 1px solid #E9ECEF; box-shadow: 0 2px 4px rgba(0,0,0,0.05); height: 100%;">
                                    <div style="font-size: 14px; color: #6C757D; margin-bottom: 12px; font-weight: 500;">üèÜ Âπ¥Â∫¶ÂàÜÂìÅÁ±ª‰∏öÁª©</div>
                                """, 
                                unsafe_allow_html=True
                            )
                            # Replaced with AgGrid
                            show_aggrid_table(
                                cat_y_final[[cat_col_S, 'Êú¨Âπ¥(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØî']],
                                height=250,
                                key="ag_cat_y"
                            )
                            
                            # Donut Chart for Year
                            if not cat_y_final.empty and cat_y_final['Êú¨Âπ¥(‰∏á)'].sum() > 0:
                                total_y = cat_y_final['Êú¨Âπ¥(‰∏á)'].sum()
                                cat_y_final['legend_label'] = cat_y_final.apply(
                                    lambda r: f"{r[cat_col_S]}   {r['Êú¨Âπ¥(‰∏á)']:.1f}‰∏á   {r['Êú¨Âπ¥(‰∏á)']/total_y:.1%}", axis=1
                                )
                                
                                fig_y = go.Figure(data=[go.Pie(
                                    labels=cat_y_final['legend_label'],
                                    values=cat_y_final['Êú¨Âπ¥(‰∏á)'],
                                    hole=0.6,
                                    marker=dict(colors=px.colors.qualitative.Pastel),
                                    textinfo='none',
                                    domain={'x': [0.4, 1.0]}
                                )])
                                fig_y.update_layout(
                                    showlegend=True,
                                    legend=dict(
                                        yanchor="middle", y=0.5,
                                        xanchor="left", x=0,
                                        font=dict(size=12, color="#333333")
                                    ),
                                    margin=dict(t=10, b=10, l=0, r=0), 
                                    height=250
                                )
                                st.plotly_chart(fig_y, use_container_width=True, key="perf_cat_year_donut")
                            else:
                                st.info("ÊöÇÊó†Êï∞ÊçÆ")
                                
                            st.markdown("</div>", unsafe_allow_html=True)

                    with tab_perf_prov:
                        # --- 5. Province Table (Detailed) ---
                        
                        # Prepare Data
                        # Group by Province
                        # 1. Actuals (Cur Month)
                        df_m_cur = df_f[(df_f['Âπ¥‰ªΩ'] == cur_year) & (df_f['Êúà‰ªΩ'] == sel_month)]
                        prov_cur = df_m_cur.groupby('ÁúÅÂå∫')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà‰∏öÁª©'})
                        
                        # 2. Actuals (Same Period)
                        df_m_last = df_f[(df_f['Âπ¥‰ªΩ'] == last_year) & (df_f['Êúà‰ªΩ'] == sel_month)]
                        prov_last = df_m_last.groupby('ÁúÅÂå∫')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü‰∏öÁª©'})
                        
                        # 3. Targets (Month)
                        if df_target is not None:
                            t_m = df_target[df_target['Êúà‰ªΩ'] == sel_month]
                            prov_target = t_m.groupby('ÁúÅÂå∫')['‰ªªÂä°Èáè'].sum().reset_index().rename(columns={'‰ªªÂä°Èáè': 'Êú¨Êúà‰ªªÂä°'})
                        else:
                            prov_target = pd.DataFrame(columns=['ÁúÅÂå∫', 'Êú¨Êúà‰ªªÂä°'])
                            
                        # Merge All
                        prov_final = pd.merge(prov_cur, prov_target, on='ÁúÅÂå∫', how='outer')
                        prov_final = pd.merge(prov_final, prov_last, on='ÁúÅÂå∫', how='outer').fillna(0)
                        
                        # Filter out rows with 0
                        prov_final = prov_final[(prov_final['Êú¨Êúà‰∏öÁª©']!=0) | (prov_final['Êú¨Êúà‰ªªÂä°']!=0) | (prov_final['ÂêåÊúü‰∏öÁª©']!=0)]
                        
                        # Metrics
                        prov_final['ËææÊàêÁéá'] = prov_final.apply(lambda x: (x['Êú¨Êúà‰∏öÁª©'] / x['Êú¨Êúà‰ªªÂä°']) if x['Êú¨Êúà‰ªªÂä°'] > 0 else 0, axis=1)
                        prov_final['ÂêåÊØîÂ¢ûÈïø'] = prov_final.apply(lambda x: ((x['Êú¨Êúà‰∏öÁª©'] - x['ÂêåÊúü‰∏öÁª©']) / x['ÂêåÊúü‰∏öÁª©']) if x['ÂêåÊúü‰∏öÁª©'] > 0 else 0, axis=1)
                        
                        # Sort
                        prov_final = prov_final.sort_values('Êú¨Êúà‰∏öÁª©', ascending=False)
                        
                        # Format for Display
                        prov_final['Êú¨Êúà‰∏öÁª©(‰∏á)'] = prov_final['Êú¨Êúà‰∏öÁª©'] / 10000
                        prov_final['Êú¨Êúà‰ªªÂä°(‰∏á)'] = prov_final['Êú¨Êúà‰ªªÂä°'] / 10000
                        prov_final['ÂêåÊúü‰∏öÁª©(‰∏á)'] = prov_final['ÂêåÊúü‰∏öÁª©'] / 10000
                        
                        # Display Columns
                        disp_df = prov_final[['ÁúÅÂå∫', 'Êú¨Êúà‰∏öÁª©(‰∏á)', 'Êú¨Êúà‰ªªÂä°(‰∏á)', 'ËææÊàêÁéá', 'ÂêåÊúü‰∏öÁª©(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']].copy()
                        
                        # Interactive Table
                        st.caption("üëá ÁÇπÂáªË°®Ê†ºË°åÂèØ‰∏ãÈíªÊü•ÁúãËØ¶ÁªÜÊï∞ÊçÆ")
                        
                        # AgGrid for Province Performance
                        ag_prov = show_aggrid_table(
                            disp_df, 
                            key="perf_prov_ag",
                            on_row_selected=True
                        )
                        
                        # Drill Down
                        # Check if selected_rows exists and is not empty
                        selected_rows = ag_prov.get('selected_rows') if ag_prov else None
                        
                        if selected_rows is not None and len(selected_rows) > 0:
                            # AgGrid return structure might differ based on version
                            # Sometimes it returns a DataFrame, sometimes a list of dicts
                            if isinstance(selected_rows, pd.DataFrame):
                                first_row = selected_rows.iloc[0]
                            else:
                                first_row = selected_rows[0]
                                
                            # Handle if it returns a DataFrame row or dict
                            sel_prov_drill = first_row.get('ÁúÅÂå∫') if isinstance(first_row, dict) else first_row['ÁúÅÂå∫']
                            
                            # Drill Down Tabs
                            st.markdown("---")
                            st.subheader(f"üìç {sel_prov_drill} - ÊòéÁªÜÊï∞ÊçÆ")
                            
                            tab_dist, tab_cat = st.tabs(["üè¢ ÁªèÈîÄÂïÜÊòéÁªÜ", "üì¶ ÂìÅÁ±ªÊòéÁªÜ"])
                            
                            # Filter data for selected province
                            d_cur = df_f[(df_f['Âπ¥‰ªΩ'] == cur_year) & (df_f['Êúà‰ªΩ'] == sel_month) & (df_f['ÁúÅÂå∫'] == sel_prov_drill)]
                            d_last = df_f[(df_f['Âπ¥‰ªΩ'] == last_year) & (df_f['Êúà‰ªΩ'] == sel_month) & (df_f['ÁúÅÂå∫'] == sel_prov_drill)]

                            # --- Tab 1: Distributor Drill Down ---
                            with tab_dist:
                                st.caption(f"Ê≠£Âú®Êü•ÁúãÔºö{sel_prov_drill} > ÁªèÈîÄÂïÜÊòéÁªÜ")
                                d_cur_g = d_cur.groupby('ÁªèÈîÄÂïÜÂêçÁß∞')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                                d_last_g = d_last.groupby('ÁªèÈîÄÂïÜÂêçÁß∞')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                
                                d_final = pd.merge(d_cur_g, d_last_g, on='ÁªèÈîÄÂïÜÂêçÁß∞', how='outer').fillna(0)
                                d_final['ÂêåÊØîÂ¢ûÈïø'] = d_final.apply(lambda x: ((x['Êú¨Êúà'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                                d_final = d_final.sort_values('Êú¨Êúà', ascending=False)
                                
                                d_final['Êú¨Êúà(‰∏á)'] = d_final['Êú¨Êúà'] / 10000
                                d_final['ÂêåÊúü(‰∏á)'] = d_final['ÂêåÊúü'] / 10000
                                
                                ag_dist = show_aggrid_table(
                                    d_final[['ÁªèÈîÄÂïÜÂêçÁß∞', 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']],
                                    key="perf_dist_ag",
                                    on_row_selected=True
                                )
                                
                                selected_rows_dist = ag_dist.get('selected_rows') if ag_dist else None
                                
                                if selected_rows_dist is not None and len(selected_rows_dist) > 0:
                                    if isinstance(selected_rows_dist, pd.DataFrame):
                                        first_row_dist = selected_rows_dist.iloc[0]
                                    else:
                                        first_row_dist = selected_rows_dist[0]
                                        
                                    sel_dist_drill = first_row_dist.get('ÁªèÈîÄÂïÜÂêçÁß∞') if isinstance(first_row_dist, dict) else first_row_dist['ÁªèÈîÄÂïÜÂêçÁß∞']
                                    st.info(f"üìç Ê≠£Âú®Êü•Áúã {sel_prov_drill} > {sel_dist_drill} ÁöÑÂ§ßÂàÜÁ±ªÊòéÁªÜ")
                                    
                                    if 'Â§ßÂàÜÁ±ª' in d_cur.columns:
                                        cat_col_S = 'Â§ßÂàÜÁ±ª'
                                    elif 'ÊúàÂàÜÊûê' in d_cur.columns:
                                        cat_col_S = 'ÊúàÂàÜÊûê'
                                    else:
                                        cat_col_S = 'ÂèëË¥ß‰ªì'
                                    
                                    # Filter data for selected dist
                                    bc_cur = d_cur[d_cur['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist_drill]
                                    bc_last = d_last[d_last['ÁªèÈîÄÂïÜÂêçÁß∞'] == sel_dist_drill]
                                    
                                    bc_cur_g = bc_cur.groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                                    bc_last_g = bc_last.groupby(cat_col_S)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                    
                                    bc_final = pd.merge(bc_cur_g, bc_last_g, on=cat_col_S, how='outer').fillna(0)
                                    bc_final['ÂêåÊØîÂ¢ûÈïø'] = bc_final.apply(lambda x: ((x['Êú¨Êúà'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                                    bc_final = bc_final.sort_values('Êú¨Êúà', ascending=False)
                                    
                                    bc_final['Êú¨Êúà(‰∏á)'] = bc_final['Êú¨Êúà'] / 10000
                                    bc_final['ÂêåÊúü(‰∏á)'] = bc_final['ÂêåÊúü'] / 10000
                                    
                                    ag_bc = show_aggrid_table(
                                        bc_final[[cat_col_S, 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']],
                                        key="perf_bc_table_dist_ag",
                                        on_row_selected=True
                                    )
                                    
                                    selected_rows_bc = ag_bc.get('selected_rows') if ag_bc else None
                                    
                                    if selected_rows_bc is not None and len(selected_rows_bc) > 0:
                                        if isinstance(selected_rows_bc, pd.DataFrame):
                                            first_row_bc = selected_rows_bc.iloc[0]
                                        else:
                                            first_row_bc = selected_rows_bc[0]
                                            
                                        sel_bc_drill = first_row_bc.get(cat_col_S) if isinstance(first_row_bc, dict) else first_row_bc[cat_col_S]
                                        st.info(f"üìç Ê≠£Âú®Êü•Áúã {sel_prov_drill} > {sel_dist_drill} > {sel_bc_drill} ÁöÑÂ∞èÂàÜÁ±ª(ÂΩíÁ±ª)ÊòéÁªÜ")
                                        
                                        # Level 4: Small Category (Group) for Selected Big Cat
                                        sc_cur = bc_cur[bc_cur[cat_col_S] == sel_bc_drill]
                                        sc_last = bc_last[bc_last[cat_col_S] == sel_bc_drill]
                                        
                                        sc_cur_g = sc_cur.groupby('ÂΩíÁ±ª')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                                        sc_last_g = sc_last.groupby('ÂΩíÁ±ª')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                        
                                        sc_final = pd.merge(sc_cur_g, sc_last_g, on='ÂΩíÁ±ª', how='outer').fillna(0)
                                        sc_final['ÂêåÊØîÂ¢ûÈïø'] = sc_final.apply(lambda x: ((x['Êú¨Êúà'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                                        sc_final = sc_final.sort_values('Êú¨Êúà', ascending=False)
                                        
                                        sc_final['Êú¨Êúà(‰∏á)'] = sc_final['Êú¨Êúà'] / 10000
                                        sc_final['ÂêåÊúü(‰∏á)'] = sc_final['ÂêåÊúü'] / 10000
                                        
                                        show_aggrid_table(
                                            sc_final[['ÂΩíÁ±ª', 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']],
                                            key="perf_sc_table_dist_ag"
                                        )

                            with tab_cat:
                                st.caption(f"Ê≠£Âú®Êü•ÁúãÔºö{sel_prov_drill} > ÂìÅÁ±ªÊòéÁªÜ (ÊåâÂ§ßÂàÜÁ±ªËÅöÂêà)")
                                if 'Â§ßÂàÜÁ±ª' in d_cur.columns:
                                    agg_col = 'Â§ßÂàÜÁ±ª'
                                elif 'ÊúàÂàÜÊûê' in d_cur.columns:
                                    agg_col = 'ÊúàÂàÜÊûê'
                                else:
                                    agg_col = 'ÂèëË¥ß‰ªì'
                                
                                c_cur_g = d_cur.groupby(agg_col)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                                c_last_g = d_last.groupby(agg_col)['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                
                                c_final = pd.merge(c_cur_g, c_last_g, on=agg_col, how='outer').fillna(0)
                                c_final['ÂêåÊØîÂ¢ûÈïø'] = c_final.apply(lambda x: ((x['Êú¨Êúà'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                                c_final = c_final.sort_values('Êú¨Êúà', ascending=False)
                                
                                c_final['Êú¨Êúà(‰∏á)'] = c_final['Êú¨Êúà'] / 10000
                                c_final['ÂêåÊúü(‰∏á)'] = c_final['ÂêåÊúü'] / 10000
                                
                                ag_cat = show_aggrid_table(
                                    c_final[[agg_col, 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']],
                                    key="perf_cat_table_ag",
                                    on_row_selected=True
                                )
                                
                                selected_rows_cat = ag_cat.get('selected_rows') if ag_cat else None
                                
                                if selected_rows_cat is not None and len(selected_rows_cat) > 0:
                                    if isinstance(selected_rows_cat, pd.DataFrame):
                                        first_row_cat = selected_rows_cat.iloc[0]
                                    else:
                                        first_row_cat = selected_rows_cat[0]
                                        
                                    sel_cat_drill = first_row_cat.get(agg_col) if isinstance(first_row_cat, dict) else first_row_cat[agg_col]
                                    st.info(f"üìç Ê≠£Âú®Êü•Áúã {sel_prov_drill} > {sel_cat_drill} ÁöÑÂ∞èÂàÜÁ±ª(ÂΩíÁ±ª)ÊòéÁªÜ")
                                    
                                    # Level 3: Small Category (Group) for Selected Big Cat (Province Level)
                                    sc_cur = d_cur[d_cur[agg_col] == sel_cat_drill]
                                    sc_last = d_last[d_last[agg_col] == sel_cat_drill]
                                    
                                    sc_cur_g = sc_cur.groupby('ÂΩíÁ±ª')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'Êú¨Êúà'})
                                    sc_last_g = sc_last.groupby('ÂΩíÁ±ª')['ÂèëË¥ßÈáëÈ¢ù'].sum().reset_index().rename(columns={'ÂèëË¥ßÈáëÈ¢ù': 'ÂêåÊúü'})
                                    
                                    sc_final = pd.merge(sc_cur_g, sc_last_g, on='ÂΩíÁ±ª', how='outer').fillna(0)
                                    sc_final['ÂêåÊØîÂ¢ûÈïø'] = sc_final.apply(lambda x: ((x['Êú¨Êúà'] - x['ÂêåÊúü']) / x['ÂêåÊúü']) if x['ÂêåÊúü'] > 0 else 0, axis=1)
                                    sc_final = sc_final.sort_values('Êú¨Êúà', ascending=False)
                                    
                                    sc_final['Êú¨Êúà(‰∏á)'] = sc_final['Êú¨Êúà'] / 10000
                                    sc_final['ÂêåÊúü(‰∏á)'] = sc_final['ÂêåÊúü'] / 10000
                                    
                                    # Dynamic height
                                    n_rows_sc2 = len(sc_final)
                                    calc_height_sc2 = (n_rows_sc2 + 1) * 35 + 10
                                    final_height_sc2 = max(150, min(calc_height_sc2, 2000))
                                    
                                    show_aggrid_table(
                                        sc_final[['ÂΩíÁ±ª', 'Êú¨Êúà(‰∏á)', 'ÂêåÊúü(‰∏á)', 'ÂêåÊØîÂ¢ûÈïø']],
                                        height=final_height_sc2,
                                        key="perf_sc_table_cat_ag"
                                    )

else:
    st.info("ËØ∑Âú®Â∑¶‰æß‰∏ä‰º†Êï∞ÊçÆÊñá‰ª∂‰ª•ÂºÄÂßãÂàÜÊûê„ÄÇ")
